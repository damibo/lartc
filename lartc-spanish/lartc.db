<!DOCTYPE book PUBLIC "-//OASIS//DTD DocBook V4.1//EN">
<!-- $Id: lartc.db,v 1.33 2002/09/01 17:33:39 ahu Exp $ -->


<script type="text/javascript" src="/static/js/analytics.js" ></script>
<link type="text/css" rel="stylesheet" href="/static/css/banner-styles.css"/>




<!-- BEGIN WAYBACK TOOLBAR INSERT -->
<script> if (window.archive_analytics) { window.archive_analytics.values['server_name']="wwwb-app11.us.archive.org";}; </script>

<script type="text/javascript" src="/static/js/disclaim-element.js" ></script>
<script type="text/javascript" src="/static/js/graph-calc.js" ></script>
<script type="text/javascript" src="/static/jflot/jquery.min.js" ></script>
<script type="text/javascript">
//<![CDATA[
var firstDate = 820454400000;
var lastDate = 1420070399999;
var wbPrefix = "/web/";
var wbCurrentUrl = "http:\/\/www.gulic.org\/comos\/LARTC\/lartc.db";

var curYear = -1;
var curMonth = -1;
var yearCount = 18;
var firstYear = 1996;
var imgWidth = 475;
var yearImgWidth = 25;
var monthImgWidth = 2;
var trackerVal = "none";
var displayDay = "8";
var displayMonth = "Apr";
var displayYear = "2004";
var prettyMonths = ["Jan","Feb","Mar","Apr","May","Jun","Jul","Aug","Sep","Oct","Nov","Dec"];

function showTrackers(val) {
	if(val == trackerVal) {
		return;
	}
	if(val == "inline") {
		document.getElementById("displayYearEl").style.color = "#ec008c";
		document.getElementById("displayMonthEl").style.color = "#ec008c";
		document.getElementById("displayDayEl").style.color = "#ec008c";		
	} else {
		document.getElementById("displayYearEl").innerHTML = displayYear;
		document.getElementById("displayYearEl").style.color = "#ff0";
		document.getElementById("displayMonthEl").innerHTML = displayMonth;
		document.getElementById("displayMonthEl").style.color = "#ff0";
		document.getElementById("displayDayEl").innerHTML = displayDay;
		document.getElementById("displayDayEl").style.color = "#ff0";
	}
   document.getElementById("wbMouseTrackYearImg").style.display = val;
   document.getElementById("wbMouseTrackMonthImg").style.display = val;
   trackerVal = val;
}
function getElementX2(obj) {
	var thing = jQuery(obj);
	if((thing == undefined) 
			|| (typeof thing == "undefined") 
			|| (typeof thing.offset == "undefined")) {
		return getElementX(obj);
	}
	return Math.round(thing.offset().left);
}
function trackMouseMove(event,element) {

   var eventX = getEventX(event);
   var elementX = getElementX2(element);
   var xOff = eventX - elementX;
	if(xOff < 0) {
		xOff = 0;
	} else if(xOff > imgWidth) {
		xOff = imgWidth;
	}
   var monthOff = xOff % yearImgWidth;

   var year = Math.floor(xOff / yearImgWidth);
	var yearStart = year * yearImgWidth;
   var monthOfYear = Math.floor(monthOff / monthImgWidth);
   if(monthOfYear > 11) {
       monthOfYear = 11;
   }
   // 1 extra border pixel at the left edge of the year:
   var month = (year * 12) + monthOfYear;
   var day = 1;
	if(monthOff % 2 == 1) {
		day = 15;
	}
	var dateString = 
		zeroPad(year + firstYear) + 
		zeroPad(monthOfYear+1,2) +
		zeroPad(day,2) + "000000";

	var monthString = prettyMonths[monthOfYear];
	document.getElementById("displayYearEl").innerHTML = year + 1996;
	document.getElementById("displayMonthEl").innerHTML = monthString;
	// looks too jarring when it changes..
	//document.getElementById("displayDayEl").innerHTML = zeroPad(day,2);

	var url = wbPrefix + dateString + '/' +  wbCurrentUrl;
	document.getElementById('wm-graph-anchor').href = url;

   //document.getElementById("wmtbURL").value="evX("+eventX+") elX("+elementX+") xO("+xOff+") y("+year+") m("+month+") monthOff("+monthOff+") DS("+dateString+") Moy("+monthOfYear+") ms("+monthString+")";
   if(curYear != year) {
       var yrOff = year * yearImgWidth;
       document.getElementById("wbMouseTrackYearImg").style.left = yrOff + "px";
       curYear = year;
   }
   if(curMonth != month) {
       var mtOff = year + (month * monthImgWidth) + 1;
       document.getElementById("wbMouseTrackMonthImg").style.left = mtOff + "px";
       curMonth = month;
   }
}
//]]>
</script>

<style type="text/css">body{margin-top:0!important;padding-top:0!important;min-width:800px!important;}#wm-ipp a:hover{text-decoration:underline!important;}</style>
<div id="wm-ipp" lang="en" class="__wb_banner_div" style="display:none; position:relative;padding:0 5px;min-height:70px;min-width:800px">


<div id="wm-ipp-inside" class="__wb_banner_div" style="position:fixed;padding:0!important;margin:0!important;width:97%;min-width:780px;border:5px solid #000;border-top:none;background-image:url(/static/images/toolbar/wm_tb_bk_trns.png);text-align:center;-moz-box-shadow:1px 1px 3px #333;-webkit-box-shadow:1px 1px 3px #333;box-shadow:1px 1px 3px #333;font-size:11px!important;font-family:'Lucida Grande','Arial',sans-serif!important;">
   <table style="border-collapse:collapse;margin:0;padding:0;width:100%;"><tbody><tr>
   <td style="padding:10px;vertical-align:top;min-width:110px;">
   <a href="/web/" title="Wayback Machine home page" style="background-color:transparent;border:none;"><img src="/static/images/toolbar/wayback-toolbar-logo.png" alt="Wayback Machine" width="110" height="39" border="0"/></a>
   </td>
   <td style="padding:0!important;text-align:center;vertical-align:top;width:100%;">

       <table style="border-collapse:collapse;margin:0 auto;padding:0;width:570px;"><tbody><tr>
       <td style="padding:3px 0;" colspan="2">
       <form target="_top" method="get" action="/web/form-submit.jsp" name="wmtb" id="wmtb" style="margin:0!important;padding:0!important;"><input type="text" name="url" id="wmtbURL" value="http://www.gulic.org/comos/LARTC/lartc.db" style="width:400px;font-size:11px;font-family:'Lucida Grande','Arial',sans-serif;" onfocus="javascript:this.focus();this.select();" /><input type="hidden" name="type" value="replay" /><input type="hidden" name="date" value="20040408020401" /><input type="submit" value="Go" style="font-size:11px;font-family:'Lucida Grande','Arial',sans-serif;margin-left:5px;width: inherit !important" /><span id="wm_tb_options" style="display:block;"></span></form>
       </td>
       <td style="vertical-align:bottom;padding:5px 0 0 0!important;" rowspan="2">
           <table style="border-collapse:collapse;width:110px;color:#99a;font-family:'Helvetica','Lucida Grande','Arial',sans-serif;"><tbody>
			
           <!-- NEXT/PREV MONTH NAV AND MONTH INDICATOR -->
           <tr style="width:110px;height:16px;font-size:10px!important;">
           	<td style="padding-right:9px;font-size:11px!important;font-weight:bold;text-transform:uppercase;text-align:right;white-space:nowrap;overflow:visible;" nowrap="nowrap">
               
		                <a href="/web/20040307034848/http://www.gulic.org/comos/LARTC/lartc.db" style="text-decoration:none;color:#33f;font-weight:bold;background-color:transparent;border:none;" title="7 Mar 2004"><strong>MAR</strong></a>
		                
               </td>
               <td id="displayMonthEl" style="background:#000;color:#ff0;font-size:11px!important;font-weight:bold;text-transform:uppercase;width:34px;height:15px;padding-top:1px;text-align:center;" title="You are here: 2:04:01 Apr 8, 2004">APR</td>
				<td style="padding-left:9px;font-size:11px!important;font-weight:bold;text-transform:uppercase;white-space:nowrap;overflow:visible;" nowrap="nowrap">
               
                       May
                       
               </td>
           </tr>

           <!-- NEXT/PREV CAPTURE NAV AND DAY OF MONTH INDICATOR -->
           <tr>
               <td style="padding-right:9px;white-space:nowrap;overflow:visible;text-align:right!important;vertical-align:middle!important;" nowrap="nowrap">
               
		                <a href="/web/20040307034848/http://www.gulic.org/comos/LARTC/lartc.db" title="3:48:48 Mar 7, 2004" style="background-color:transparent;border:none;"><img src="/static/images/toolbar/wm_tb_prv_on.png" alt="Previous capture" width="14" height="16" border="0" /></a>
		                
               </td>
               <td id="displayDayEl" style="background:#000;color:#ff0;width:34px;height:24px;padding:2px 0 0 0;text-align:center;font-size:24px;font-weight: bold;" title="You are here: 2:04:01 Apr 8, 2004">8</td>
				<td style="padding-left:9px;white-space:nowrap;overflow:visible;text-align:left!important;vertical-align:middle!important;" nowrap="nowrap">
               
                       <img src="/static/images/toolbar/wm_tb_nxt_off.png" alt="Next capture" width="14" height="16" border="0"/>
                       
			    </td>
           </tr>

           <!-- NEXT/PREV YEAR NAV AND YEAR INDICATOR -->
           <tr style="width:110px;height:13px;font-size:9px!important;">
				<td style="padding-right:9px;font-size:11px!important;font-weight: bold;text-align:right;white-space:nowrap;overflow:visible;" nowrap="nowrap">
               
                       2003
                       
               </td>
               <td id="displayYearEl" style="background:#000;color:#ff0;font-size:11px!important;font-weight: bold;padding-top:1px;width:34px;height:13px;text-align:center;" title="You are here: 2:04:01 Apr 8, 2004">2004</td>
				<td style="padding-left:9px;font-size:11px!important;font-weight: bold;white-space:nowrap;overflow:visible;" nowrap="nowrap">
               
                       2005
                       
				</td>
           </tr>
           </tbody></table>
       </td>

       </tr>
       <tr>
       <td style="vertical-align:middle;padding:0!important;">
           <a href="/web/20040408020401*/http://www.gulic.org/comos/LARTC/lartc.db" style="color:#33f;font-size:11px;font-weight:bold;background-color:transparent;border:none;" title="See a list of every capture for this URL"><strong>2 captures</strong></a>
           <div class="__wb_banner_div" style="margin:0!important;padding:0!important;color:#666;font-size:9px;padding-top:2px!important;white-space:nowrap;" title="Timespan for captures of this URL">7 Mar 04 - 8 Apr 04</div>
       </td>
       <td style="padding:0!important;">
       <a style="position:relative; white-space:nowrap; width:475px;height:27px;" href="" id="wm-graph-anchor">
       <div class="__wb_banner_div" id="wm-ipp-sparkline" style="position:relative; white-space:nowrap; width:475px;height:27px;background-color:#fff;cursor:pointer;border-right:1px solid #ccc;" title="Explore captures for this URL">
			<img id="sparklineImgId" style="position:absolute; z-index:9012; top:0px; left:0px;"
				onmouseover="showTrackers('inline');" 
				onmouseout="showTrackers('none');"
				onmousemove="trackMouseMove(event,this)"
				alt="sparklines"
				width="475"
				height="27"
				border="0"
				src="/web/jsp/graph.jsp?graphdata=475_27_1996:-1:000000000000_1997:-1:000000000000_1998:-1:000000000000_1999:-1:000000000000_2000:-1:000000000000_2001:-1:000000000000_2002:-1:000000000000_2003:-1:000000000000_2004:3:001100000000_2005:-1:000000000000_2006:-1:000000000000_2007:-1:000000000000_2008:-1:000000000000_2009:-1:000000000000_2010:-1:000000000000_2011:-1:000000000000_2012:-1:000000000000_2013:-1:000000000000_2014:-1:000000000000"></img>
			<img id="wbMouseTrackYearImg" 
				style="display:none; position:absolute; z-index:9010;"
				width="25" 
				height="27"
				border="0"
				src="/static/images/toolbar/transp-yellow-pixel.png"></img>
			<img id="wbMouseTrackMonthImg"
				style="display:none; position:absolute; z-index:9011; " 
				width="2"
				height="27" 
				border="0"
				src="/static/images/toolbar/transp-red-pixel.png"></img>
       </div>
		</a>

       </td>
       </tr></tbody></table>
   </td>
   <td style="text-align:right;padding:5px;width:65px;font-size:11px!important;">
       <a href="javascript:;" onclick="document.getElementById('wm-ipp').style.display='none';" style="display:block;padding-right:18px;background:url(/static/images/toolbar/wm_tb_close.png) no-repeat 100% 0;color:#33f;font-family:'Lucida Grande','Arial',sans-serif;margin-bottom:23px;background-color:transparent;border:none;" title="Close the toolbar">Close</a>
       <a href="http://faq.web.archive.org/" style="display:block;padding-right:18px;background:url(/static/images/toolbar/wm_tb_help.png) no-repeat 100% 0;color:#33f;font-family:'Lucida Grande','Arial',sans-serif;background-color:transparent;border:none;" title="Get some help using the Wayback Machine">Help</a>
   </td>
   </tr></tbody></table>

</div>
</div>
<script type="text/javascript">
 var wmDisclaimBanner = document.getElementById("wm-ipp");
 if(wmDisclaimBanner != null) {
   disclaimElement(wmDisclaimBanner);
 }
</script>
<!-- END WAYBACK TOOLBAR INSERT -->
<Book id="lartc" lang="es">
<?dbhtml banner-text="Made possible by PowerDNS">
<?dbhtml banner-href="http://www.powerdns.com">

  <bookinfo>
    <Title>Enrutamiento avanzado y control de tráfico en Linux</Title>
    <authorgroup>
      <author>
	<FirstName>Bert</FirstName><Surname>Hubert</Surname>
        <affiliation>
	  <orgname>Netherlabs BV</orgname>
          <address><email>bert.hubert@netherlabs.nl</email></address>
        </affiliation>
      </author>
 
      <collab>
	<collabname>Thomas Graf (Section Author)</collabname>
        <affiliation>
          <address><email>tgraf%suug.ch</email></address>
	</affiliation>
      </collab>


      <collab>
        <collabname>Gregory Maxwell (autor de secciones)</collabname>
      </collab>
  

      <collab>
        <collabname>Remco van Mook (autor de secciones)</collabname>
        <affiliation>
          <address><email>remco@virtu.nl</email></address>
        </affiliation>
     </collab>
  
     <collab>
       <collabname>Martijn van Oosterhout (autor de secciones)</collabname>
        <affiliation>
          <address><email>kleptog@cupid.suninternet.com</email></address>
        </affiliation>
     </collab>
  
     <collab>
       <collabname>Paul B Schroeder (autor de secciones)</collabname>
        <affiliation>
          <address><email>paulsch@us.ibm.com</email></address>
        </affiliation>
     </collab>
  
     <collab>
       <collabname>Jasper Spaans (autor de secciones)</collabname>
        <affiliation>
          <address><email>jasper@spaans.ds9a.nl</email></address>
        </affiliation>
     </collab>
     <collab>
       <collabname>Pedro Larroy (autor de secciones)</collabname>
        <affiliation>
          <address><email>piotr%member.fsf.org</email></address>
        </affiliation>
     </collab>

     <collab role="translator">
       <collabname>Ricardo J. Cárdenes (traductor al castellano)</collabname>
       <affiliation>
         <address><email>ricardo%conysis.com</email></address>
       </affiliation>
     </collab>

   </authorgroup>
  
   <revhistory>
     <revision>
       <revnumber role="rcs">$Revision: 1.35 $</revnumber>
       <date role="rcs">$Date: 2003/07/26 19:57:49 $</date>
       <revremark>Edición en DocBook</revremark>
     </revision>
     <revision>
       <revnumber>1.33-es</revnumber>
       <date>2003/07/11</date>
       <revremark>Primera revisión de la traducción al castellano</revremark>
     </revision>
   </revhistory>
                                   
   <Abstract>
     <Para>Una introducción bastante práctica a
     <application>iproute2</application>, el control de tráfico y un poco
     de <application>netfilter</application>.
     </para>
   </Abstract>
  
</bookinfo>
<toc></toc>
<chapter id="lartc.dedication">
    <Title>Dedicatoria</Title>

    <Para>
      Este documento está dedicado a un montón de personas, y es mi
      intención devolverles algo. Una lista de unos pocos:
    </Para>

    <Para>

      <ItemizedList>
	<ListItem>
	  <Para>
	    Rusty Russell
	  </Para>
	</ListItem>
	<ListItem>

	  <Para>
	    Alexey N. Kuznetsov
	  </Para>
	</ListItem>
	<ListItem>
	  
	  <Para>
	    Los buenos chicos de Google
	  </Para>
	</ListItem>
	<ListItem>
	  
	  <Para>
	    El personal de Casema Internet
	  </Para>
	</ListItem>

      </ItemizedList>
	
    </Para>

  </chapter>

  <chapter id="lartc.intro">
    <Title>Introducción</Title>

<Para>
Bienvenido, gentil lector.
</Para>

<Para>
      Con este documento espero iluminarte en cómo hacer más con el
      enrutamiento de Linux 2.2/2.4. Aunque la mayoría de los usuarios lo
      desconozca, están usando herramientas que permiten hacer cosas
      espectaculares. Ordenes tales como <command>route</command> e
      <command>ifconfig</command> en realidad son envolturas realmente
      delgadas alrededor de la poderosa infraestructura de iproute2.
</Para>

    <Para>
      Espero que este Cómo sea tan legible como los de Rusty Russell,
      famoso (entre otras cosas) por netfilter.
    </Para>

    <Para>
      Siempre puede localizarnos escribiendo al <ULink
	URL="mailto:HOWTO@ds9a.nl"
	>equipo del HOWTO</ULink>
      (hágalo en inglés). Sin embargo, le pedimos que considere enviar
      el mensaje a la lista de correo (vea la sección correspondiente)
      si tiene dudas que no estén relacionadas directamente con este
      documento. No somos un servicio de atención gratuita, aunque a
      menudo respondamos a las preguntas que nos hacen en la lista.
</Para>

<Para>
Antes de que se pierda en este Cómo, si lo único que desea es hacer un
control de tráfico sencillo, sáltese todo lo demás y vaya directo al
capítulo <citetitle><xref linkend="lartc.other"></citetitle>, y lea sobre
CBQ.init.
</Para>

<Sect1 id="lartc.intro.disclaimer">
<Title>Descargo de responsabilidad y licencia</Title>

<Para>
Este documento se distribuye con la esperanza de que sea útil,
pero SIN NINGUN TIPO DE GARANTIA; incluso sin las garantías
implícitas MERCANTILES o DE ADECUACION PARA UN PROPOSITO PARTICULAR.
</Para>

<Para>
En breve, si su backbone STM-64 se desconfigura y empieza a repartir
pornografía a sus clientes más estimados, no es culpa nuestra. Lo
sentimos.
</Para>

<Para>
Copyright (c) 2002 by bert hubert, Gregory Maxwell, Martijn van
Oosterhout, Remco van Mook, Paul B. Schroeder and others. This material may
be distributed only subject to the terms and conditions set forth in the
Open Publication License, v1.0 or later (the latest version is presently
available at http://www.opencontent.org/openpub/).
</Para>

<Para>
Copie y distribuya (vendiéndolo o regalándolo) este documento en cualquier
formato. Le pedimos que envíe correcciones y comentarios al mantenedor del
documento.
</Para>

<Para>
También le pedimos que si publica este Cómo en papel, envíe algunas
muestras a los autores para <quote>propósitos de revisión</quote> :-)
</Para>

</Sect1>

<Sect1 id="lartc.intro.prior">
  <Title>Conocimientos previos</Title>

<Para>
Tal como implica el título, este es un Cómo <quote>Avanzado</quote>.
Aunque no es ciencia espacial de ninguna manera, se asumen ciertos
conocimientos previos.
</Para>

<Para>
Aquí hay algunas referencias que pueden ayudarle a aprender algo más:
<VariableList>
<VarListEntry>
  <Term>
    <ULink URL="http://netfilter.samba.org/unreliable-guides/networking-concepts-HOWTO/index.html">
      El Cómo de conceptos de redes de Rusty Russell</ULink>. También
      dispone de una
      <ULink URL="http://www.insflug.org/COMOs/conceptos-de-redes-COMO/conceptos-de-redes-COMO.html">
      versión en castellano</ULink>.
  </Term>
  <ListItem>
    <Para>Muy buena introducción, que explica lo que es una red, y cómo se
    conecta con otras.
    </Para>
  </ListItem>
</VarListEntry>
<VarListEntry>
  <Term>Redes en Linux Cómo (Previamente Net-3 Como)</Term>
  <ListItem>
    <Para>Gran material, aunque un poco exhaustivo. Le enseña un montón de
    cosas que ya deben estar configuradas si es capaz de conectar a
    Internet. Debería estar en
    <filename>/usr/doc/HOWTO/NET3-4-HOWTO.txt</filename> pero también lo
    puede encontrar
    <ULink URL="http://www.linuxports.com/howto/networking">en
    línea</ULink> (y en castellano
    <ULink URL="http://www.insflug.org/COMOs/Redes-En-Linux-Como/Redes-En-Linux-Como.html">aquí</ULink>).
    </Para>
  </ListItem>
</VarListEntry>
</VariableList>
</Para>

</Sect1>

<Sect1 id="lartc.intro.linux">
  <Title>Qué puede hacer Linux por usted</Title>

<Para>
Una pequeña lista de cosas posibles:
</Para>

<ItemizedList>
<ListItem>
  <Para>Mejorar el ancho de banda de ciertos computadores
  </Para>
</ListItem>
<ListItem>
  <Para>Mejorar el ancho de banda HACIA ciertos computadores
  </Para>
</ListItem>
<ListItem>
  <Para>Ayudarle a compartir su ancho de banda de forma justa
  </Para>
</ListItem>
<ListItem>
  <Para>Proteger su red ante ataques DoS
  </Para>
</ListItem>
<ListItem>
  <Para>Proteger a Internet de sus clientes
  </Para>
</ListItem>
<ListItem>
  <Para>Multiplexar varios servidores como uno solo, para equilibrio
  de carga o disponibilidad mejorada
  </Para>
</ListItem>
<ListItem>
  <Para>Restringir el acceso a sus computadores
  </Para>
</ListItem>
<ListItem>
  <Para>Limitar el acceso de sus usuarios a otras máquinas
  </Para>
</ListItem>
<ListItem>
  <Para>Hacer enrutamiento basado en el id de los usarios (¡sí!),
  dirección MAC, dirección IP de origen, puerto, tipo de servicio, hora
  del día o contenido
  </Para>
</ListItem>
</ItemizedList>

<Para>
Actualmente, no mucha gente usa estas capacidades avanzadas. Esto sucede
por varias razones. Mientras que la documentación existente es exahustiva,
no es muy práctica. El control de tráfico está casi sin documentar.
</Para>

</Sect1>

<Sect1 id="lartc.intro.houskeeping">
  <Title>Notas de mantenimiento</Title>

<Para>
Hay varias cosas que habría que resaltar sobre este documento. Aunque
que lo he escrito en su mayoría, realmente no quería que fuese así. Creo
mucho en el Open Source, de manera que le animo a que me envíe sus
impresiones, actualizaciones, parches, etc. No dude en informarme de
fallos de ortografía o errores por antigüedad. (Nota: lo siguiente sólo
tiene sentido en el documento original) Si mi inglés parece algo
acartonado, por favor, tenga en cuenta que no soy un hablante nativo.
Siéntase libre de enviarme sugerencias.
</Para>

<Para>
Si cree que está mejor cualificado para mantener una sección, o piensa que
puede crear y mantener nuevas secciones, sea bienvenido. El SGML de este
Cómo está disponible vía CVS, y me gustaría que trabajase más gente en él.
</Para>

<Para>
Como ayuda para esto, podrá encontrar varias notas FIXME. ¡Los parches
siempre vienen bien! Cuando se encuentre con un FIXME, debería saber que
está entrando en territorio desconocido. Esto no quiere decir que no haya
errores en otras partes, pero tenga especial cuidado. Si ha comprobado que
algo es válido, por favor, háganoslo saber para eliminar la nota de FIXME.
</Para>

<Para>
Sobre este Cómo, me voy a tomar una serie de libertades. Por ejemplo,
postulo una conexión a Internet de 10Mbit, aunque sé muy bien que esto no
es nada común.
</Para>

</Sect1>

<Sect1 id="lartc.intro.cvs">
  <Title>Acceso, CVS y envío de actualizaciones</Title>

<Para>
El lugar canónico de este Cómo es
<ULink URL="http://www.ds9a.nl/lartc">éste</ULink>.
</Para>

<Para>
Ahora disponemos de acceso anónimo a CVS para todo el mundo. Esto es bueno
por varias razones. Puede actualizar de forma sencilla a nuevas versiones
de este Cómo y enviar parches es fácil.
</Para>

<Para>
Más aún, permite a los autores trabajar en el fuente de forma
independiente, lo cual es bueno.
</Para>

<Screen width="80">
$ export CVSROOT=:pserver:anon@outpost.ds9a.nl:/var/cvsroot
$ cvs login
CVS password: [introduzca "cvs" (sin comillas)]
$ cvs co 2.4routing
cvs server: Updating 2.4routing
U 2.4routing/lartc.db
</Screen>

<Para>
Si ha hecho cambios y quiere contribuir con ellos, ejecute
<userinput>cvs -z3 diff -uBb</userinput>,
y envíe el resultado a <email>howto@ds9a.nl</email>, que nosotros
podemos integrarlo de forma sencilla. ¡Gracias! Por favor, asegúrese de
que edita el fichero .db. Por cierto, los otros ficheros se generan
partiendo de éste.
</Para>

<Para>
Se proporciona un Makefile que le ayudará a crear postscript, dvi, pdf,
html y texto plano. Puede que necesite instalar
<application>docbook</application>, <application>docbook-utils</application>,
<application>ghostscript</application> y <application>tetex</application>
para obtener todos los formatos.
</Para>

<para>
¡Procure no editar 2.4routing.sgml! Contiene una versión antigua de este
HOWTO. El fichero correcto es lartc.db.
</para>
</Sect1>

<Sect1 id="lartc.intro.mlist">
  <Title>Lista de correo</Title>

<Para>
Los autores reciben un creciente número de mensajes sobre este Cómo.
Debido al claro interés de la comunidad, se ha decidido crear una lista de
correo donde la gente pueda hablar entre sí sobre Advanced Routing
and Traffic Control. Puede suscribirse a la lista (se habla en inglés)
<ULink URL="http://mailman.ds9a.nl/mailman/listinfo/lartc">aquí</ULink>.
</Para>

<Para>
Debería precisar que los autores no suelen responder preguntas que no se
hagan a la lista. Nos gustaría que el archivo de la lista se convirtiera
en algo así como una base de conocimiento. Si tiene una pregunta, sírvase
buscar antes en el archivo, y sólo después envíela a la lista.
</Para>

</Sect1>

<Sect1 id="lartc.intro.layout">
  <Title>Disposición de este documento</Title>

<Para>
Vamos a empezar a hacer cosas interesantes casi inmediatamente, lo que
también significa que inicialmente habrán partes no del todo explicadas, o
que no estén perfectas. Por favor, lea superficialmente esas partes y
asuma que todo se aclarará más adelante.
</Para>

<Para>
Enrutar y filtrar son dos cosas distintas. El filtrado está bastante bien
documentado en los Cómo de Rusty, disponibles aquí:
</Para>

<ItemizedList>
<ListItem>
  <Para><ULink URL="http://netfilter.samba.org/unreliable-guides/">
    Rusty's Remarkably Unreliable Guides</ULink>
  </Para>
</ListItem>
</ItemizedList>

<Para>Vamos a centrarnos principalmente en las posibilidades de combinar
netfilter e iproute2.
</Para>

</Sect1>

</chapter>

<chapter id="lartc.iproute2">
  <Title>Introducción a iproute2</Title>

<Sect1 id="lartc.iproute2.why">
  <Title>¿Por qué iproute2?</Title>

<Para>
La mayoría de las distribuciones de Linux, y la mayoría de los UNIX, usan
actualmente las venerables órdenes <command>arp</command>,
<command>ifconfig</command> y <command>route</command>
Aunque funcionan, muestran cierto comportamiento inesperado apartir de
Linux 2.2.
Por ejemplo, los túneles GRE son parte integral del enrutado hoy día, pero
precisan herramientas completamente diferentes.
</Para>

<Para>
Con <application>iproute2</application>, los túneles son una parte
integral del juego de herramientas.
</Para>

<Para>
Los núcleos Linux 2.2 y superiores incluyen un subsistema de red
completamente rediseñado. Este nuevo código de red proporciona a Linux un
rendimiento y características con poca competencia en el panorama general
de los SO. En realiadd, el nuevo código de enrutado, filtrado y
clasificación tiene más posibilidades que el que porporcionan muchos
enrutadores y cortafuegos dedicados y productos de control de tráfico.
</Para>

<Para>
Según se inventan nuevos conceptos de red, la gente encuentra maneras de
emplastarlos encima de la infraestructura existente en los SO. Este
continuo apilamiento de porquería ha llevado a código de red lleno de
comportamientos extraños, muy parecido a lo que sucede con los idiomas
humanos. En el pasado, Linux emuló la forma de SunOS de gestionar muchas
de estas cosas, pero no era ideal.
</Para>

<Para>
Esta nueva infraestructura hace posible expresar claramente
características que antes estaban más allá del alcance de Linux.
</Para>

</Sect1>

<Sect1 id="lartc.iproute2.tour">
  <Title>revisión de iproute2</Title>

<Para>
Linux tiene un sistema sofisticado para proporcionar ancho de banda
llamado Traffic Control. Este sistema soporta varios métodos de
clasificación, priorizado, compartición y limitación tanto de tráfico
entrante como saliente.
</Para>

<Para>
Empezaremos con un pequeño «tour» por las posibilidades de iproute2.
</Para>

</Sect1>

<Sect1 id="lartc.iproute2.package">
  <Title>Prerequisitos</Title>

<Para>
Debería asegurarse de que tiene instaladas las herramientas de espacio de
usuario. Este paquete se llama «iproute» tanto en RedHat como en Debian, y
en cualquier caso, puede encontrarlo en
<filename>ftp://ftp.inr.ac.ru/ip-routing/iproute2-2.2.4-now-ss??????.tar.gz"</filename>.
</Para>

<Para>
También puede buscar
<ULink URL="ftp://ftp.inr.ac.ru/ip-routing/iproute2-current.tar.gz">aquí</ULink> 
la última versión.
</Para>

<Para>
Algunas partes de iproute precisan que active ciertas opciones del núcleo.
También debería saber que todas las versiones de RedHat hasta la 6.2,
incluida, vienen con la mayoría de capacidades de control de tráfico en el
núcleo de serie.
</Para>

<Para>
RedHat 7.2 lo tiene todo de serie.
</Para>

<Para>
También debe asegurarse de que tiene soporte de netlink, en caso de que
escoja configurar su propio núcleo. Iproute2 lo necesita.
</Para>

</Sect1>

<Sect1 id="lartc.iproute2.explore">
  <Title>Explorar la configuración actual</Title>

<Para>
Puede que le sorprenda, ¡pero iproute2 ya está configurado! Las órdenes
<command>ifconfig</command> y <command>route</command> actuales ya usan
las llamadas a sistema avanzadas, pero en su mayoría con configuraciones
por defecto (es decir, aburridas).
</Para>

<Para>
La herramienta <command>ip</command> es central, y le pediremos que nos
muestre nuestras interfaces.
</Para>

<Sect2>
<Title><command>ip</command> nos muestra nuestros enlaces</Title>

<Screen width="80">
[ahu@home ahu]$ ip link list
1: lo: &#60;LOOPBACK,UP&#62; mtu 3924 qdisc noqueue 
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
2: dummy: &#60;BROADCAST,NOARP&#62; mtu 1500 qdisc noop 
    link/ether 00:00:00:00:00:00 brd ff:ff:ff:ff:ff:ff
3: eth0: &#60;BROADCAST,MULTICAST,PROMISC,UP&#62; mtu 1400 qdisc pfifo_fast qlen 100
    link/ether 48:54:e8:2a:47:16 brd ff:ff:ff:ff:ff:ff
4: eth1: &#60;BROADCAST,MULTICAST,PROMISC,UP&#62; mtu 1500 qdisc pfifo_fast qlen 100
    link/ether 00:e0:4c:39:24:78 brd ff:ff:ff:ff:ff:ff
3764: ppp0: &#60;POINTOPOINT,MULTICAST,NOARP,UP&#62; mtu 1492 qdisc pfifo_fast qlen 10
    link/ppp 

</Screen>

<Para>
Puede que para usted varíe, pero esto es lo que muestra mi enrutador NAT
en casa. Sólo voy a explicar parte de la salida ya que no todo es
directamente relevante.
</Para>

<Para>
Primero vemos la interfaz loopback. Aunque su computador puede funcionar
sin una, le advierto que no lo haga. El tamaño MTU (Maximum Transfer Unit)
es de 3924 octetos, y no se supone que deba encolar. Lo cual tiene sentido
porque la interfaz loopback es una fantasía en la imaginación del núcleo.
</Para>

<Para>
Dejaré de lado por ahora la interfaz dummy, que puede no estar presente en
su computador. Después están mis dos interfaces de red físicas, una está
del lado de mi cable módem, y la otra sirve a mi segmento ethernet casero.
Más aún, vemos una interfaz ppp0.
</Para>

<Para>
Observe la ausencia de direcciones IP. iproute desconecta los conceptos de
«enlace» y «dirección IP». De todas maneras, con el alias de IP, el
concepto de «la» dirección IP se ha vuelto bastante irrelevante.
</Para>

<Para>
Sin embargo, nos muestra las direcciones MAC, el identificador en hardware
de nuestras interfaces ethernet.
</Para>

</Sect2>

<Sect2>
  <Title><command>ip</command> nos muestra nuestras direcciones IP</Title>

<Screen width="80">
[ahu@home ahu]$ ip address show        
1: lo: &#60;LOOPBACK,UP&#62; mtu 3924 qdisc noqueue 
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 brd 127.255.255.255 scope host lo
2: dummy: &#60;BROADCAST,NOARP&#62; mtu 1500 qdisc noop 
    link/ether 00:00:00:00:00:00 brd ff:ff:ff:ff:ff:ff
3: eth0: &#60;BROADCAST,MULTICAST,PROMISC,UP&#62; mtu 1400 qdisc pfifo_fast qlen 100
    link/ether 48:54:e8:2a:47:16 brd ff:ff:ff:ff:ff:ff
    inet 10.0.0.1/8 brd 10.255.255.255 scope global eth0
4: eth1: &#60;BROADCAST,MULTICAST,PROMISC,UP&#62; mtu 1500 qdisc pfifo_fast qlen 100
    link/ether 00:e0:4c:39:24:78 brd ff:ff:ff:ff:ff:ff
3764: ppp0: &#60;POINTOPOINT,MULTICAST,NOARP,UP&#62; mtu 1492 qdisc pfifo_fast qlen 10
    link/ppp 
    inet 212.64.94.251 peer 212.64.94.1/32 scope global ppp0
</Screen>

<Para>
Esto contiene más información. Nos muestra todas nuestras direcciones, y a
qué tarjetas pertenecen. «inet» significa Internet (IPv4). Hay muchas
otras familias de direcciones, pero no nos importan por el momento.
</Para>

<Para>
Examinemos eth0 más de cerca. Dice que está relacionada con la dirección
inet «10.0.0.1/8». ¿Qué significa esto? El /8 indica el número de bits que
están en la Dirección de Red. Hay 32 bit, de manera que quedan 24 bits que
son parte de nuestra red. Los primeros 8 bits de 10.0.0.1 corresponden a
10.0.0.0, nuestra Dirección de Red, y nuestra máscara de red (netmask) es
255.0.0.0.
</Para>

<Para>
Las otras máquinas están conectadas a esta interfaz, de manera que
10.250.3.13 es accesible de forma directa desde eth0, al igual que
10.0.0.1, por ejemplo.
</Para>

<Para>
Con ppp0, vemos el mismo concepto, aunque los números son diferentes. Su
dirección es 212.64.94.251, sin máscara de subred. Esto significa que
tenemos una conexión punto a punto y que cada dirección, con la excepción
de 212.64.94.251, es remota. Hay más información, sin embargo. Nos dice
que en la otra punta del enlace hay, de nuevo, una única dirección,
212.64.94.1. El /32 nos dice que no hay «bits de red».
</Para>

<Para>
Es absolutamente vital que comprenda bien estos conceptos. Remítase a la
documentación mencionada al principio de este Cómo si tiene problemas.
</Para>

<Para>
También observará «qdisc», que significa Disciplina de Cola (Queueing
Discipline). Más adelante veremos que es vital.
</Para>

</Sect2>

<Sect2>
  <Title><command>ip</command> nos muestra nuestras rutas</Title>

<Para>
Bien, ya sabemos cómo encontrar direcciones 10.x.y.z, y somos capaces de
alcanzar 212.64.94.1. Sin embargo, esto no es suficiente, de manera que
necesitamos instrucciones sobre cómo alcanzar al resto del mundo. La
Internet está disponible mediante nuestra conexión ppp, y parece que
212.64.94.1 está deseando esparcir nuestros paquetes por el mundo, y
entregarnos resultados de vuelta.
</Para>

<Screen width="80">
[ahu@home ahu]$ ip route show
212.64.94.1 dev ppp0  proto kernel  scope link  src 212.64.94.251 
10.0.0.0/8 dev eth0  proto kernel  scope link  src 10.0.0.1 
127.0.0.0/8 dev lo  scope link 
default via 212.64.94.1 dev ppp0 
</Screen>

<Para>
Bastante explícito. Las primeras 4 líneas indican explícitamente lo
que quedó implícito con <command>ip address show</command>, y la última
línea nos dice que el resto del mundo lo podemos encontrar mediante
212.64.94.1, nuestra pasarela por defecto. Podemos saber que es una
pasarela por la palabra «via», que nos dice que necesitamos enviar
paquetes a 212.64.94.1, que ya se encargará del resto.
</Para>

<Para>
Como referencia, esto es lo que la vieja utilidad <command>route</command>
nos muestra:
</Para>

<Screen width="80">
[ahu@home ahu]$ route -n
Kernel IP routing table
Destination     Gateway         Genmask         Flags Metric Ref    Use
Iface
212.64.94.1     0.0.0.0         255.255.255.255 UH    0      0        0 ppp0
10.0.0.0        0.0.0.0         255.0.0.0       U     0      0        0 eth0
127.0.0.0       0.0.0.0         255.0.0.0       U     0      0        0 lo
0.0.0.0         212.64.94.1     0.0.0.0         UG    0      0        0 ppp0
</Screen>

</Sect2>

</Sect1>

<Sect1 id="lartc.iproute2.arp">
  <Title>ARP</Title>

<Para>
ARP es el Address Resolution Protocol que se describe en el
<ULink URL="http://www.faqs.org/rfcs/rfc826.html">RFC 826</ULink>.
ARP lo usa una máquina en red para averiguar la localización/dirección
hardware de otra máquina en la misma red local. Las máquinas en Internet
se conocen generalmente por sus nombres que se corresponden a direcciones
IP. Así es como una máquina en la red foo.com es capaz de comunicarse con
otras máquinas que están en la red bar.net. Una dirección IP, sin embargo,
no puede decirte la localización física de una máquina. Aquí es donde
entra ARP.
</Para>

<Para>
Tomemos un ejemplo muy sencillo. Supongamos que tengo una red compuesta de
varias máquinas. Dos de ellas que están en mi red son foo con dirección IP
10.0.0.1 y bar con dirección IP 10.0.0.2. Ahora foo quiere hacer ping
hacia bar para ver si está viva, pero, ¡vaya!, foo no tiene idea de dónde
está bar. De manera que cuando foo decide hacer ping hacia bar necesita
realizar una consulta ARP.
Esta consulta ARP es algo así como si foo gritase en la red «¡Bar
(10.0.0.2)! ¿Dónde estás?» Como resultado de esto, cada máquina de la red
escuchará el grito de foo, pero sólo bar (10.0.0.2) responderá. Bar
enviará entonces una respuesta ARP directamente a foo, que viene a ser
como si bar dijese, «Foo (10.0.0.1), estoy aquí en 00:60:94:E9:08:12».
Después de esta sencilla transacción que sirve para localizar a su amigo
en la red, foo es capaz de comunicarse con bar hasta que olvide (su caché
arp) dónde está bar (normalmente tras 15 minutos, en Unix).
</Para>

<Para>
Ahora, veamos cómo funciona.
Puede ver la caché/tabla arp/neighbor actual de su máquina así:
</Para>

<Screen width="80">
[root@espa041 /home/src/iputils]# ip neigh show
9.3.76.42 dev eth0 lladdr 00:60:08:3f:e9:f9 nud reachable
9.3.76.1 dev eth0 lladdr 00:06:29:21:73:c8 nud reachable
</Screen>

<Para>
Como puede ver, mi máquina espa041 (9.3.76.41) sabe dónde encontrar a
espa042 (9.3.76.42) y espagate (9.3.76.1). Ahora añadamos otra máquina a
la caché arp.
</Para>

<Screen width="80">
[root@espa041 /home/paulsch/.gnome-desktop]# ping -c 1 espa043
PING espa043.austin.ibm.com (9.3.76.43) from 9.3.76.41 : 56(84) bytes of data.
64 bytes from 9.3.76.43: icmp_seq=0 ttl=255 time=0.9 ms

--- espa043.austin.ibm.com ping statistics ---
1 packets transmitted, 1 packets received, 0% packet loss
round-trip min/avg/max = 0.9/0.9/0.9 ms

[root@espa041 /home/src/iputils]# ip neigh show
9.3.76.43 dev eth0 lladdr 00:06:29:21:80:20 nud reachable
9.3.76.42 dev eth0 lladdr 00:60:08:3f:e9:f9 nud reachable
9.3.76.1 dev eth0 lladdr 00:06:29:21:73:c8 nud reachable
</Screen>

<Para>
Como resultado de que espa041 intente contactar con espa043, se ha añadido
la dirección/localización hardware de espa043 a la caché arp/neighbor. De
manera que mientras no caduque la entrada de espa043 (como resultado de la
ausencia de comunicación entre ambas), espa041 sabe dónde encontrar a
espa043 y no necesita enviar una consulta ARP.
</Para>

<Para>
Ahora, eliminemos a espa043 de nuestra caché arp:
</Para>

<Screen width="80">
[root@espa041 /home/src/iputils]# ip neigh delete 9.3.76.43 dev eth0
[root@espa041 /home/src/iputils]# ip neigh show
9.3.76.43 dev eth0  nud failed
9.3.76.42 dev eth0 lladdr 00:60:08:3f:e9:f9 nud reachable
9.3.76.1 dev eth0 lladdr 00:06:29:21:73:c8 nud stale
</Screen>

<Para>
Ahora espa041 ha vuelto a olvidar dónde encontrar a espa043 y necesitará
enviar otra consulta ARP la siguiente vez que necesite comunicarse con
espa043. También puede ver en el listado anterior que espagate (9.3.76.1)
ha cambiado al estado «stale». Esto significa que la localización mostrada
todavía es válida, pero tendrá que ser confirmada en la primera
transacción que se haga con esa máquina.
</Para>

</Sect1>

</chapter>

<chapter id="lartc.rpdb">
  <Title>Reglas (base de datos de normas de rutado)</Title>

<Para>
Si tiene una red grande, probablemente tenga que encargarse de las
necesidades de diferentes personas, que deberían ser servidas de forma
diferente. La base de datos de normas de rutado (routing policy database)
le permite hacerlo teniendo varios conjuntos de tablas de rutado.
</Para>

<Para>
Si quiere usar esta característica, asegúrese de que compila su núcleo con
las opciones «IP: advanced router» e «IP: policy routing».
</Para>

<Para>
Cuando el núcleo necesita tomar una decisión de encaminamiento, busca la
tabla que necesita consultar. Por defecto, hay tres tablas. La antigua
herramienta "route" modifica las tablas principal y local, al igual que la
herramienta ip (por defecto).
</Para>

<Para>Las reglas por defecto:
</Para>

<Screen width="80">
[ahu@home ahu]$ ip rule list
0:	from all lookup local 
32766:	from all lookup main 
32767:	from all lookup default
</Screen>

<Para>
Aquí se lista la priorida de todas las reglas. Vemos que todas son
aplicables a todos los paquetes («from all»). Hemos visto anteriormente la
tabla «main», mostrada por <userinput>ip route ls</userinput>, pero las
tablas «local» y «default» son nuevas.
</Para>

<Para>
Si queremos hacer cosas interesantes, generaremos reglas que se refieran a
diferentes tablas que nos permitirán saltarnos las reglas generales de
rutado del sistema.
</Para>

<Para>
Si desea ver la semántica exacta de lo que hace el núcleo cuando hay más
de una regla válida, vea la documentación ip-cref de Alexey.
</Para>

<Sect1 id="lartc.rpdb.simple">
  <Title>Normas de encaminamiento por origen sencillas</Title>

<Para>
<!-- DUDA -->
Tomando de nuevo un ejemplo real, tengo 2 cable módems (en realidad 3,
pero acabé devolviendo uno), conectados a un router Linux NAT
<!-- DUDA -->
(«masquerading»). La gente que vive aquí me paga por acceder a Internet.
Suponga que uno de mis compañeros de casa sólo visita hotmail y desea
pagar menos. Esto me parece bien, pero acabará usando el cable módem de
menos prestaciones.
</Para>

<Para>
El cable módem «rápido» se conoce como 212.64.94.251 y es un enlace PPP a
212.64.94.1. El «lento» es conocido por varias IP, por ejemplo
212.64.78.148, y es un enlace a 195.96.98.253.
</Para>

<Para>La tabla local:
</Para>

<Screen width="80">
[ahu@home ahu]$ ip route list table local
broadcast 127.255.255.255 dev lo  proto kernel  scope link  src 127.0.0.1 
local 10.0.0.1 dev eth0  proto kernel  scope host  src 10.0.0.1 
broadcast 10.0.0.0 dev eth0  proto kernel  scope link  src 10.0.0.1 
local 212.64.94.251 dev ppp0  proto kernel  scope host  src 212.64.94.251 
broadcast 10.255.255.255 dev eth0  proto kernel  scope link  src 10.0.0.1 
broadcast 127.0.0.0 dev lo  proto kernel  scope link  src 127.0.0.1 
local 212.64.78.148 dev ppp2  proto kernel  scope host  src 212.64.78.148 
local 127.0.0.1 dev lo  proto kernel  scope host  src 127.0.0.1 
local 127.0.0.0/8 dev lo  proto kernel  scope host  src 127.0.0.1 
</Screen>

<Para>
Montón de cosas obvias, pero que hace falta especificar en algún sitio.
Bien, aquí están. La tabla por defecto está vacía.
</Para>

<Para>Veamos la tabla «main»:
</Para>

<Screen width="80">
[ahu@home ahu]$ ip route list table main 
195.96.98.253 dev ppp2  proto kernel  scope link  src 212.64.78.148 
212.64.94.1 dev ppp0  proto kernel  scope link  src 212.64.94.251 
10.0.0.0/8 dev eth0  proto kernel  scope link  src 10.0.0.1 
127.0.0.0/8 dev lo  scope link 
default via 212.64.94.1 dev ppp0 
</Screen>

<Para>
Ahora generaremos una nueva regla que llamaremos «John», por nuestro
hipotético compañero. Aunque podemos trabajar con números, es mucho más
sencillo añadir nuestras tablas a /etc/iproute2/rt_tables.
</Para>

<Screen width="80">
# echo 200 John &#62;&#62; /etc/iproute2/rt_tables
# ip rule add from 10.0.0.10 table John
# ip rule ls
0:	from all lookup local 
32765:	from 10.0.0.10 lookup John
32766:	from all lookup main 
32767:	from all lookup default
</Screen>

<Para>
Ahora todo lo que queda es generar la tabla John, y refrescar la caché de
rutas:
</Para>

<Screen width="80">
# ip route add default via 195.96.98.253 dev ppp2 table John
# ip route flush cache
</Screen>

<Para>
Ya hemos terminado. Dejamos como ejercicio al lector implementar esto en
ip-up.
</Para>

</Sect1>

<sect1 id="lartc.rpdb.multiple-links">
  <title>Encaminamiento con varios enlaces de salida/proveedores</title>
<para>
La siguiente es una configuración común, en la que hay dos proveedores que
conectan una red local (o incluso una única máquina) a la gran Internet.

<screen>
                                                                 ________
                                         +-------------+        /
                                         |             |       |
                            +------------+ Proveedor 1 +-------
        __                  |            |             |     /
    ___/  \_         +------+-------+    +-------------+    |
  _/        \__      |     if1      |                      /
 /             \     |              |                      |
|   Red local   -----+ Linux router |                      |     Internet
 \_           __/    |              |                      |
   \__     __/       |     if2      |                      \
      \___/          +------+-------+    +-------------+    |
                            |            |             |     \
                            +------------+ Proveedor 2 +-------
                                         |             |       |
                                         +-------------+        \________
</screen>
</para>
<para>
Normalmente surgen dos preguntas dada esta configuración.
</para>
      <sect2><title>Acceso dividido</title>
	<para>
	  La primera es cómo enrutar respuestas a paquetes que vienen de
	  un proveedor particular, por ejemplo Proveedor 1, de vuelta por
	  el mismo camino.
	</para>
	<para>
	  Primero establezcamos algunos nombres simbólicos. Digamos que
	  <command>$IF1</command> es el nombre de la primera interfaz (if1
	  en la figura) y <command>$IF2</command> el nombre de la segunda.
	  Sean entonces <command>$IP1</command> la dirección IP asociada
	  con <command>$IF1</command> y <command>$IP2</command> la IP
	  asociada con <command>$IF2</command>. Luego, digamos que
	  <command>$P1</command> es la dirección IP de la pasarela a
	  Proveedor 1, y <command>$P2</command> la IP de la pasarela a
	  Proveedor 2. Por último, <command>$P1_NET</command> será la red
	  IP donde está <command>$P1</command>, y
	  <command>$P2_NET</command> la red IP donde está
	  <command>$P2</command>.
	</para>
	<para>
	  Creamos dos tablas de encaminamiento adicionales, llamémoslas
	  <command>T1</command> y <command>T2</command>. Las añadimos a
	  /etc/iproute2/rt_tables. Entonces las configuramos de la
	  siguiente manera:
	</para>
	<para>
	<screen>
	  ip route add $P1_NET dev $IF1 src $IP1 table T1
	  ip route add default via $P1 table T1
	  ip route add $P2_NET dev $IF2 src $IP2 table T2
	  ip route add default via $P2 table T2
	</screen>
	  
	  Nada espectacular; simplemente hemos montado una ruta hacia una
	  pasarela, y una ruta por defecto mediante ella, tal como sería
	  el caso con un único proveedor, pero ponemos las rutas en tablas
	  separadas, una por proveedor. Observe que basta la ruta hacia la
	  red, ya que le indica cómo encontrar cualquier máquina dentro de
	  esa red, lo que incluye la pasarela, como se especificó
	  anteriormente.
	</para>
	<para>
	  Después configuramos la tabla de rutas principal (main). Es una
	  buena idea encaminar las cosas a vecinos directos mediante la
	  interfaz conectada a ese vecino. Observe las opciones «src», que
	  se aseguran que se escoge la dirección IP correcta.

	  <screen>
	    ip route add $P1_NET dev $IF1 src $IP1
	    ip route add $P2_NET dev $IF2 src $IP2
	  </screen>

	  Luego, la ruta por defecto preferente:
	  
	  <screen>
	    ip route add default via $P1
	  </screen>

	  A continuación, configuramos las reglas de encaminamiento. Estas
	  son las que escogen qué tabla de rutas se usa. Querrá asegurarse
	  de que encamina por una interfaz dada si ya tenemos una
	  dirección de origen correspondiente:
	  
	  <screen>
	    ip rule add from $IP1 table T1
	    ip rule add from $IP2 table T2
	  </screen>

	  Estas órdenes se aseguran de que todas las respuestas al tráfico
	  proveniente de una interfaz en particular será contestado por
	  esta interfaz.
	</para>
	<para>
	<warning><para>
El lector Rod Roark señala: «Si $P0_NET es la red local y $IF0 su interfaz,
serían deseables las siguientes órdenes adicionales:
<screen>
ip route add $P0_NET     dev $IF0 table T1
ip route add $P2_NET     dev $IF2 table T1
ip route add 127.0.0.0/8 dev lo   table T1
ip route add $P0_NET     dev $IF0 table T2
ip route add $P1_NET     dev $IF1 table T2
ip route add 127.0.0.0/8 dev lo   table T2

</screen>»
	</para></warning></para>
	<para>
	  Esta es la configuración más básica. Funcionará para todos los
	  procesos que estén funcionando en el propio router, y para la
	  red local, si está enmascarada, y si no, entonces puede que
	  tenga un espacio IP de ambos proveedores, o que vaya a
	  enmascarar la salida por uno de los proveedores. En ambos casos,
	  querrá añadir reglas escogiendo por cual proveedor encaminar
	  basándose en las direcciones IP de las máquinas en la red local.
 	</para>
      </sect2>
      <sect2><title>Equilibrio de carga</title>
	<para>
	  La segunda pregunta es cómo equilibar el tráfico que va por los
	  dos proveedores. En realidad no es difícil si ya ha configurado
	  un acceso dividido como se indicó previamente.
	  </para>
	<para>
	  En lugar de escoger uno de los proveedores como la salida por
	  defecto, configuraremos la ruta por defecto para que sea
	  multicamino (multipath route). Por defecto, el núcleo
	  equilibrará las rutas sobre los dos proveedores. Esto se hace
	  como sigue (una vez más, nos apoyamos en el ejemplo de la
	  sección sobre acceso dividido):

	  <screen>
	    ip route add default scope global nexthop via $P1 dev $IF1 weight 1 \
	    nexthop via $P2 dev $IF2 weight 1
	  </screen>

	  Esto equilibrará las rutas sobre ambos proveedores. Los
	  parámetros <command>weight</command> se pueden modificar para
	  favorecer a un proveedor sobre el otro.
	</para>
	<para>
	  Tenga en cuenta que el equilibrio no será perfecto, ya que se
	  basa en rutas, y las rutas están en caché. Esto significa que
	  las rutas usadas más a menudo siempre irán sobre el mismo
	  proveedor.
	</para>
	<para>
	  Más aún, si realmente quiere hacer esto, probablemente también
	  quiera los parches de Julian Anastasov que hay en <ulink url="http://www.ssi.bg/~ja/#routes">http://www.ssi.bg/~ja/#routes</ulink>,
	  la página del parche de rutas de Julian. Hará más sencillo el
	  trabajo.
	</para>
      </sect2>
    </sect1>
  </chapter>

<chapter id="lartc.tunnel">
   <Title>GRE y otros túneles</Title>

<Para>
Hay tres tipos de túneles en Linux. Están los túneles IP sobre IP, los
túneles GRE y túneles que se realizan fuera del núcleo (como por ejemplo,
PPTP).
</Para>

<Sect1 id="lartc.tunnel.remarks">
  <Title>Breve inciso sobre los túneles:</Title>

<Para>
Los túneles se pueden usar para hacer varias cosas poco usuales y bastante
interesantes. También pueden hacer que las cosas vayan horriblemente mal
si no los configura bien. No ponga su ruta por defecto sobre un
dispositivo de túnel a menos que sepa <Emphasis>EXACTAMENTE</Emphasis> lo
que está haciendo :-). Más aún, los túneles incrementan la carga, porque
necesitan un juego extra de cabeceras IP. Normalmente, esto significa 20
bytes por paquete, de manera que si el tamaño normal de un paquete (MTU)
en una red es de 1500 bytes, un paquete enviado por un túnel sólo puede
ser de 1480 bytes como mucho. Esto no es necesariamente un problema, pero
asegúrese de leer algo sobre fragmentación/reensamblaje de paquetes IP si
planea conectar redes grandes con túneles. Oh, y por supuesto, la manera
más rápida de cavar un túnel es cavar desde los dos extremos.
</Para>

</Sect1>

<Sect1 id="lartc.tunnel.ip-ip">
  <Title>Túneles IP sobre IP</Title>

<Para>
Este tipo de túneles lleva disponible en Linux mucho tiempo. Precisa dos
módulos del núcleo,
ipip.o y new_tunnel.o
</Para>

<Para>
Digamos que tenemos tres redes: las redes internas A y B, y una red
intermedia C (o Internet, por ejemplo).
De manera que tenemos la red A:
</Para>

<Screen width="80">
network 10.0.1.0
netmask 255.255.255.0
router  10.0.1.1
</Screen>

<Para>El router tiene la dirección 172.16.17.18 en la red C.
</Para>

<Para>y la red B:
</Para>

<Screen width="80">
network 10.0.2.0
netmask 255.255.255.0
router  10.0.2.1
</Screen>

<Para>Cuyo router tiene la dirección 172.19.20.21 en la red C.
</Para>

<Para>
Hasta donde le concierne a C, asumimos que pasará cualquier paquete que
vaya de A a B y viceversa. Incluso puede usar Internet para esto.
</Para>

<Para>Esto es lo que haremos:
</Para>

<Para>Primero, asegurarnos de que los módulos están instalados:
</Para>

<Screen width="80">
insmod ipip.o
insmod new_tunnel.o
</Screen>

<Para>Luego, en el router de la red A, hacemos lo siguiente:
</Para>

<Screen width="80">
ifconfig tunl0 10.0.1.1 pointopoint 172.19.20.21
route add -net 10.0.2.0 netmask 255.255.255.0 dev tunl0
</Screen>

<Para>Y en el de la red B:
</Para>

<Screen width="80">
ifconfig tunl0 10.0.2.1 pointopoint 172.16.17.18
route add -net 10.0.1.0 netmask 255.255.255.0 dev tunl0
</Screen>

<Para>Y si ha dejado de usar el túnel:
</Para>

<Screen width="80">
ifconfig tunl0 down
</Screen>

<Para>Listo, ya lo tiene. Sin embargo, no puede enviar tráfico de difusión
(broadcast) o IPv6 mediante un túnel IP-sobre-IP. Simplemente puede
conectar dos redes IPv4 que normalmente no podrían comunicarse entre
ellas; eso es todo. En lo que respecta a la compatibilidad, este código
lleva ahí mucho tiempo, de manera que es compatible hasta con los núcleos
1.3. Los túneles IP-sobre-IP de Linux no funcionan con otros sistemas
operativos o routers, hasta donde yo sé. Es sencillo, y funciona. Uselo si
lo necesita, en cualquier otro caso, use GRE.
</Para>

</Sect1>

<Sect1 id="lartc.tunnel.gre">
  <Title>Túneles GRE</Title>

<Para>
GRE es un protocolo de tunelizado que desarrolló Cisco originalmente, y
que puede hacer unas cuántas cosas más que los túneles IP-sobre-IP. Por
ejemplo, puede transportar tráfico multicast e IPv6 sobre un túnel GRE.
</Para>

<Para>
En Linux, necesitará el módulo ip_gre.o.
</Para>

<Sect2>
<Title>Túneles IPv4</Title>

<Para>
Primero hagamos un túnel IPv4:
</Para>

<Para>
Digamos que tenemos 3 redes: las redes internas A y B, y una red
intermedia C (por ejemplo, Internet).
</Para>

<Para>
De manera que tenemos la red A:

<Screen width="80">
network 10.0.1.0
netmask 255.255.255.0
router  10.0.1.1
</Screen>

El router tiene la dirección 172.16.17.18 en la red C.
Llamaremos a esta red neta (ok, no es muy original)
</Para>

<Para>
Y la red B:

<Screen width="80">
network 10.0.2.0
netmask 255.255.255.0
router  10.0.2.1
</Screen>

El router tiene la dirección 172.19.20.21 en la red C.
Llamemos a esta red netb (seguimos con nuestra originalidad)
</Para>

<Para>
Hasta donde concierne a la red C, asumiremos que dejará pasar los paquetes
enviados de A a B y vicebersa. Cómo y por qué, no nos interesa.
</Para>

<Para>En el router de la red A, haremos lo siguiente:
</Para>

<Screen width="80">
ip tunnel add netb mode gre remote 172.19.20.21 local 172.16.17.18 ttl 255
ip link set netb up
ip addr add 10.0.1.1 dev netb
ip route add 10.0.2.0/24 dev netb
</Screen>

<Para>
Miremos esto con más atención. En la línea 1, hemos añadido un dispositivo
de túnel, y le hemos llamado netb (bastante obvio porque es a donde
queremos llegar). Más aún, le hemos dicho que use el protocolo GRE (mode
gre), que la dirección remota es 172.19.20.21 (el router en el otro
extremo), que nuestros paquetes de túnel deberían ser originados por
172.16.17.18 (lo que permite a nustro router tener varias direcciones IP
en la red C y decidir cual usar para el tunelizado) y que el campo TTL del
paquete debería establecerse en 255 (ttl 255).
</Para>

<Para>
La segunda línea habilita el dispositivo.
</Para>

<Para>
En la tercera línea le hemos dado a la recién nacida interfaz netb la
dirección 10.0.1.1. Esto está bien para redes pequeñas, pero cuando
empiece una expedición de zapadores (MUCHOS túneles), quizá debiera
considerar usar otro rango de IP para las interfaces de túneles (en este
ejemplo, podría usar 10.0.3.0).
</Para>

<Para>
En la cuarta línea hemos establecido la ruta hacia la red B. Fíjese la
notación diferente para la máscara de red. Si no está familiarizado con
esta notación, así es como funciona: escriba la máscara de red en forma
binaria, y cuente todos los unos. Si no sabe cómo hacerlo, limítese a
recordar que 255.0.0.0 es /8, 255.255.0.0 es /16 y 255.255.255.0 es /24.
Ah, y 255.255.254.0 es /23, en caso de que tuviera curiosidad.
</Para>

<Para>
Pero ya hemos tenido bastante de esto; veamos el router de la red B.

<Screen>
ip tunnel add neta mode gre remote 172.16.17.18 local 172.19.20.21 ttl 255
ip link set neta up
ip addr add 10.0.2.1 dev neta
ip route add 10.0.1.0/24 dev neta
</Screen>

Y cuando vaya a eliminar el túnel del router A:

<Screen>
ip link set netb down
ip tunnel del netb
</Screen>

Por supuesto, puede cambiar netb por neta para el router B.
</Para>

</Sect2>

<Sect2>
<Title>Túneles IPv6</Title>

<Para>
Vea la sección 6 si quiere una pequeña introducción a las direcciones
IPv6.
</Para>

<Para>
Vamos con los túneles.
</Para>

<Para>
Asumamos que tiene la siguiente red IPv6, y que quiere conectarse a la
6bone, o con un amigo.
</Para>

<Para>

<Screen>
Red 3ffe:406:5:1:5:a:2:1/96
</Screen>

Su dirección IPv4 es 172.16.17.18, y el router 6bone tiene la dirección
IPv4 172.22.23.24.
</Para>

<Para>

<Screen>
ip tunnel add sixbone mode sit remote 172.22.23.24 local 172.16.17.18 ttl 255
ip link set sixbone up
ip addr add 3ffe:406:5:1:5:a:2:1/96 dev sixbone
ip route add 3ffe::/15 dev sixbone 
</Screen>

</Para>

<Para>
Vamos a comentar esto. En la primera línea, hemos creado un dispositivo de
túnel llamado sixbone. Le hemos dado modo sit (que es un túnel IPv6 sobre
IPv4) y le dijimos dónde debe ir (remote) y de dónde viene (local). TTL se
pone al máximo, 255. Después activamos el dispositivo (up). Tras esto,
añadimos nuestra propia dirección de red, y establecemos una ruta para
3ffe::/15 (que actualmente es la totalidad de la 6bone) a través del
túnel.
</Para>

<Para>
Los túneles GRE son actualmente el tipo preferido de túneles. Es un
estándar que está ampliamente adoptado fuera de la comunidad de Linux, y
por tanto una Cosa Buena.
</Para>

</Sect2>

</Sect1>

<Sect1 id="lartc.tunnel.userland">
  <Title>Túneles en espacio de usuario</Title>

<Para>
Literalmente, hay docenas de implementaciones de túneles fuera del núcleo.
Los más conocidos por supuesto son PPP y PPTP, pero hay mucho más (algunos
propietarios, algunos seguros, otros que ni siquiera usan IP) y que
realmente están más allá del ámbito de este Cómo.
</Para>

</Sect1>

</chapter>

<chapter id="lartc.ipv6-tunnel">
<Title>Túneles IPv6 con Cisco o la 6bone</Title>

<Para>
Por Marco Davids &lt;marco@sara.nl&gt;
</Para>

<Para>
NOTA al mantenedor:
</Para>

<Para>
Hasta donde sé, estos túneles IPv6-IPv4 no son por definición túneles GRE.
Podría tunelizar IPv6 sobre IPv4 mediante dispositivos GRE (GRE tuneliza
CUALQUIER cosa sobre IPv4), pero el dispositivo que se usa quí («sit»)
sólo tuneliza IPv6 sobre IPv4 y por lo tanto es algo diferente.
</Para>

<Sect1 id="lartc.tunnel-ipv6.addressing">
  <Title>Túneles IPv6</Title>

<Para>
Esta es otra aplicación de las capacidades para tunelizado de Linux. Es
popular entre la gente que ha adoptado IPv6 tempranamente, o pioneros, si
lo prefiere. El ejemplo práctico descrito más adelante no es, ciertamente,
la única manera de hacer túneles IPv6. Sin embargo, es el método que se
usa a menudo para hacer túneles entre Linux y un router Cisco con
posibilidades de IPv6 y la experiencia nos dice que tras lo que mucha
gente anda. Apuesto 10 a 1 a que esto se aplica a usted también ;-)
</Para>

<Para>
Notas breves sobre las direcciones IPv6:
</Para>

<Para>
Las direcciones IPv6 son, comparadas con las IPv4, realmente grandes: 128
bits frente a 32. Y nos proporciona justo lo que necesitamos: muchas,
muchas direcciones IP:
340.282.266.920.938.463.463.374.607.431.768.211.465, para ser precisos.
Aparte de esto, se supone que IPv6 (o IPng, de IP Next Generation) traerá
una reducción el tamaño de las tablas de rutas de los router principales
de Internet, una configuración más sencilla para el equipamiento, mejor
seguridad en el nivel de IP y mejor soporte para QoS (calidad de
servicio).
</Para>

<Para>
Un ejemplo: 2002:836b:9820:0000:0000:0000:836b:9886
</Para>

<Para>
Escribir direcciones IPv6 puede ser una gran molestia. Por tanto, nos
facilitaremos la vida siguiendo algunas reglas:
</Para>

<Para>

<ItemizedList>
<ListItem>

<Para>
No use ceros sin significado (a la izquierda). Igual que hace en IPv4.

</Para>
</ListItem>
<ListItem>

<Para>
Use dos puntos (:) para separara cada grupo de 16 bits o dos bytes.

</Para>
</ListItem>
<ListItem>

<Para>
Cuando tenga muchos ceros consecutivos,
puede abreviarlos con ::. Sólo puede hacer esto una vez por cada
dirección, y sólo en grupos de 16 bits.
</Para>
</ListItem>

</ItemizedList>

</Para>

<Para>
La dirección 2002:836b:9820:0000:0000:0000:836b:9886 puede escribirse
2002:836b:9820::836b:9886, que es algo más sencilla.
</Para>

<Para>
En otro ejemplo, la dirección 3ffe:0000:0000:0000:0000:0020:34A1:F32C
puede simplificarse como 3ffe::20:34A1:F32C, que es mucho más corta.
</Para>

<Para>
Se pretende que IPv6 sea el sucesor de la actual IPv4. Debido a que es una
tecnología relativamente nueva, no hay ninguna red mundial IPv6 nativa.
Se está introduciendo la 6bone para posibilitar la aceleración del cambio.
</Para>

<Para>
Las redes IPv6 nativas se conectan unas a otras encapsulando el protocolo
IPv6 en paquetes IPv4 y enviándolos mediante la infraestructura IPv4 ya
existente desde un sitio IPv6 a otro.
</Para>

<Para>
Aquí es justo donde entran los túneles.
</Para>

<Para>
Para poder usar IPv6, deberíamos tener un núcleo que lo admita. Hay muchos
documentos buenos sobre cómo conseguirlo. Pero todo se reduce a unos pocos
pasos:

<ItemizedList>
<ListItem>

<Para>
Obtenga una distribución Linux reciente, con una glibc adecuada.
</Para>
</ListItem>
<ListItem>

<Para>
Luego, consiga una fuente actualizada del núcleo.
</Para>
</ListItem>

</ItemizedList>

Si lo tiene todo, puede seguir adelante y compilar un núcleo con
capacidades de IPv6:

<ItemizedList>
<ListItem>

<Para>
Vaya a /usr/src/linux y escriba:
</Para>
</ListItem>
<ListItem>

<Para>
make menuconfig
</Para>
</ListItem>
<ListItem>

<Para>
Escoja «Networking Options»
</Para>
</ListItem>
<ListItem>

<Para>
Marque «The IPv6 protocol», «IPv6: enable EUI-64 token format», «IPv6:
disable provider based addresses»
</Para>
</ListItem>

</ItemizedList>

CONSEJO: No use la opción de módulo. A menudo no funciona bien.
</Para>

<Para>
En otras palabras, compile IPv6 dentro del núcleo.
Una vez hecho esto, guarde su configuración y compile el núcleo.
</Para>

<Para>
CONSEJO: Antes de hacerlo, considere la posibilidad de editar el Makefile:
EXTRAVERSION = -x ; --&#62; ; EXTRAVERSION = -x-IPv6
</Para>

<Para>
Hay un montón de documentación sobre cómo compilar e instalar un núcleo,
sin embargo este documento se refiere a otras cosas. Si tiene problemas en
esta etapa, vaya a buscar algo de documentación sobre la compilación del
núcleo de acuerdo con sus propias especificaciones.
</Para>

<Para>
El fichero /usr/src/linux/README podría ser un buen sitio donde empezar.
Tras haber hecho todo esto, y reiniciado con su nuevo núcleo, puede que
quiera ejecutar "/sbin/ifconfig -a" y ver el nuevo "sit0-device". SIT
significa Simple Internet Transition. Puede felicitarse a sí mismo; ahora
está un paso más cerca de IP, la Próxima Generación ;-)
</Para>

<Para>
Ahora vamos con el siguiente paso. Quiere conectar su máquina, o incluso
su LAN entera a otras redes que puedan trabajar con IPv6. Puede ser la
«6bone», que está configurada especialmente para este propósito particular.
</Para>

<Para>
Asumamos que tiene la siguiente red IPv6: 3ffe:604:6:8::/64 y que quiere
conectar con la 6bone, o con un amigo. Fíjese que la notación /64 de
subred funciona igual que con cualquier dirección IP normal.
</Para>

<Para>
Su dirección IPv4 es 145.100.24.181 y el router de 6bone tiene la
dirección IPv4 145.100.1.5
</Para>

<Screen width="80">
# ip tunnel add sixbone mode sit remote 145.100.1.5 [local 145.100.24.181 ttl 255]
# ip link set sixbone up
# ip addr add 3FFE:604:6:7::2/126 dev sixbone
# ip route add 3ffe::0/16 dev sixbone
</Screen>

<Para>
Comentemos esto. En la primera línea, hemos creado un dispositivo de túnel
llamado sixbone. Le hemos dado el modo sit (que es tunelizado IPv6 sobre
IPv4) y le hemos dicho dónde debe ir (remote) y de dónde viene (local). El
TTL se establece al máximo, 255.
</Para>

<Para>
Después activamos el dispositivo (up). Tras esto, añadimos nuestra propia
dirección de red, y establecemos una ruta para 3ffe::/15 (que actualmente
es la totalidad de la 6bone) a través del túnel. Si la máquina en la que
trabaja es su pasarela IPv6, quizá le interesa añadir estas líneas:
</Para>

<Screen width="80">
# echo 1 &#62;/proc/sys/net/ipv6/conf/all/forwarding
# /usr/local/sbin/radvd
</Screen>

<Para>
En la última arrancamos radvd, que es (como zebra) un demonio anunciador
de rutas, para dar soporte a las capacidades de autoconfiguración de IPv6.
Búsquelo en su motor de búsqueda favorito si lo desea.
Puede comprobar las cosas así:
</Para>

<Screen width="80">
# /sbin/ip -f inet6 addr
</Screen>

<Para>
Si tiene radvd ejecutándose en la pasarela IPv6 y arranca una máquina
Linux con capacidades IPv6 en su LAN, podrá disfrutar de los beneficios de
la autoconfiguración de IPv6:
</Para>

<Screen width="80">
# /sbin/ip -f inet6 addr
1: lo: &lt;LOOPBACK,UP&gt; mtu 3924 qdisc noqueue inet6 ::1/128 scope host

3: eth0: &lt;BROADCAST,MULTICAST,UP&gt; mtu 1500 qdisc pfifo_fast qlen 100
inet6 3ffe:604:6:8:5054:4cff:fe01:e3d6/64 scope global dynamic
valid_lft forever preferred_lft 604646sec inet6 fe80::5054:4cff:fe01:e3d6/10 
scope link
</Screen>

<Para>
Podría ir más allá y configurar el programa bind para que trabaje con
direcciones IPv6. El tipo A tiene un equivalente para IPv6: AAAA. El
equivalente de in-addr.arpa es: ip6.int. Hay mucha información disponible
sobre este tema.
</Para>

<Para>
Hay disponible un número creciente de aplicaciones que pueden trabajar con
IPv6, incluyendo secure shell, telnet, inetd, el navegador Mozilla, el
servidor web Apache y muchos otros. Pero se sale del ámbito de este
documento sobre Rutado ;-)
</Para>

<Para>
Por el lado del Cisco la configuración debería parecerse a esto:

<Screen>
!
interface Tunnel1
description IPv6 tunnel
no ip address
no ip directed-broadcast
ipv6 address 3FFE:604:6:7::1/126
tunnel source Serial0
tunnel destination 145.100.24.181
tunnel mode ipv6ip
!
ipv6 route 3FFE:604:6:8::/64 Tunnel1
</Screen>

Pero si no tiene un Cisco a su disposición, pruebe uno de los muchos
proveedores de túneles IPv6 disponibles en Internet. Están deseando
configurar su Cisco con un túnel extra para usted. La mayoría lo hacen
mediante una interfaz web amigable. Busque «ipv6 tunnel broker» en su
buscador favorito.
</Para>

</Sect1>

</chapter>

  <chapter id="lartc.ipsec">
    <Title>IPsec: IP segura sobre Internet</Title>

    <Para>
      Hoy día hay dos tipos de IPSEC disponibles para Linux. Para 2.2 y
      2.4, existe FreeS/WAN, que es la primera gran implementación. Tienen 
      <ULink URL="http://www.freeswan.org/">un sitio oficial</ulink> y
      se mantiene <ulink url="http://www.freeswan.ca">otro no
      oficial</ulink>. Tradicionalmente, no se ha juntado FreeS/WAN con el
      núcleo principal por varias razones. Las mencionadas más a menudo
      son problemas "políticos" por la posibilidad de que habiendo
      americanos (de EEUU) trabajando en cifrado, pueda comprometerse su
      exportabilidad. Más aún, no se integra muy bien con el núcleo de
      Linux, lo que le hace mal candidato para una fusión.
    </para>
    <para>
      Además, <ulink
url="http://www.edlug.ed.ac.uk/archive/Sep2002/msg00244.html">muchas</ulink>
      personas <ulink
url="http://lists.freeswan.org/pipermail/design/2002-November/003901.html">han
      expresado sus reservas</ulink> sobre la calidad del código. Para
      configurar FreeS/WAN, <ulink
      url="http://www.freeswan.org/doc.html">dispone</ulink> de un montón
      de <ulink
url="http://www.freeswan.ca/docs/freeswan-1.99/doc/index.html">documentación</ulink>.
    </para>
    <para>
      Desde Linux 2.5.47, hay una implementación nativa de IPSEC en el
      núcleo. Fue escrita por Alexey Kuznetsov y Dave Miller, inspirados
      por el trabajo del grupo USAGI IPv6. Con su inclusión en el núcleo,
      también se integró la CryptoAPI de James Morris (que hace la parte
      de cifrado).
    </para>
    <para>
      Este COMO sólo documentará la versión 2.5+ de IPSEC. Recomendamos
      FreeS/WAN por ahora para los usuarios de Linux 2.4, pero tenga en
      cuenta que su configuración difiere de la de IPSEC nativo.
      Relacionado con esto, ahora existen <ulink
      url="http://gondor.apana.org.au/~herbert/freeswan/">parches</ulink>
      para hacer que el código de espacio de usuario de FreeS/WAN funcione
      con el IPSEC nativo de Linux.
    </para>
    <para>
	Desde 2.5.49, IPSEC funciona sin necesidad de parches.
	</para>
	<para>
      <note>
	<para>
	  Parece que hay herramientas disponibles <ulink
	  url="http://sourceforge.net/projects/ipsec-tools">aquí</ulink>.
	  Se dispone de varios programas, siendo el que enlazamos basado
	  en Racoon.
	</para>
	<para>
	Cuando compile el núcleo, asegúrese de activar "PF_KEY", "AH",
	"ESP" y ¡todo lo que hay en CryptoAPI!
	</para>
      </note>
      <warning>
	<para>
	  ¡El autor de este capítulo es un completo incompetente con
	  IPSEC! Si encuentra los inevitables errores, por favor
	  coménteselo a bert hubert <email>ahu@ds9a.nl</email>.
	</para>
      </warning>
    </Para>
    <para>
      Primero, vamos a mostrar cómo establecer de forma manual
      comunicación segura entre dos máquinas. Gran parte de este proceso
      se puede automatizar, pero veremos cómo hacerlo a mano para
      familiarizarnos con lo que pasa "entre bambalinas".
    </para>
    <para>
	Puede saltarse la siguiente sección si sólo está interesado en el
	intercambio automático de claves (automatic keying), pero tenga en
	cuenta que tener conocimientos sobre el intercambio manual es
	útil.
    </para>
    <sect1 id="lartc.ipsec.intro"><title>Introducción al intercambio manual de claves</title>
      <para>
	IPSEC es un tema complicado. Hay mucha información en la red, pero
	este COMO se concentrará en enseñarle a ponerlo a funcionar y
	explicar los principios básicos. Todos los ejemplos están basados
	en Racoon, que encontrará en el enlace anterior.
      </para>
      <para>
	<note>
	  <para>
	    ¡Muchas configuraciones de iptables eliminan paquetes de
	    IPSEC! Para dejar pasar IPSEC, use: "iptables -A xxx -p 50 -j
	    ACCEPT" e "iptables -A xxx -p 51 -j ACCEPT"
	  </para>
	</note>
      </para>
      <para>
	IPSEC ofrece una versión segura del Internet Protocol. La
	seguridad en este contexto significa dos cosas diferentes: cifrado
	y autentificación.
	Una visión inocente de la seguridad ofrece sólo cifrado, pero es
	sencillo demostrar que esto es insuficiente: puedes estar
	comunicándote de forma cifrada, pero no hay garantías de que en el
	otro extremo esté quien tú esperas.
      </para>
      <para>
	IPSEC admite "Encapsulated Security Payload" (ESP) para el cifrado
	y "Authentication Header" (AH) para autentificar al otro extremo.
	Puede configurarlos ambos, o decidir usar sólo uno.
      </para>
      <para>
	Tanto ESP como AH dependen de asociaciones de seguridad (security
	associations). Una asociación de seguridad (SA) consiste en
	origen, destino y una instrucción. Un ejemplo de autentificación
	por SA podría ser así:
	<screen>
	  add 10.0.0.11 10.0.0.216 ah 15700 -A hmac-md5 "1234567890123456";
	</screen>
	Esto significa «el tráfico que va de 10.0.0.11 a 10.0.0.216 que
	necesita AH puede ser firmado usando HMAC-MD5 usando la clave
	1234567890123456». Esta instrucción va etiquetada con el
	identificador SPI ("Security Parameter Index") "15700", hablaremos
	de ello más adelante. La parte interesante sobre los SA es que son
	simétricos. Ambos extremos de una conversación comparten
	exactamente el mismo SA; en el otro extremo no encontraremos una
	copia especular. Tenga en cuenta sin embargo que no hay una regla
	"autoreverse": esta SA sólo describe una autentificación posible
	desde 10.0.0.11 a 10.0.0.216. Para tener tráfico en las dos
	direcciones, hacen falta dos SA.
      </para>
      <para>
	Un ejemplo de SA ESP:
	<screen>
add 10.0.0.11 10.0.0.216 esp 15701 -E 3des-cbc "123456789012123456789012";
	</screen>
	Aquí dice que «el tráfico que va de 10.0.0.11 a 10.0.0.216 que
	necesita cifrado puede serlo usando 3des-cbc con la clave
	123456789012123456789012». El identificador SPI es "15701".
      </para>
      <para>
	Hasta ahora, hemos visto que las SA describen instrucciones
	posibles, pero en realidad no describen normas sobre cuándo se
	deben usar. En realidad, podría haber un número arbitrario de SA
	idénticas que sólo difiriesen en sus id SPI. Casualmente, SPI
	significa Security Parameter Index. Para hacer cifrado realmente,
	necesitamos describir una norma (policy). Esta norma puede incluir
	cosas como «usa ipsec si está disponible» o «corta el tráfico a
	menos que haya ipsec».
      </para>
      <para>
	Una Security Policy (SP) típica podría parecerse a esto:
	<screen>
spdadd 10.0.0.216 10.0.0.11 any -P out ipsec
   esp/transport//require
   ah/transport//require;
	</screen>
	Si se introduce en el sistema 10.0.0.216, esto quiere decir que
	todo el tráfico que vaya hacia 10.0.0.11 debe ir cifrado y
	encapsulado en una cabecera de autentificación AH. Fíjese que no
	se indica qué SA ha de usarse; determinar esto se deja como
	ejercicio para el núcleo.
      </para>
	<para>
	En otras palabras, una Security Policy (norma de seguridad)
	especifica QUE queremos; mientras que una Security Association
	describe COMO lo queremos.
</para>
      <para>
	Los paquetes salientes son etiquetados con el SA SPI ("el cómo")
	que el núcleo use para cifrado y autentificación, de manera que el
	otro extremo pueda buscar la instrucción de verificación y
	decodificación correspondiente.
      </para>
      <para>
	Lo que sigue es una configuración muy simple para hablar desde la
	máquina 10.0.0.216 con la 10.0.0.11 usando cifrado y
	autentificación. Fíjese que el camino inverso (reverse path) es
	texto plano en esta primera versión, de manera que no debería usar
	esta configuración en producción.
      </para>
      <para>
	En la máquina 10.0.0.216:
	<screen>
#!/sbin/setkey -f
add 10.0.0.216 10.0.0.11 ah 24500 -A hmac-md5 "1234567890123456";
add 10.0.0.216 10.0.0.11 esp 24501 -E 3des-cbc "123456789012123456789012";

spdadd 10.0.0.216 10.0.0.11 any -P out ipsec
   esp/transport//require
   ah/transport//require;
	</screen>
      </para>
      <para>
	En la máquina 10.0.0.11, las mismas Security Association, sin
	Security Policy:
	<screen>
#!/sbin/setkey -f
add 10.0.0.216 10.0.0.11 ah 24500 -A hmac-md5 "1234567890123456";
add 10.0.0.216 10.0.0.11 esp 24501 -E 3des-cbc "123456789012123456789012";
	</screen>
      </para>
      <para>
	Con esta configuración (puede ejecutar los ficheros si tiene
	"setkey" en /sbin), "ping 10.0.0.11" desde 10.0.0.216 debería dar
	resultados similares a este usando tcpdump:
	<screen>
22:37:52 10.0.0.216 &gt; 10.0.0.11: AH(spi=0x00005fb4,seq=0xa): ESP(spi=0x00005fb5,seq=0xa) (DF)
22:37:52 10.0.0.11 &gt; 10.0.0.216: icmp: echo reply
	</screen>
	Fíjese en cómo el ping que vuelve de 10.0.0.11 es de hecho visible
	claramente. El ping inicial no lo puede leer tcpdump por supuesto,
	pero muestra el Security Parameter Index de AH y ESP, que le dice
	a 10.0.0.11 cómo verificar la autenticidad de nuestro paquete y
	cómo descrifrarlo.
      </para>
      <para>
	De todas maneras, hay que mencionar algunas cosas. La
	configuración anterior aparece en muchos ejemplos de IPSEC y es
	muy peligrosa. El problema es que lo anterior contiene normas
	sobre cómo debería tratar 10.0.0.216 los paquetes que van a
	10.0.0.11, y explica cómo debería tratar 10.0.0.11 estos paquetes,
	¡pero NO indica a 10.0.0.11 que descarte tráfico sin autentificar
	o cifrar!
      </para>
      <para>
	Cualquiera puede ahora insertar datos falsos y completamente sin
	cifrar y 10.0.0.11 los aceptará. Para remediarlo, necesitamos una
	norma de tráfico entrante para 10.0.0.11, como sigue:
	<screen>
#!/sbin/setkey -f
spdadd 10.0.0.216 10.0.0.11 any -P IN ipsec
   esp/transport//require
   ah/transport//require;
	</screen>
	Esto le dice a 10.0.0.11 que cualquier tráfico que venga de
	10.0.0.216 debe tener ESP y AH válidos.
      </para>
      <para>
	Ahora, para completar esta configuración, necesitamos que el
	tráfico devuelto sea también cifrado y autentificado, por
	supuesto. La configuración completa en 10.0.0.216:
	<screen>
#!/sbin/setkey -f
flush;
spdflush;

# AH
add 10.0.0.11 10.0.0.216 ah 15700 -A hmac-md5 "1234567890123456";
add 10.0.0.216 10.0.0.11 ah 24500 -A hmac-md5 "1234567890123456";

# ESP
add 10.0.0.11 10.0.0.216 esp 15701 -E 3des-cbc "123456789012123456789012";
add 10.0.0.216 10.0.0.11 esp 24501 -E 3des-cbc "123456789012123456789012";

spdadd 10.0.0.216 10.0.0.11 any -P out ipsec
           esp/transport//require
           ah/transport//require;

spdadd 10.0.0.11 10.0.0.216 any -P in ipsec
           esp/transport//require
           ah/transport//require;

	</screen>
      </para>
      <para>
	Y en 10.0.0.11:
	<screen>
#!/sbin/setkey -f
flush;
spdflush;

# AH
add 10.0.0.11 10.0.0.216 ah 15700 -A hmac-md5 "1234567890123456";
add 10.0.0.216 10.0.0.11 ah 24500 -A hmac-md5 "1234567890123456";

# ESP
add 10.0.0.11 10.0.0.216 esp 15701 -E 3des-cbc "123456789012123456789012";
add 10.0.0.216 10.0.0.11 esp 24501 -E 3des-cbc "123456789012123456789012";


spdadd 10.0.0.11 10.0.0.216 any -P out ipsec
           esp/transport//require
           ah/transport//require;

spdadd 10.0.0.216 10.0.0.11 any -P in ipsec
           esp/transport//require
           ah/transport//require;

	</screen>
      </para>
      <para>
	Fíjese que en este ejemplo hemos usado claves idénticas para ambas
	direcciones de tráfico. Sin embargo, esto no es necesario.
      </para>
      <para>
	Para comprobar la configuración que hemos creado, ejecute
	<command>setkey -D</command>, que muestra las asociaciones de
	seguridad, o <command>setkey -DP</command> que muestra las normas
	configuradas.
      </para>
    </sect1>
    <sect1 id="lartc.ipsec.automatic.keying"><title>Intercambio automático de claves</title>
      <para>
	En la sección anterior configuramos el cifrado usando secretos
	compartidos (claves compartidas) sencillos. En otras palabras, para
	mantenernos seguros, necesitamos transferir nuestra configuración
	de cifrado sobre un canal del que nos fiemos. Si fuéramos a
	configurar el otro extremo con telnet, cualquier tercero podría
	conocer nuestro secreto compartido y la configuración no sería
	segura.
      </para>
      <para>
	Más aún, como nuestro secreto está compartido, ya no es secreto.
	El extremo remoto puede hacer poco con nuestra clave, pero
	necesitamos estar seguros de que usamos una clave diferente para
	comunicarnos con todos nuestros colaboradores. Esto precisa un
	gran número de claves: si hay 10 partes involucradas, necesitamos
	al menos 50 claves diferentes.
      </para>
      <para>
	Aparte del problema de la clave simétrica, también hay necesidad
	de renovar la clave. Si un tercero consigue capturar suficiente
	tráfico, podría estar en situación de obtener la clave por
	ingeniería inversa. Esto se previente pasando a nuevas claves de
	vez en cuándo, pero es un proceso que necesita ser automatizado.
      </para>
      <para>
	Otro problema es que con las claves manuales descritas
	anteriormente definimos exactamente los algoritmos y longitud de
	claves a usar, algo que precisa de un montón de coordinación con
	las partes remotas. Es deseable ser capaz de describir una norma
	de claves más amplia, como «podemos usar 3DES y Blowfish con al
	menos las siguientes longitudes de clave».
      </para>
      <para>
	Para resolver estos problemas, IPSEC proporciona Internet Key
	Exchange para intercambiar automáticamente claves generadas al
	azar que se transmiten usando tecnología de de cifrado asimétrico,
	de acuerdo con detalles de algoritmo negociados.
      </para>
      <para>
	La implementación de IPSEC de Linux 2.5 funciona con el demonio
	IKE "racoon" de KAME. Desde el 9 de noviembre, se puede compilar
	la versión de racoon que acompaña a la distribución de iptools de
	Alexey, aunque necesitará eliminar #include &lt;net/route.h&gt; en
	dos ficheros. De forma alternativa, he proporcionado una
<ulink url="http://ds9a.nl/ipsec/racoon.bz2">versión precompilada</ulink>.
      </para>
	<para>
	<note>
	  <para>
		IKE necesita acceso al puerto UDP 500; asegúrese de que
		iptables no lo bloquea.
       	  </para>
	</note>
	</para>
	<sect2 id="lartc.ipsec.keying.theory"><title>Teoría</title>
	<para>
		Como se explicó anteriormente, el intercambio automático
		hace por nosotros un montón de trabajo. Específicamente,
		crea asociaciones de seguridad sobre la marcha. Sin
		embargo, no establece normas por nosotros, que es como
		debe ser.
	</para>
	<para>
	Por tanto, para beneficiarse de IKE, configure una norma, pero no
	proporcione ninguna SA. Si el núcleo descubre que hay una norma
	IPSEC, pero no una asociación de seguridad, se lo dirá al demonio
	IKE, que entonces intentará negociar una.
	</para>
	<para>
	Reiterando, una Security Policy especifica QUE queremos; una
	Security Association describe COMO lo queremos. Usar el
	intercambio automático nos permite abstraernos especificando sólo
	qué queremos.
	</para>
</sect2>
	<sect2
id="lartc.ipsec.automatic.keying.example"><title>Ejemplo</title>
	<para>
	El racoon de Kame viene con una gran cantidad de opciones, la
	mayoría de las cuales tiene valores adecuados por defecto, de
	manera que no necesitamos tocarlos. Como describimos antes, el
	operador necesita definir una norma de seguridad, pero no
	asociaciones de seguridad. Le dejaremos la negociación al demonio
	IKE.
	</para>
	<para>
	En este ejemplo, 10.0.0.11 y 10.0.0.216 van a volver a configurar
	comunicaciones seguras, pero esta vez con la ayuda de racoon. Por
	sencillez esta configuración usará claves pre-compartidas, los
	temidos «secretos compartidos». Los certificados X.509 los
	discutimos en una sección aparte; vea
	<xref linkend="lartc.ipsec.x509">.
</para>
<para> Vamos a ceñirnos a una configuración casi por defecto, idéntica en
ambas máquinas:
	</para>
	<para>
<screen>
path pre_shared_key "/usr/local/etc/racoon/psk.txt";

remote anonymous
{
        exchange_mode aggressive,main;
        doi ipsec_doi;
        situation identity_only;

        my_identifier address;

        lifetime time 2 min;   # sec,min,hour
        initial_contact on;
        proposal_check obey;    # obey, strict or claim

        proposal {
                encryption_algorithm 3des;
                hash_algorithm sha1;
                authentication_method pre_shared_key;
                dh_group 2 ;
        }
}

sainfo anonymous
{
        pfs_group 1;
        lifetime time 2 min;
        encryption_algorithm 3des ;
        authentication_algorithm hmac_sha1;
                compression_algorithm deflate ;
}
</screen>
	</para>
	<para>
	Un montón de configuración (creo que aún podemos eliminar más para
	acercarnos a la configuración por defecto). Pocas cosas a
	resaltar. Hemos preparado dos configuraciones anónimas que sirven
	para todos los extremos remotos, haciendo más sencilla cualquier
	configuración posterior. No hay necesidad de entradas diferentes
	por máquina, a menos que realmente las queramos.
</para>
	<para>
	Más aún, hemos configurado de manera que nos identificamos a
	nosotros mismo basándonos en la dirección IP ("my_identifier
	address"), y declaramos que podemos hacer 3des, sha1, y que
	usaremos una clave pre-compartida (pre-shared), que está en
	psk.txt.
	</para>
	<para>
	Ahora en psk.txt, configuraremos dos entradas, que difieren en
	ambas máquinas.
En 10.0.0.11:
<screen>
10.0.0.216      clave2
</screen>
En 10.0.0.216:
<screen>
10.0.0.11       clave2
</screen>
        Make sure these files are owned by root, and set to mode 0600,
racoon will not trust their contents otherwise. Note that these files are
mirrors from eachother.
	Asegúrese de que estos ficheros pertenecen al root, en modo 0600,
	ya que racoon no confiará en su contenido de otro modo. Fíjese en
	que los ficheros son especulares.
	</para>
	<para>
	Ahora estamos preparados para configurar la norma deseada, que es
	bastante simple. En la máquina 10.0.0.216:
<screen>
#!/sbin/setkey -f
flush;
spdflush;

spdadd 10.0.0.216 10.0.0.11 any -P out ipsec
        esp/transport//require;

spdadd 10.0.0.11 10.0.0.216 any -P in ipsec
        esp/transport//require;
</screen>
Y en 10.0.0.11:
<screen>
#!/sbin/setkey -f
flush;
spdflush;

spdadd 10.0.0.11 10.0.0.216 any -P out ipsec
        esp/transport//require;

spdadd 10.0.0.216 10.0.0.11 any -P in ipsec
        esp/transport//require;
</screen>
Fíjese en que de nuevo estas normas son especulares.
	</para>
	<para>
	¡Ahora estamos listos para lanzar racoon! Una vez lanzado, en el
	momento que hagamos telnet de 10.0.0.11 a 10.0.0.216, o viceversa,
	racoon empezará a negociar:
<screen>
12:18:44: INFO: isakmp.c:1689:isakmp_post_acquire(): IPsec-SA
  request for 10.0.0.11 queued due to no phase1 found.
12:18:44: INFO: isakmp.c:794:isakmp_ph1begin_i(): initiate new
  phase 1 negotiation: 10.0.0.216[500]<=>10.0.0.11[500]
12:18:44: INFO: isakmp.c:799:isakmp_ph1begin_i(): begin Aggressive mode.
12:18:44: INFO: vendorid.c:128:check_vendorid(): received Vendor ID:
  KAME/racoon
12:18:44: NOTIFY: oakley.c:2037:oakley_skeyid(): couldn't find
  the proper pskey, try to get one by the peer's address.
12:18:44: INFO: isakmp.c:2417:log_ph1established(): ISAKMP-SA
  established 10.0.0.216[500]-10.0.0.11[500]
spi:044d25dede78a4d1:ff01e5b4804f0680
12:18:45: INFO: isakmp.c:938:isakmp_ph2begin_i(): initiate new phase 2
  negotiation: 10.0.0.216[0]<=>10.0.0.11[0]
12:18:45: INFO: pfkey.c:1106:pk_recvupdate(): IPsec-SA established:
  ESP/Transport 10.0.0.11->10.0.0.216 spi=44556347(0x2a7e03b)
12:18:45: INFO: pfkey.c:1318:pk_recvadd(): IPsec-SA established:
  ESP/Transport 10.0.0.216->10.0.0.11 spi=15863890(0xf21052)
</screen>
</para>
<para>
	Si ahora ejecutamos setkey -D, que nos muestra las asociaciones de
	seguridad, las encontraremos:
<screen>
10.0.0.216 10.0.0.11
        esp mode=transport spi=224162611(0x0d5c7333) reqid=0(0x00000000)
        E: 3des-cbc  5d421c1b d33b2a9f 4e9055e3 857db9fc 211d9c95 ebaead04
        A: hmac-sha1  c5537d66 f3c5d869 bd736ae2 08d22133 27f7aa99
        seq=0x00000000 replay=4 flags=0x00000000 state=mature
        created: Nov 11 12:28:45 2002   current: Nov 11 12:29:16 2002
        diff: 31(s)     hard: 600(s)    soft: 480(s)
        last: Nov 11 12:29:12 2002      hard: 0(s)      soft: 0(s)
        current: 304(bytes)     hard: 0(bytes)  soft: 0(bytes)
        allocated: 3    hard: 0 soft: 0
        sadb_seq=1 pid=17112 refcnt=0
10.0.0.11 10.0.0.216
        esp mode=transport spi=165123736(0x09d79698) reqid=0(0x00000000)
        E: 3des-cbc  d7af8466 acd4f14c 872c5443 ec45a719 d4b3fde1 8d239d6a
        A: hmac-sha1  41ccc388 4568ac49 19e4e024 628e240c 141ffe2f
        seq=0x00000000 replay=4 flags=0x00000000 state=mature
        created: Nov 11 12:28:45 2002   current: Nov 11 12:29:16 2002
        diff: 31(s)     hard: 600(s)    soft: 480(s)
        last:                           hard: 0(s)      soft: 0(s)
        current: 231(bytes)     hard: 0(bytes)  soft: 0(bytes)
        allocated: 2    hard: 0 soft: 0
        sadb_seq=0 pid=17112 refcnt=0
</screen>
Así como las normas de seguridad que configuramos nosotros mismos:
<screen>
10.0.0.11[any] 10.0.0.216[any] tcp
        in ipsec
        esp/transport//require
        created:Nov 11 12:28:28 2002 lastused:Nov 11 12:29:12 2002
        lifetime:0(s) validtime:0(s)
        spid=3616 seq=5 pid=17134
        refcnt=3
10.0.0.216[any] 10.0.0.11[any] tcp
        out ipsec
        esp/transport//require
        created:Nov 11 12:28:28 2002 lastused:Nov 11 12:28:44 2002
        lifetime:0(s) validtime:0(s)
        spid=3609 seq=4 pid=17134
        refcnt=3
</screen>
</para>
	<sect3><title>Problemas y defectos conocidos</title>
	<para>
		Si esto no funciona, compruebe que todos los ficheros de
		configuración pertenecen a root, y que sólo pueden ser
		leídos por root. Para arrancar racoon en primer plano, use
		"-F". Para forzarlo a leer determinado fichero de
		configuración, en lugar del especificado al compilar, use
		"-f". Si quiere una cantidad abusiva de detalles, añada
		la sentencia "log debug;" a racoon.conf.
	</para>
	</sect3>
	</sect2>
	<sect2 id="lartc.ipsec.x509"><title>Uso de certificados X.509 para el intercambio automático de claves</title>
	<para>
        As mentioned before, the use of shared secrets is hard because
they
aren't easily shared and once shared, are no longer secret. Luckily, there
is asymmetric encryption technology to help resolve this.
	Como mencionamos antes, el uso de secretos compartidos es difícil
	porque no son fáciles de compartir, y una vez compartidos, dejan
	de ser secretos. Por suerte, hay tecnología de cifrado asimétrico
	que nos ayuda a resolver esto.
	</para>
	<para>
	Si cada participante en IPSEC crea claves pública y privada, se
	puede configurar comunicaciones seguras entre ambas partes
	publicando sus claves públicas y normativa de configuración.
	</para>
	<para>
	Crear una clave es relativamente sencillo, aunque requiere algo de
	trabajo. Lo que sigue se basa en la herramienta "openssl".
	</para>
	<sect3><title>Crear un certificado X.509 para su máquina</title>
	<para>
	OpenSSL cuenta con mucha infraestructura para claves que pueden
	ser o no firmadas por autoridades de certificación. Ahora mismo,
	nos saltaremos toda la infraestructura y practicaremos un poco de
	la vieja seguridad de Snake Oil, y lo haremos sin un certificado
	autorizado.
	</para>
	<para>
	Primero emitiremos una "petición de certificado" para nuestra
	máquina, llamada "laptop":
<screen>
$ openssl req -new -nodes -newkey rsa:1024 -sha1 -keyform PEM -keyout \
  laptop.private -outform PEM -out request.pem
</screen>
Esto nos hace algunas preguntas:
<screen>
Country Name (2 letter code) [AU]:NL
State or Province Name (full name) [Some-State]:.
Locality Name (eg, city) []:Delft
Organization Name (eg, company) [Internet Widgits Pty Ltd]:Linux Advanced
Routing & Traffic Control
Organizational Unit Name (eg, section) []:laptop
Common Name (eg, YOUR name) []:bert hubert
Email Address []:ahu@ds9a.nl

Please enter the following 'extra' attributes
to be sent with your certificate request
A challenge password []:
An optional company name []:
</screen>
	Dejamos a su discreción la forma la completitud con que quiera
	rellenar esto. Puede o no querer poner ahí el nombre de la
	máquina, dependiendo en sus necesidades de seguridad. En este
	ejemplo, lo hemos hecho.
</para>
	<para>
	Ahora "autofirmaremos" esta petición:
<screen>
$ openssl x509 -req -in request.pem -signkey laptop.private -out \
  laptop.public
Signature ok
subject=/C=NL/L=Delft/O=Linux Advanced Routing &amp; Traffic \
  Control/OU=laptop/CN=bert hubert/Email=ahu@ds9a.nl
Getting Private key
</screen>
	Ahora podemos descartar el fichero "request.pem".
	</para>
	<para>
	Repita este procedimiento con todas las máquinas para las que
	necesite una clave. Puede distribuir el fichero ".public" con
	impunidad, ¡pero esconda el fichero ".private"!
	</para>
	</sect3>
	<sect3><title>Configuración y puesta en marcha</title>
	<para>
	Una vez tenermos un par de claves pública y privada para nuestras
	máquinas podemos decirle a racoon que las use.
	</para>
	<para>
	Volvemos a nuestra configuración anterior y las dos máquinas,
	10.0.0.11 ("upstairs") y 10.0.0.216 ("laptop")
	</para>
	<para>
	Añadimos al fichero <filename>racoon.conf</filename> de 10.0.0.11:
<screen>
path certificate "/usr/local/etc/racoon/certs";

remote 10.0.0.216
{
        exchange_mode aggressive,main;
        my_identifier asn1dn;
        peers_identifier asn1dn;

        certificate_type x509 "upstairs.public" "upstairs.private";

        peers_certfile "laptop.public";
        proposal {
                encryption_algorithm 3des;
                hash_algorithm sha1;
                authentication_method rsasig;
                dh_group 2 ;
        }
}
</screen>
	Esto le dice a racoon que los certificados los encontrará en
	<filename>/usr/local/etc/racoon/certs/</filename>. Más aún,
	contiene elementos de configuración específicos para el extremo
	10.0.0.216.
	</para>
	<para>
	Las líneas "asn1dn" le dicen a racoon que el identificador de los
	extremos tanto local como remoto serán extraídos de las claves
	públicas. Estos son los "subject=/C=NL/L=Delft/O=Linux Advanced
	Routing &amp; Traffic Control/OU=laptop/CN=bert
	hubert/Email=ahu@ds9a.nl" que vimos en la salida anterior.
	</para>
	<para>
	La línea <command>certificate_type</command> configura las claves
	pública y privada. La orden <command>peers_certfile</command>
	configura racoon para que lea la clave pública del extremo remoto
	del fichero <filename>laptop.public</filename>.
	</para>
	<para>
	La entrada <command>proposal</command> no ha cambiado con respecto
	a lo que vimos antes, con la excepción de que
	<command>authentication_method</command> ahora es
	<command>rsasig</command>, indicando el uso de claves RSA
	pública/privada para la autentificación.
	</para>
	<para>
	El añadido a la configuración de 10.0.0.216 es casi idéntico,
	excepto por su naturaleza especular habitual:
<screen>
path certificate "/usr/local/etc/racoon/certs";

remote 10.0.0.11
{
        exchange_mode aggressive,main;
        my_identifier asn1dn;
        peers_identifier asn1dn;

        certificate_type x509 "laptop.public" "laptop.private";

        peers_certfile "upstairs.public";

        proposal {
                encryption_algorithm 3des;
                hash_algorithm sha1;
                authentication_method rsasig;
                dh_group 2 ;
        }
}
</screen>
</para>
	<para>
	Ahora que hemos definido estas sentencias en ambas máquinas, sólo
	necesitamos poner en su sitio los ficheros de claves. La máquina
	"upstairs" necesita tener <filename>upstairs.private</filename>,
	<filename>upstairs.public</filename>, y
	<filename>laptop.public</filename> en
	<filename>/usr/local/etc/racoon/certs</filename>. Asegúrese de que
	este directorio pertenece a root y tiene modo 0700, ¡o racoon
	rechazará leerlo!
</para>
<para>
La máquina "laptop" necesita tener <filename>laptop.private</filename>,
<filename>laptop.public</filename>, y <filename>upstairs.public</filename>
en <filename>/usr/local/etc/racoon/certs</filename>. En otras palabras,
cada máquina necesita sus propias claves pública y privada y además, la
clave pública de la remota.
</para>
<para>
	Verifique que existe una Security Policy (ejecute las líneas
	"spdadd" que hay en <xref
	linkend="lartc.ipsec.automatic.keying.example">).
	Entonces lance racoon y todo debería funcionar.
</para>
	</sect3>
	<sect3><title>Cómo configurar túneles de forma segura</title>
	<para>
        To setup secure communications with a remote party, we must
exchange
public keys. While the public key does not need to be kept a secret, on
the
contrary, it is very important to be sure that it is in fact the unaltered
key. In other words, you need to be certain there is no 'man in the
middle'.
	Para configurar comunicaciones seguras con un extremo remoto,
	debemos intercambiar claves públicas. Mientras no hace falta
	mantener en secreto la clave pública, sino al contrario, es muy
	importante asegurarse de que en realidad es la clave sin
	alteraciones. En otras palabras, debe tener la certeza de que no
	hay un "hombre en medio"<footnote><para>N. del T.: "man in the
	middle", un tipo de ataque</para></footnote>
	</para>
	<para>
Para facilitarlo, OpenSSL proporciona la orden "digest":
<screen>
$ openssl dgst upstairs.public
MD5(upstairs.public)= 78a3bddafb4d681c1ca8ed4d23da4ff1
</screen>
</para>
	<para>
	Ahora, todo lo que necesitamos hacer es comprobar si el otro
	participante ve el mismo "digest". Esto se puede hacer
	encontrándose en la vida real, o quizá por teléfono, ¡asegurándose
	de que el número del otro no se envió en el mismo mensaje que
	contenía la clave!
	</para>
	<para>
	Otra manera de hacer esto es usar una Trusted Third Party (un
	tercero de confianza) que tenga una Certificate Authority
	(autoridad certificadore). Esta CA firmaría nuestra clave, la que
	hicimos anteriomente.
	</para>

	</sect3>
    </sect2>

    </sect1>
    <sect1 id="lartc.ipsec.tunnel"><title>Túneles con IPSEC</title>
      <para>
	Hasta ahora, sólo hemos visto IPSEC en el modo llamado de
	"transporte", donde ambos puntos entienden directamente IPSEC.
	Como este no suele ser el caso, es necesario que sólo los routers
	entiendan IPSEC, y que hagan el trabajo para las otras máquinas
	tras ellos. A esto se llama "modo túnel".
      </para>
      <para>
	Configurar esto es facilísimo. Para meter en un túnel todo el
	tráfico de 130.161.0.0/16 a 10.0.0.216 pasando por 10.0.0.11,
	hacemos lo siguiente en 10.0.0.216:
<screen>
#!/sbin/setkey -f
flush;
spdflush;

add 10.0.0.216 10.0.0.11 esp 34501
        -m tunnel
        -E 3des-cbc "123456789012123456789012";

spdadd 10.0.0.0/24 130.161.0.0/16 any -P out ipsec
           esp/tunnel/10.0.0.216-10.0.0.11/require;
</screen>
	Fíjese en el "-m tunnel", ¡es de vital importancia! Esto configura
	una SA de cifrado ESP entre los extremos del túnel, 10.0.0.216 y
	10.0.0.11.
      </para>
      <para>
	Lo siguiente es configurar el túnel en sí. Se instruye al núcleo
	para que cifre todo el tráfico que tiene que encaminar desde
	10.0.0.0/24 a 130.161.0.0. Más aún, este tráfico tiene que ser
	enviado a 10.0.0.11.
      </para>
      <para>
	10.0.0.11 también necesita algo de configuración:
<screen>
#!/sbin/setkey -f
flush;
spdflush;

add 10.0.0.216 10.0.0.11 esp 34501
        -m tunnel
        -E 3des-cbc "123456789012123456789012";

spdadd 10.0.0.0/24 130.161.0.0/16 any -P in ipsec
           esp/tunnel/10.0.0.216-10.0.0.11/require;
</screen>
	Fíjese en que es exactamente idéntico, excepto por el cambio de
	"-P out" a "-P in". Igual que con los ejemplos anteriores, ahora
	sólo hemos configurado el tráfico en una dirección. Completar la
	otra parte del túnel se deja como ejercicio al lector.
      </para>
      <para>
	Otro nombre para esta configuración es "proxy ESP", que es algo
	más claro.
      </para>
      <para>
	<note>
	  <para>
	    ¡El túnel IPSEC necesita tener activo IP Forwarding en el
	    núcleo!
	  </para>
	</note>
      </para>
    </sect1>
    <sect1 id="lartc.ipsec.other"><title>Otro software IPSEC</title>
      <para>
	Thomas Walpuski informa que ha escrito un parche para hacer que el
	isakpmd de OpenBSD funcione con el IPSEC de Linux 2.5. Es más, ¡el
	repositorio principal de CVS de isakpmd ahora contiene este
	código! Tiene algunas notas <ulink
	url="http://bender.thinknerd.de/~thomas/IPsec/isakmpd-linux.html">en
	su página</ulink>.
      </para>
      <para>

	isakpmd es bastante diferente del racoon mencionado anteriormente,
	pero a mucha gente le gusta. Podrá encontrarlo <ulink
url="http://www.openbsd.org/cgi-bin/cvsweb/src/sbin/isakmpd/">aquí</ulink>.
	Le más sobre el CVS de OpenBSD <ulink
url="http://www.openbsd.org/anoncvs.html">aquí</ulink>. Thomas también ha
	puest un <ulink
url="http://bender.thinknerd.de/~thomas/IPsec/isakmpd.tgz">fichero
	tar</ulink> a disposición de aquellos que no se sientan cómodos
	con CVS o patch.

      </para>
	<para>
	Más aún, hay parches para hacer que las herramientas de usuario de
	FreeS/WAN trabajen con el IPSEC nativo de Linux 2.5, y podrá
	encontrarlos <ulink
	url="http://gondor.apana.org.au/~herbert/freeswan/">aquí</ulink>.
    </sect1>
    <sect1 id="lartc.ipsec.interop"><title>Interoperación de IPSEC con otros sistemas</title>
      <para>
	FIXME: Escribir esto
      </para>
      <sect2 id="lartc.ipsec.interop.win32"><title>Windows</title>
	<para>
	Andreas Jellinghaus &lt;aj@dungeon.inka.de&gt; informa: "win2k:
	funciona. clave pre_compartida usando la dirección ip para
	autentificación (no pienso que windows soporte cadenas fqdn o
	userfqdn). También deberían funcionar los certificados, pero no lo
	he probado.".

	</para>
      </sect2>
    </sect1>

  </chapter>

<chapter id="lartc.multicast">
<Title>Enrutado multicast</Title>

<Para>
FIXME: ¡Sin editor!
</Para>

<Para>
El Multicast-HOWTO es antiguo (relativamente hablando) y por esa razón
podría ser poco preciso o incluso una mala guía en algunos puntos.
</Para>

<Para>
Antes de que pueda encaminar tráfico multicast, necesita configurar el
núcleo Linux para que admita el tipo de enrutado multicast que desea.
Para esto, a su vez, se necesita que decida qué tipo de encaminamiento
multicast espera usar. Esencialmente hay cuatro tipos "comunes": DVMRP (la
versión Multicast del protocolo RIP unicas), MOSPF (lo mismo pero para
OSPF), PIM-SM ("Protocol Independent Multicasting - Sparse Mode", que
asume que los usuarios de cualquier grupo multicast están esparcidos, en
lugar de concentrados), y PIM-DM (lo mismo, pero en "Modo Denso", que
asume que hay concentraciones significativas de usuarios en el mismo grupo
multicast).
</Para>

<Para>
En el núcleo Linux, verá que no aparecen estas opciones. Esto es debido a
que el protocolo en sí lo controla una aplicación de enrutado, como Zebra,
mrouted o pimd. Sin embargo, aún así hace falta que tenga una buena idea
de lo que va a usar, para escoger las opciones adecuadas en el núcleo.
</Para>

<Para>
Para todo el encaminamiento multicasat, definitivamente necesitará activar
«multicasting» y «multicast routing». Esto es suficiente para DVMRP y
MOSPF. Si va a usar PIM, también debe activar PIMv1 o PIMv2, dependiendo
de si el tipo de red al que conecta usa la versión 1 o la 2 del protocolo
PIM.
</Para>

<Para>
Una vez tenga preparado todo lo que necesita, y tenga el núcleo de Linux
compilado, podrá ver que los protocolos IP que se listan durante el
arranque ahora incluyen IGMP. Este protocolo sirve para gestionar grupos
multicast. En el momento de escribir esto, Linux admite sólo las versiones
1 y 2 de IGMP, aunque existe la versión 3 y ha sido documentada. Esto en
realidad no nos afecta mucho, ya que IGMPv3 todavía es demasiado nueva
como para que sus capacidades extra vayan a ser muy útiles. Como IGMP
trata con grpos, sólo vamos a usar las características presentes en la
versión más sencilla de IGMP sobre grupos enteros. En la mayoría de los
casos encontrará IGMPv2, aunque todavía se usa mucho IGMPv1.
</Para>

<Para>
Seguimos. Hemos activado multicasting. Ahora, tenemos que decirle al
núcleo de Linux que haga algo con él, para poder empezar a encaminar. Esto
significa añadir la red virtual Multicast a la tabla del router:
</Para>

<Para>
ip route add 224.0.0.0/4 dev eth0
</Para>

<Para>
(¡Asumiendo, por supuesto, que está haciendo multicast sobre eth0!
Sustituya el dispositivo por el que haya escogido.)
</Para>

<Para>
Ahora, dígale a Linux que reenvíe paquetes...
</Para>

<Para>
echo 1 &#62; /proc/sys/net/ipv4/ip_forward
</Para>

<Para>
En este momento, puede que se esté preguntando si con esto llegará a hacer
algo en algún momento. Por tanto, para probar nuestra conexión, haremos
ping al grupo por defecto, 224.0.0.1, para ver si alguien está vivo. Todas
las máquinas de su LAN con el multicast activo
<Emphasis>deberían</Emphasis> responder, pero nadie más. Comprobará que
ninguna de las máquinas que responden tiene la dirección IP 224.0.0.1.
¡Qué sorpresa! Esta es una dirección de grupo («difusión» o «broadcast»
para suscriptores), y todos los miembros del grupo responderán con su
propia dirección, no con la dirección de grupo.
</Para>

<Para>
ping -c 2 224.0.0.1
</Para>

<Para>
En este momento, estamos preparados para hacer el verdadero encaminamiento
de multicast. Bueno, eso asumiendo que tenga dos redes entre las que crear
la ruta.
</Para>

<Para>
(¡Continuará!)
</Para>

</chapter>

<chapter id="lartc.qdisc">
<Title>Disciplinas de colas (qdiscs) para gestión del ancho de banda</Title>

<Para>
Cuando descubrí esto, <Emphasis>realmente</Emphasis> me impactó. Linux
2.2/2.4 viene con todo lo necesario para gestionar el ancho de banda en
formas comparables a los sistemas dedicados de alto nivel para gestión de
ancho de banda.
</Para>

<Para>
Linux va incluso más allá de lo que proporcionan Frame y ATM.
</Para>

<Para>Para prevenir confusiones, sepa que <command>tc</command> usa las
siguientes reglas para la especificación de ancho de banda:
 
<literallayout class='monospaced'>
mbps = 1024 kbps = 1024 * 1024 bps =&#62; byte/s
mbit = 1024 kbit =&#62; kilobit/s.
mb = 1024 kb = 1024 * 1024 b =&#62; byte
mbit = 1024 kbit =&#62; kilobit.
</literallayout>

Internamente, los números se almacenan en bps y b.
</Para>

<Para>Pero cuando <command>tc</command> imprime las tasas, usa lo
siguiente:
</Para>

<literallayout class='monospaced'>
1Mbit = 1024 Kbit = 1024 * 1024 bps =&#62; byte/s
</literallayout>

<Sect1 id="lartc.qdisc.explain">
  <Title>Las colas y disciplinas de cola explicadas</Title>

<Para>
Con el encolamiento determinamos la manera en que se
<Emphasis>ENVIAN</Emphasis> los datos. Es importante darse cuenta de que
sólo podemos dar forma a lo que transmitimos.
</Para>

<Para>
De la manera en que trabaja Internet, no tenemos control directo sobre lo
que la gente nos envía. Es un poco como el buzón (¡físico!) de su casa. No
hay manera en que pueda influenciar al mundo para modificar la cantidad de
correo que le envían, ya que no puede ponerse en contacto con todo el
mundo.
</Para>

<Para>
Sin embargo, la Internet se basa en su mayoría en TCP/IP, que tiene
algunas características que nos ayudarán. TCP/IP no tiene manera de saber
la capacidad de la red entre dos sistemas, de manera que simplemente
empieza a enviar datos más y más rápido («comienzo lento») y cuando se
empiezan a perder paquetes, porque no hay espacio para enviarlos, reduce
la marcha. En realidad, es un poco más inteligente que todo esto, pero
hablaremos de ello más adelante.
</Para>

<Para>
Esto es equivalente a no leer la mitad del correo, y esperar que la gente
deje de enviárselo. Con la diferencia de que para Internet, funciona :-)
</Para>

<Para>
Si tiene un router y desea evitar que ciertas máquinas dentro de su red
descarguen demasiado rápido, necesita dar forma (shape) a la interfaz
*interna* del router, la que envía los datos a sus computadores.
</Para>

<Para>
También tiene que asegurarse de que controla el cuello de botella del
enlace. Si tiene una NIC de 100Mbit y un router con un enlace de 256kbit,
tiene que asegurarse de que no envía más datos de los que el router puede
manejar. Por otro lado, será el router el que controle el enlace y
ajuste el ancho de banda disponible. Necesitamos «poseer la cola» por
decirlo así, y ser el enlace más lento de la cadena. Por suerte, esto es
muy posible.
</Para>

</Sect1>

<Sect1 id="lartc.qdisc.classless">
  <Title>Disciplinas de cola simples, sin clases</Title>

<Para>
Como dije, con las disciplinas de cola, cambiamos el modo en que se envían
los datos. Las disciplinas de cola sin clases son aquellas que,
mayormente, aceptan datos y se limitan a reordenarlos, retrasarlos, o
descartarlos.
</Para>

<Para>
Esto se puede usar para ajustar el tráfico de una interfaz entera, sin
subdivisiones. ¡Es vital que comprenda esta parte del encolado antes de
que pasemos a los qdisc-contenedores-de-qdiscs con clases!
</Para>

<Para>
La disciplina más usada, con mucho, es la qdisc pfifo_fast (se usa por
defecto). Esto también explica por qué estas características avanzadas
son tan robustas. No son más que «simplemente otra cola».
</Para>

<Para>
Cada una de estas colas tiene puntos fuertes y debilidades específicos.
Puede que no todas estén bien probadas.
</Para>

<Sect2>
<Title>pfifo_fast</Title>

<Para>
Esta cola es, como su nombre indica, First In, First Out (el primero que
entra es el primero que sale), lo que significa que ningún paquete recibe
un tratamiento especial. Al menos, no mucho. Esta cola tiene 3 de lo que
llamamos «bandas». Dentro de cada banda, se aplican las reglas FIFO. Sin
embargo, no se procesará la banda 1 mientras haya paquetes esperando en la
banda 0. Lo mismo se aplica para las bandas 1 y 2.
</Para>

<Para>
El núcleo obedece la marca llamada Type of Service que hay en los
paquetes, y tiene cuidado de insertar los paquetes de «mínimo retraso» en
la banda 0.
</Para>

<Para>
¡No confunda esta qdisc sencilla y sin clases con la PRIO con clases!
Aunque se comportan de manera similar, la pfifo_fast no tiene clases y no
puede añadir otras qdisc a ella con la orden tc.
</Para>

<Sect3>
<Title>Parámetros y forma de uso</Title>

<Para>
No puede configurar la qdisc pfifo_fast ya que es el la cola por defecto
fija. Así es como va configurada de serie:
<VariableList>

<VarListEntry>
<Term>priomap</Term>
<ListItem>
<Para>
Determina cómo se corresponden las prioridades de los paquetes, tal como
las asigna el núcleo, a las bandas. La correspondencia se basa en el
octeto TOS del paquete, que es así:
</Para>

<Para>

<Screen>
   0     1     2     3     4     5     6     7
+-----+-----+-----+-----+-----+-----+-----+-----+
|                 |                       |     |
|   PRECEDENCE    |          TOS          | MBZ |
|                 |                       |     |
+-----+-----+-----+-----+-----+-----+-----+-----+
</Screen>

</Para>

<Para>
Los cuatro bits TOS (el «campo TOS») se define como:

<Screen>
Binary Decimcal  Meaning
-----------------------------------------
1000   8         Minimizar retraso (md)
0100   4         Maximizar transferencia (mt)
0010   2         Maximizar fiabilidad (mr)
0001   1         Minimizar el coste monetario (mmc)
0000   0         Servicio normal
</Screen>

</Para>

<Para>
Como hay 1 bit a la derecha de estos cuatro, el valor real del campo TOS
es el doble del valor de sus bits. Tcpdump -v -v muestra el valor del
campo TOS completo, no sólo sus cuatro bits. Este es el valor que ve en la
primera columna de esta tabla:
</Para>

<Para>

<Screen>
TOS     Bits  Significa                Prioridad Linux   Banda
--------------------------------------------------------------
0x0     0     Servicio normal          0 Mejor esfuerzo  1
0x2     1     Minimizar coste monet.   1 Relleno         2
0x4     2     Maximizar fiabilidad     0 Mejor esfuerzo  1
0x6     3     mmc+mr                   0 Mejor esfuerzo  1
0x8     4     Mazimizar transferencia  2 En masa         2
0xa     5     mmc+mt                   2 En masa         2
0xc     6     mr+mt                    2 En masa         2
0xe     7     mmc+mr+mt                2 En masa         2
0x10    8     Minimizar retrasos       6 Interactivo     0
0x12    9     mmc+md                   6 Interactivo     0
0x14    10    mr+md                    6 Interactivo     0
0x16    11    mmc+mr+md                6 Interactivo     0
0x18    12    mt+md                    4 Int. en masa    1
0x1a    13    mmc+mt+md                4 Int. en masa    1
0x1c    14    mr+mt+md                 4 Int. en masa    1
0x1e    15    mmc+mr+mt+md             4 Int. en masa    1
</Screen>

</Para>

<Para>
Muchos números. La segunda columna contiene el valor de los cuatro bits
TOS relevantes, seguidos por su significado traducido. Por ejemplo, el 15
significa que un paquete espera un Mínimo coste monetario, la Máxima
fiabilidad, la Máxima transferencia Y un Retraso mínimo. Yo llamaría a
esto un «paquete holandés» <footnote><para>N. del T: el autor es holandés,
y supongo que se reirá mucho con este chiste</para></footnote>.
</Para>

<Para>
La cuarta columna indica la manera en que el núcleo Linux interpreta los
bits del TOS, mostrando qué prioridad les asigna.
</Para>

<Para>
La última columna indica el resultado del priomap por defecto. En la línea
de órdenes el priomap por defecto se parece a:

<Screen>
1, 2, 2, 2, 1, 2, 0, 0 , 1, 1, 1, 1, 1, 1, 1, 1
</Screen>

</Para>

<Para>
Esto significa que a la prioridad 4, por ejemplo, se asigna la banda
número 1. El priomap también le permite listar prioridades mayores (&gt;
7) que no se corresponden a asignaciones del TOS, sino que se configuran
por otros medios.
</Para>

<Para>
Esta tabla del RFC 1349 (léalo para obtener más detalles) le dice cómo
deberían activar las aplicaciones los bits del TOS:

<Screen>
TELNET                   1000           (minimizar retraso)
FTP
	Control          1000           (minimizar retraso)
        Datos            0100           (maximizar transferencia)

TFTP                     1000           (minimizar retraso)

SMTP 
	Fase de órdenes  1000           (minimizar retraso)
        Fase de datos    0100           (maximizar transferencia)

Domain Name Service
	Consulta UDP     1000           (minimizar retraso)
	Consulta TCP     0000
	Transf. de zona  0100           (maximizar transferencia)

NNTP                     0001           (minimizar coste monetario)

ICMP
	Errores          0000
	Peticiones       0000 (la mayoría)
	Respuestas       &#60;igual que las peticiones&#62; (la mayoría)
</Screen>

</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>txqueuelen</Term>
<ListItem>
<Para>
La longitud de esta cola se obtiene de la configuración de la interfaz,
que puede ver y modificar con ifconfig o ip. Para establecer la longitud
de la cola a 10, ejecute: ifconfig eth0 txqueuelen 10
</Para>

<Para>
¡No puede establecer este parámetro con tc!
</Para></ListItem>
</VarListEntry>
</VariableList>
</Para>

</Sect3>

</Sect2>

<Sect2>
<Title>Token Bucket Filter</Title>

<Para>
El Token Bucket Filter (TBF) es un qdisc sencillo que se limita a dejar
pasar paquetes que lleguen a una tasa que no exceda una impuesta
administrativamente, pero con la posibilidad de permitir ráfagas cortas
que excedan esta tasa.
</Para>

<Para>
TBF es muy preciso, amigable para la red y el procesador. ¡Debería ser su
primera elección si sólo quiere ralentizar una interfaz!
</Para>

<Para>
La implementación de TBF consiste en un búfer (el bucket o balde), que se
llena constatemente con piezas virtuales de información denominadas
tokens, a una tasa específica (token rate). El parámetro más importante
del bucket es su tamaño, que es el número de tokens que puede almacenar.
</Para>

<Para>
Cada token que llega toma un paquete de datos entrante de la cola de datos
y se elimina del bucket. Asociar este algoritmo con los dos flujos (tokens
y datos), nos da tres posibles situaciones:
</Para>

<Para>

<ItemizedList>
<ListItem>

<Para>
Los datos llegan a TBF a una tasa que es <Emphasis>igual</Emphasis> a la
de tokens entrantes. En este caso, cada paquete entrante tiene su token
correspondiente y pasa a la cola sin retrasos.

</Para>
</ListItem>
<ListItem>

<Para>
Los datos llegan al TBF a una tasa <Emphasis>menor</Emphasis> a la de los
token. Sólo una parte de los tokens se borran con la salida da cada
paquete que se envía fuera de la cola, de manera que se acumulan los
tokens, hasta llenar el bucket. Los tokens sin usar se pueden utilizar
para enviar datos a velocidades mayores de la tasa de tokens, en cuyo caso
se produce una corta ráfaga de datos.
</Para>
</ListItem>
<ListItem>

<Para>
Los datos llegan al TBF a una tasa <Emphasis>mayor</Emphasis> a la de los
token. Esto signigica que el bucket se quedará pronto sin tokens, lo que
causará que TBF se acelere a sí mismo por un rato. Esto se llama una
«situación sobrelímite». Si siguen llegando paquetes, empezarán a ser
descartados.
</Para>
</ListItem>

</ItemizedList>

</Para>

<Para>
Esta última situación es muy importante, porque permite ajustar
administrativamente al ancho de banda disponible a los datos que están
pasando por el filtro.
</Para>

<Para>
La acumulación de tokens permite ráfagas cortas de datos extralimitados
para que pasen sin pérdidas, pero cualquier sobrecarga restante causará
que los paquetes se vayan retrasando constantemente, y al final sean
descartados.
</Para>

<Para>
Tenga en cuenta que en la implementación actual, los tokens se
corresponden a bytes, no a paquetes.
</Para>

<Sect3>
<Title>Parámetros y uso</Title>

<Para>
Incluso aunque probablemente no necesite hacerle cambios, tbf tiene
algunos controles ajustables. Primero, los parámetros que estarán
disponibles siempre:
<VariableList>

<VarListEntry>
<Term>limit o latency</Term>
<ListItem>
<Para>
Limit es el número de bytes que pueden ser encolados a la espera de que
haya tokens disponibles. También puede especificar esto estableciendo el
parámetro latency, que indica el periodo máximo de tiempo que puede pasar
un paquete en el TBF. Este último cálculo tiene en cuenta el tamaño del
bucket, la tasa y posiblemente el peakrate (la tasa de picos, si es que la
ha configurado).
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>burst/buffer/maxburst</Term>
<ListItem>
<Para>
Tamaño del bucket, en bytes. Esta es la máxima cantidad de bytes para los
que pueden haber tokens disponibles instantáneamente. En general, grandes
tasas precisan grandes búferes. Para 10mbit/s sobre Intel, ¡necesitará al
menos un búfer de 10kbyte si desea alcanzar la tasa que ha configurado!
</Para>

<Para>
Si el búfer es demasiado pequeño, se descartarán paquetes debido a que
llegan más tokens por tick del temporizador de los que caben en el bucket.
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>mpu</Term>
<ListItem>
<Para>
Un paquete de tamaño cero no usa un ancho de banda cero. En ethernet,
ningún paquete usa menos de 64 bytes. La Minimum Packet Unit determina el
uso mínimo de tokens por paquete.
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>rate</Term>
<ListItem>
<Para>
El ajuste de la velocidad. ¡Vea las indicaciones hechas anteriormente
sobre la velocidad!
</Para></ListItem>
</VarListEntry>
</VariableList>
</Para>

<Para>
Si el paquete contiene tokens y se le permite estar vacío, por defecto
tendrá velocidad infinita. Si esto no es aceptable, use los siguientes
parámetros:
</Para>

<Para>
<VariableList>

<VarListEntry>
<Term>peakrate</Term>
<ListItem>
<Para>
Si hay tokens disponibles, y llegan paquetes, por defecto se envían
inmediatamente, a «la velocidad de la luz» por decirlo de alguna manera.
Puede que esto no sea lo que usted quiere, especialmente si tiene un
bucket grande.
</Para>

<Para>
La tasa de picos se puede usar para especificar cuán rápido se le permite
al bucket vaciarse. Si está haciendo todo según el libro, esto se consigue
enviando un paquete, y esperando después lo suficiente antes de enviar el
siguiente. Hemos calculado nuestras esperas de manera que se envíen justo
a la tasa de picos (peakrate).
</Para>

<Para>
Sin embargo, debido a la resolución por defecto de 10ms del temporizador
de Unix, con paquetes de 10.000 bits de media, ¡estaremos limitados a una
tasa de picos de 1mbit/s!
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>mtu/minburst</Term>
<ListItem>
<Para>
La peakrate de 1mbit/s no es muy útil si la tasa normal es mayor que ésa.
Es posible tener una tasa de picos mayor enviando más paquetes por
fracción del temporizador, ¡lo que significa de forma efectiva que hemos
creado un segundo bucket!
</Para>

<Para>
Este segundo bucket contiene por defecto un único paquete, por lo que no
es un bucket realmente.
</Para>

<Para>
Para calcular la peakrate máxima posible, multiplique la mtu configurada
por 100 (o más correctamente, HZ, que es 100 en Intel, y 1024 en Alpha).
</Para></ListItem>
</VarListEntry>
</VariableList>
</Para>

</Sect3>

<Sect3>
<Title>Configuración de ejemplo</Title>

<Para>
Esta es una configuración sencilla pero *muy* útil:

<Screen>
# tc qdisc add dev ppp0 root tbf rate 220kbit latency 50ms burst 1540
</Screen>

</Para>

<Para>
Ok, ¿por qué es esto útil? Si tiene un dispositivo de red con una cola
grande, como un módem para DSL o un cable módem, y quiere comunicarse con
él mediante un dispositivo rápido, como una interfaz ethernet, se
encontrará conque enviar cualquier cosa destruye completamente la
interactividad.
</Para>

<Para>
Esto se debe a que enviar datos llena la cola del módem, que probablamente
es *enorme* porque realmente ayuda a conseguir una buena transferencia de
datos al enviar. Pero esto no es lo que usted quiere; lo que quiere es
tener una cola no tan grande de manera que la interactividad se mantenga
de manera que aún pueda hacer otras cosas mientras envía los datos.
</Para>

<Para>
La línea anterior reduce los envíos a una tasa que no lleve formar colas
en el módem (la cola estará en Linux, donde podemos ajustarla a un tamaño
limitado).
</Para>

<Para>
Cambie 220kbit por su velocidad *real* de envío, menos un pequeño
porcentaje. Si tiene un módem realmente rápido, suba «burst» un poco.
</Para>

</Sect3>

</Sect2>

<Sect2 id="lartc.sfq">
<Title>Stochastic Fairness Queueing</Title>

<Para>
Stochastic Fairness Queueing (SFQ) es una implementación sencilla de la
familia de algoritmos de colas justas (fair queueing). Es menos preciso
que los otros, pero también necesita menos cálculos mientras que resulta
ser casi perfectamente justo.
</Para>

<Para>
La palabra clave en SFQ es conversación (o flujo), que se corresponde en
su mayoría a una sesión TCP o a un flujo UDP. El tráfico se divide en un
número bastante grande de colas FIFO, una por cada conversación. Entonces
se envía el tráfico de una manera parecida a round robin, dando a cada
sesión por turnos la oportunidad de enviar datos.
</Para>

<Para>
Esto lleva a un comportamiento bastante equitativo y evita que una única
conversación ahogue a las demás. SFQ se llama «estocástica» porque
realmente no crea una cola para cada sesión, sino que tiene un algoritmo
que divide el tráfico en un número limitado de colas usando un algoritmo
de hash (troceo).
</Para>

<Para>
Debido al hash, varias sesiones pueden acabar en el mismo bucket, lo que
dividirá por dos las posibilidades de cada sesión de enviar un paquete,
reduciendo a la mitad de esta forma la velocidad efectiva disponible. Para
evitar que esta situación acabe siendo detectable, SFQ cambia a menudo su
algoritmo hash de manera que dos sesiones sólo colisionen durante unos
pocos segundos.
</Para>

<Para>
¡Es importante tener en cuenta que SFQ sólo es útil en caso de que la
interfaz real de salida esté realmente llena! Si no lo está, entonces la
máquina Linux no encolará paquetes y no se producirá efecto alguno. Más
tarde describiremos cómo combinar SFQ con otros qdisc para obtener lo
mejor de ambos mundos.
</Para>

<Para>
Específicamente, configurar SFQ sobre una interfaz ethernet que esté
apuntando al cable módem o a un router DSL, ¡no tiene sentido si no se
hace algún ajuste más!
</Para>

<Sect3>
<Title>Parámetros y uso</Title>

<Para>
SFQ es mayormente autoajustable:
<VariableList>

<VarListEntry>
<Term>perturb</Term>
<ListItem>
<Para>
Reconfigurar el hash una vez cada estos segundos. Si no se indica, el hash
no se reconfigurará nunca. No es recomendable. 10 segundos es
probablemente un buen valor.
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>quantum</Term>
<ListItem>
<Para>
Cantidad de bytes de un flujo que se permiten sacar de la cola antes de
que le toque el turno a la siguiente cola. Por defecto es 1 paquete de
tamaño máximo (tamaño MTU). ¡No lo ponga por debajo del MTU!
</Para></ListItem>
</VarListEntry>
</VariableList>
</Para>

</Sect3>

<Sect3>
<Title>Configuración de ejemplo</Title>

<Para>
Si tiene un dispositivo que tenga velocidad de enlace y tasa actual
disponible idénticas, como una línea telefónica, esta configuración
ayudará a mejorar la equitatividad:

<Screen>
# tc qdisc add dev ppp0 root sfq perturb 10
# tc -s -d qdisc ls
qdisc sfq 800c: dev ppp0 quantum 1514b limit 128p flows 128/1024 perturb 10sec 
 Sent 4812 bytes 62 pkts (dropped 0, overlimits 0) 
</Screen>

</Para>

<Para>
El número 800c: es el número de manejador asignado de forma automática,
limit indica que pueden esperar 128 paquetes en esta cola. Hay 1024
hashbuckets disponibles para la contabilidad, de los cuales puede haber
128 activos al mismo tiempo (¡no caben más paquetes en la cola!) Los hash
se reconfiguran una vez cada 10 segundos.
</Para>

</Sect3>

</Sect2>

</Sect1>

<Sect1 id="lartc.qdisc.advice">
  <Title>Consejos sobre en qué momento usar qué cola</Title>

<Para>
Resumiendo, estas son las colas sencillas que realmente gestionan el
tráfico reordenando, ralentizando o eliminando paquetes.
</Para>

<Para>
Los siguientes consejos pueden ayudarle a escoger qué cola usar. Menciona
algunas qdisc descritas en el capítulo
<citetitle><xref linkend="lartc.adv-qdisc"></citetitle>.
</Para>

<ItemizedList>
<ListItem>
<Para>
Para simplemente ralentizar el tráfico de salida, use el Token Bucket
Filter. Funciona para grandes anchos de banda, si escala el bucket.
</Para>
</ListItem>
<ListItem>

<Para>
Si su enlace está realmente lleno y quiere asegurarse de que ninguna
sesión domina el ancho de banda de salida, use Stochastical Fairness
Queueing.
</Para>
</ListItem>
<ListItem>

<Para>
Si tiene un backbone grande y sabe lo que está haciendo, considere usar
Random Early Drop (vea el capítulo Avanzado).
</Para>
</ListItem>
<ListItem>

<Para>
Para «dar forma» al tráfico de entrada que no está reenviando, use el
Ingress Policer. El ajuste del tráfico de entrada se denomina «policing»,
por cierto, no «shaping».
</Para>
</ListItem>
<ListItem>

<Para>
Si *lo está* reenviando, use un TBF en la interfaz hacia la que está
redirigiendo los datos. A menos que quiera ajustar el tráfico que vaya a
salir por varias interfaces, en cuyo caso el único factor común es la
interfaz de entrada. En tal caso, use el Ingress Policer.
</Para>
</ListItem>
<ListItem>

<Para>
Si no quiere ajustar, sino ver si su interfaz está tan cargada que tiene
una cola, use la cola pfifo (no pfifo_fast). Carece de bandas internas
pero lleva la cuenta del tamaño de su búfer.
</Para>
</ListItem>
<ListItem>
<Para>
Por último, siempre puede usar el <quote>ajuste social</quote>.
No siempre es posible usar la tecnología para conseguir lo que se quiere.
Los usuarios se toman las limitaciones técnicas como hostilidad.
¡Una palabra amable también puede ayudar a dividir correctamente su ancho
de banda!
</Para>
</ListItem>
</ItemizedList>

</Sect1>

<Sect1 id="lartc.qdisc.terminology">
  <Title>Terminología</Title>

<Para>
Para entender correctamente configuraciones más complicadas se necesita
explicar primero algunos conceptos. Debido a la complejidad y la relativa
novedad de este tema, la gente usa un montón de términos diferentes cuando
en realidad quieren decir lo mismo.
</Para>

<Para>
Lo que sigue se basa remotamente en
<filename>draft-ietf-diffserv-model-06.txt</filename>,
<citetitle>Un modelo informal de gestión para routers
Diffserv</citetitle>.
Actualmente lo puede encontrar en
<ulink url="http://www.ietf.org/internet-drafts/draft-ietf-diffserv-model-06.txt">
  http://www.ietf.org/internet-drafts/draft-ietf-diffserv-model-06.txt
</ulink>.
</Para>

<Para>
Léalo para ver las definiciones estrictas de los términos usados.
<VariableList>

<VarListEntry>
<Term>Disciplina de colas (qdisc)</Term>
<ListItem>
<Para>
Un algoritmo que controla la cola de un dispositivo, sea de entrada
(ingress) o de salida (egress).
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>qdisc raíz (root qdisc)</Term>
<ListItem>
<Para>
La qdisc raíz es la que está adjunta al dispositivo.
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>Qdisc sin clases</Term>
<ListItem>
<Para>
Una qdisc sin subdivisiones internas configurables.
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>Qdisc con clases</Term>
<ListItem>
<Para>
Una qdisc con clases contiene múltiples clases. Algunas de ellas contienen
otra qdisc, que a su vez puede ser con clases, pero no tiene por qué. De
acuerdo con la definición estricta, pfifo_fast *es* con clases, porque
contiene tres bandas que son, en realidad, clases.  Sin embargo, desde la
perspectiva de configuración del usuario, no tiene clases ya que las
clases no se pueden tocar con la herramienta tc.
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>Clases</Term>
<ListItem>
<Para>
Una qdisc con clases puede tener muchas clases, cada una de las cuales es
interna a ella. A una clase, a su vez, se le pueden añadir varias clases.
De manera que una clase puede tener como padre una qdisc u otra clase.

Una clase terminal (o clase "hoja": leaf class) es una clase que no tiene
clases hijas. Esta clase tiene 1 qdisc adjunta. Esta qdisc es responsable
de enviar datos a la clase. Cuando creas una clase, se le adjunta una
qdisc fifo. Cuando añades una clase hija, se elimina esta qdisc. Para
clases terminales, esta qdisc fifo puede ser reemplazada con otra más
adecuada. Incluso se puede reemplazar esta qdisc fifo por otra con clases
de manera que se puedan añadir más clases.
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>Clasificador</Term>
<ListItem>
<Para>
Cada qdisc con clases necesita determinar a qué clase necesita enviar un
paquete. Esto se hace usando el clasificador.
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>Filtro</Term>
<ListItem>
<Para>
La clasificación se puede realizar usando filtros. Un filtro contiene
varias condiciones que pueden ser cumplidas.
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>Scheduling (ordenamiento)</Term>
<ListItem>
<Para>
Una qdisc puede, con la ayuda de un clasificador, decidir que algunos
paquetes necesitan salir antes que otros. Este proceso se denomina
Scheduling, y lo realiza por ejemplo la qdisc qfifo_fast anteriormente
mencionada. El Scheduling también se denomina «reordenamiento», pero esto
es confuso.
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>Shaping (ajuste)</Term>
<ListItem>
<Para>
El proceso de retrasar paquetes antes de que salgan para hacer que el
tráfico sea conforme a una tasa máxima configurada. El Shapping se realiza
durante la salida («egress»). Coloquialmente, al descarte de paquetes para
ralentizar el tráfico también se le suele denominar Shapping.
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>Policing</Term>
<ListItem>
<Para>
Retrasar o descartar paquetes para que el tráfico se mantenga por debajo
de un ancho de banda configurado. En Linux, el «policing» sólo puede
descartar paquetes, no retrasarlo (no hay una «cola de ingreso» - ingress
queue).
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>Conservativa de trabajo</Term>
<ListItem>
<Para>
Una qdisc conservativa de trabajo (work-conserving) siempre distribuye
paquetes si los hay disponibles. En otras palabras, nunca retrasa un
paquete si el adaptador de red está preparado para enviarlo (en el caso de
una qdisc de salida - egress).
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>No conservativa de trabajo</Term>
<ListItem>
<Para>
Algunas colas, como la Token Bucket Filter, por ejemplo, pueden necesitar
retrasar un paquete durante un cierto tiempo para limitar el ancho de
banda. Esto significa que algunas veces rechazarán enviar un paquete,
incluso aunque los haya disponibles.
</Para></ListItem>
</VarListEntry>
</VariableList>
</Para>

<Para>
Ahora que conocemos la terminología, veamos dónde están todas estas cosas.
</Para>

<Para>

<Screen width="80">
       Programas en espacio de usuario
                     ^
                     |
     +---------------+-----------------------------------------+
     |               Y                                         |
     |    -------&#62; Pila IP                                      |
     |   |              |                                      |
     |   |              Y                                      |
     |   |              Y                                      |
     |   ^              |                                      |
     |   |  / ----------&#62; Reenvío -&#62;                           |
     |   ^ /                       |                           |
     |   |/                        Y                           |
     |   |                         |                           |
     |   ^                         Y              /-qdisc1-\   |
     |   |                     Clasificador de   /--qdisc2--\  |
  ---&#62;-&#62; Qdisc de              Salida (Egress)   ---qdisc3---- | -&#62;
     |   Entrada (Ingress)                       \__qdisc4__/  |
     |                                            \-qdiscN_/   |
     |                                                         |
     +----------------------------------------------------------+
</Screen>

Gracias a Jamal Hadi Salim por esta representación ASCII.
</Para>

<Para>
El gran bloque representa al núcleo. La flecha de la izquierda es el
tráfico entrando en la máquina desde la red. Entonces se le pasa a la
Qdisc de Entrada que puede aplicar filtros a los paquetes, y decidir
descartarlos. A esto se le llama «Policing».
</Para>

<Para>
Esto ocurre en una etapa muy temprana, antes de que se haya visto mucho
del núcleo. Por tanto, es un buen lugar para descartar tráfico sin
consumir mucho tiempo de CPU.
</Para>

<Para>
Si se le permite continuar al paquete, puede estar destinado a una
aplicación local, en cuyo caso entra en la pila IP para ser procesado, y
se envía a un programa en espacio de usuario. El paquete también puede ser
reenviado sin pasar por una aplicación, en cuyo caso se destina a la
salida (egress). Los programas de espacio de usuario también pueden
distribuir datos, que serán examinados y reenviados por el Clasificador de
Salida.
</Para>

<Para>
Ahí es observado y encolado por cualquiera de varias qdisc. En el caso por
defecto, sin configurar, sólo hay instalada una qdisc de salida,
pfifo_fast, que siempre recibe el paquete. A esto se le llama «encolado»
(enqueueing).
</Para>

<Para>
Ahora el paquete está en la qdisc, esperando a que el núcleo pida que sea
retransmitido por la interfaz de salida. A esto se le llama «desencolado».
</Para>

<Para>
Esta figura también funciona en el caso de que haya un único adaptador de
red (las flechas de entrada y salida al núcleo no se deben tomar demasiado
literalmente). Cada adaptador de red tiene ranuras tanto para entrada como
para salida.
</Para>

</Sect1>

<Sect1 id="lartc.qdisc.classful">
  <Title>Disciplinas de cola con clases</Title>

<Para>
Las qdisc con clases son muy útiles si tiene diferentes tipos de tráfico a
los que quiere dar un tratamiento separado. Una de las qdisc con clases se
denomina «CBQ», «Class Based Queueing», y se la menciona tan
frecuentemente que la gente suele identificar el encolado con clases sólo
con CBQ, pero éste no es el caso.
</Para>

<Para>
CBQ es meramente la que lleva más tiempo (y también la más compleja). No
siempre es la que necesita. Esto puede ser un trauma para los partidarios
del «efecto sendmail», que nos enseña que cualquier tecnología compleja
que no viene documentada debe ser lo mejor que hay disponible.
</Para>

<Para>
En breve diremos más sobre CBQ y sus alternativas.
</Para>

<Sect2>
<Title>El flujo dentro de las qdisc con clases y sus clases</Title>

<Para>
Cuando entra tráfico dentro de una qdisc con clases, hay que enviarlo a
alguna de las clases que contiene (se necesita «clasificarlo»). Para
determinar qué hay que hacer con un paquete, se consulta a los «filtros».
Es importante saber que los filtros se llaman desde dentro de una qdisc,
¡y no al revés!
</Para>

<Para>
Los filtros asociados a esa qdisc devuelven entonces una decisión, y la
qdisc la usa para encolar el paquete en una de las clases. Cada subclase
puede probar otros filtros para ver si se imparten más instrucciones. En
caso contrario, la clase  encola el paquete en la qdisc que contiene.
</Para>

<Para>
Aparte de contener otras qdisc, la mayoría de las qdisc con clases también
realizan «shaping». Esto es útil tanto para reordenar paquetes (con SFQ,
por ejemplo) como para controlar tasas. Necesitará esto en caso de tener
una interfaz de gran velocidad (por ejemplo, ethernet) enviando a un
dispositivo más lento (un cable módem).
</Para>

<Para>
Si sólo fuera a usar SFQ, no debería pasar nada, ya que los paquetes
entrarían y saldrían de su router sin retrasos: la interfaz de salida es
mucho más rápida que la velocidad del enlace en sí. No habrá cola que
reordenar.
</Para>

</Sect2>

<Sect2>
<Title>La familia qdisc: raíces, controladores, hermanos y padres</Title>

<Para>
Cada interfaz tiene una «qdisc raíz» de salida, que por defecto es la
disciplina de colas pfifo_fast sin clases que mencionamos anteriormente. A
cada qdisc y clase se le asigna un controlador (handle), que puede usar en
posteriores sentencias de configuración para referirse a la qdisc. Aparte
de la qdisc de salida, la interfaz también puede tener una de entrada, que
dicta las normas sobre el tráfico que entra.
</Para>

<Para>
Los controladores de estas qdisc consisten en dos partes, un número mayor
y un número menor: &lt;mayor&gt;:&lt;menor&gt;. Es costumbre darle a la
qdisc de raíz el nombre «1:», que es lo mismo que «1:0». El número menor
de una qdisc siempre es 0.
</Para>

<Para>
Las clases deben tener el mismo número mayor que sus padres. Este número
mayor tiene que ser único dentro de una configuración de salida o entrada.
El número menor debe ser único dentro de una qdisc y sus clases.
</Para>

<Sect3>
<Title>Cómo se usan los filtros para clasificar el tráfico</Title>

<Para>
Recapitulando, una jerarquía típica puede ser como ésta:

<Screen>
                     1: qdisc raíz
                      |
                     1:1   clase hija
                   /  |  \
                  /   |   \
                 /    |    \
              1:10  1:11  1:12   clases hijas
               |      |     |
               |     11:    |    clase terminal
               |            |
               10:         12:   qdisc
              /   \       /   \
           10:1  10:2   12:1  12:2   clases terminales
</Screen>

</Para>

<Para>
¡Pero no deje que este árbol le engañe! *No* debe imaginarse que el núcleo
está en la cima del árbol y la red abajo, ya que no es el caso. Los
paquetes se encolan y desencolan en el qdisc raíz, que es la única cosa
con la que habla el núcleo.
</Para>

<Para>
Un paquete se clasifica en una cadena como ésta:
</Para>

<Para>
1: -&#62; 1:1 -&#62; 12: -&#62; 12:2
</Para>

<Para>
Ahora el paquete reside en una cola de una qdisc asociada a la clase 12:2.
En este ejemplo, se asocia un filtro a cada «nodo» del árbol, y cada cual
escoge qué rama se toma en su paso. Esto puede tener sentido, Sin embargo,
también es posible:
</Para>

<Para>
1: -&#62; 12:2
</Para>

<Para>
En este caso, un filtro asociado a la raíz decidió enviar el paquete
directamente a 12:2.
</Para>

</Sect3>

<Sect3>
<Title>Cómo se desencolan los paquetes para enviarlos al hardware</Title>

<Para>
Cuando el núcleo decide que necesita extraer paquetes para enviarlos a la
interfaz, la qdisc 1: raíz recibe una petición de desencolar, que se pasa
a 1:1, que a su vez la pasa a 10:, 11:, y 12:, cada una de las cuales
consulta a sus descendientes, e intenta hacer dequeue() sobre ellos. En
este caso, el núcleo necesita recorrer todo el árbol, porque sólo 12:2
contiene un paquete.
</Para>

<Para>
En breve, las clases anidadas SOLO hablan a sus qdisc paternas, y nunca a
una interfaz. ¡Sólo la qdisc raíz recibe peticiones de desencolado del
núcleo!
</Para>

<Para>
La consecuencia de esto es que las clases nunca desencolan más rápido de
lo que sus padres permiten. Y esto es exactamente lo que queremos: de esta
manera, podemos tener SFQ como clase interna, que no hace ajustes, sólo
reordena, y tenemos una qdisc externa, que es la que hace los ajustes.
</Para>

</Sect3>

</Sect2>

<Sect2>
<Title>La qdisc PRIO</Title>

<Para>
La qdisc PRIO en realidad no hace ajustes, sino que sólo subdivide el
tráfico basándose en cómo haya configurado los filtros. Puede considerar
la qdisc PRIO como una pfifo_fast con esteroides, en la que cada banda es
una clase separada, en lugar de una simple FIFO.
</Para>

<Para>
Cuando se encola un paquete a la qdisc PRIO, se escoge una clase basándose
en las órdenes de filtrado que haya dado. Por defecto, se crean tres
clases. Estas clases contienen qdisc que son puras FIFO sin estructura
interna, pero puede sustituirlas por cualquier qdisc que haya disponible.
</Para>

<Para>
Siempre que se necesite desencolar un paquete, se intenta primero con la
clase :1. Las clases más altas sólo se usan si no se ha conseguido el
paquete en las clases más bajas.
</Para>

<Para>
Esta qdisc es muy útil en caso de que quiera dar prioridad a cierto
tráfico sin usar sólo las marcas TOS sino usando el potencial de los
filtros de tc. También puede contener cualquier qdisc, mientras que
pfifo_fast está limitada a qdisc de fifo sencillas.
</Para>

<Para>
Como en realidad no hace ajustes, se le aplica el mismo aviso que a SFQ:
úsela solamente si el enlace físico está realmente lleno o métala dentro
de una qdisc con clases que haga ajustes. Esto último se aplica a la
mayoría de dispositivos DSL y cable módems.
</Para>

<Para>
Hablando formalmente, la qdisc PRIO es un reorganizador conservativo.
</Para>

<Sect3>
<Title>Parámetros y uso de PRIO</Title>

<Para>
tc reconoce los siguientes parámetros:
<VariableList>

<VarListEntry>
<Term>bands</Term>
<ListItem>
<Para>
Número de bandas a crear. Cada banda es una clase. Si cambia este número,
también deberá cambiar:
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>priomap</Term>
<ListItem>
<Para>
Si no proporciona filtros de tc para clasificar el tráfico, la qdisc PRIO
examina la prioridad TC_PRIO para decidir cómo encolar el tráfico.
</Para>

<Para>
Esto funciona igual que con la qdisc pfifo_fast mencionada previamente,
refiérase a ella si desea más detalles.
</Para></ListItem>
</VarListEntry>
</VariableList>
Las bandas son clases, y todas se llaman de mayor:1 a mayor:3 por defecto,
de manera que si nuestra qdisc PRIO se llama 12:, tc filtrará el tráfico a
12:1 para garantizar la mayor prioridad.
</Para>

<Para>
Repetimos: ¡la banda 0 va al número menor 1! La banda 1 al número menor 2,
etc.
</Para>

</Sect3>

<Sect3>
<Title>Configuración de ejemplo</Title>

<Para>
Crearemos este árbol:

<Screen>
     raíz 1: prio
       /   |   \
     1:1  1:2  1:3
      |    |    |
     10:  20:  30:
     sfq  tbf  sfq
banda 0    1    2
</Screen>

</Para>

<Para>
El tráfico masivo irá a 30:, el interactivo a 20: o 10:.
</Para>

<Para>
Líneas de órdenes:

<Screen>
# tc qdisc add dev eth0 root handle 1: prio 
## Esto crea *instantáneamente las clases 1:1, 1:2, 1:3
  
# tc qdisc add dev eth0 parent 1:1 handle 10: sfq
# tc qdisc add dev eth0 parent 1:2 handle 20: tbf rate 20kbit buffer 1600 limit 3000
# tc qdisc add dev eth0 parent 1:3 handle 30: sfq                                
</Screen>

</Para>

<Para>
Ahora veamos qué hemos creado:

<Screen>
# tc -s qdisc ls dev eth0 
qdisc sfq 30: quantum 1514b 
 Sent 0 bytes 0 pkts (dropped 0, overlimits 0) 

 qdisc tbf 20: rate 20Kbit burst 1599b lat 667.6ms 
 Sent 0 bytes 0 pkts (dropped 0, overlimits 0) 

 qdisc sfq 10: quantum 1514b 
 Sent 132 bytes 2 pkts (dropped 0, overlimits 0) 

 qdisc prio 1: bands 3 priomap  1 2 2 2 1 2 0 0 1 1 1 1 1 1 1 1
 Sent 174 bytes 3 pkts (dropped 0, overlimits 0) 
</Screen>

Como puede ver, la banda 0 ya ha tenido algo de tráfico, ¡y se envió un
paquete mientras ejecutábamos la orden!
</Para>

<Para>
Ahora vamos a hacer alguna transferencia masiva con una herramienta que
ajuste pertinentemente las marcas TOS, y echemos otro vistazo:

<Screen>
# scp tc ahu@10.0.0.11:./
ahu@10.0.0.11's password: 
tc                   100% |*****************************|   353 KB    00:00    
# tc -s qdisc ls dev eth0
qdisc sfq 30: quantum 1514b 
 Sent 384228 bytes 274 pkts (dropped 0, overlimits 0) 

 qdisc tbf 20: rate 20Kbit burst 1599b lat 667.6ms 
 Sent 2640 bytes 20 pkts (dropped 0, overlimits 0) 

 qdisc sfq 10: quantum 1514b 
 Sent 2230 bytes 31 pkts (dropped 0, overlimits 0) 

 qdisc prio 1: bands 3 priomap  1 2 2 2 1 2 0 0 1 1 1 1 1 1 1 1
 Sent 389140 bytes 326 pkts (dropped 0, overlimits 0) 
</Screen>

Como puede ver, todo el tráfico fue al controlador 30:, que es la banda de
menor prioridad, tal como esperábamos. Ahora, para verificar que el tráfico
interactivo va a bandas más altas, crearemos un poco:
</Para>

<Para>

<Screen>
# tc -s qdisc ls dev eth0
qdisc sfq 30: quantum 1514b 
 Sent 384228 bytes 274 pkts (dropped 0, overlimits 0) 

 qdisc tbf 20: rate 20Kbit burst 1599b lat 667.6ms 
 Sent 2640 bytes 20 pkts (dropped 0, overlimits 0) 

 qdisc sfq 10: quantum 1514b 
 Sent 14926 bytes 193 pkts (dropped 0, overlimits 0) 

 qdisc prio 1: bands 3 priomap  1 2 2 2 1 2 0 0 1 1 1 1 1 1 1 1
 Sent 401836 bytes 488 pkts (dropped 0, overlimits 0) 
</Screen>

</Para>

<Para>
Funcionó (todo el tráfico adicional se ha ido a 10:, que es nuestra qdisc
de más alta prioridad). No se ha enviado tráfico a la de más baja
prioridad, que recibió anteriormente todo nuestro scp.
</Para>

</Sect3>

</Sect2>

<Sect2>
<Title>La famosa qdisc CBQ</Title>

<Para>
Como se dijo antes, CBQ es la qdisc más compleja disponible, la más
publicitada, la menos comprendida, y probablemente la más difícil de
configurar correctamente. Esto no se debe a que los autores sean malvados
o incompetentes, ni mucho menos, sino sólo que el algoritmo CBQ no es tan
preciso y realmente no se ajusta del todo a la manera de trabajar de
Linux.
</Para>

<Para>
Además de ser de clases, CBQ también es ajustadora (shaper) y es en este
aspecto en el que no funciona del todo bien. Debería funcionar de esta
manera. Si intenta ajustar a 1mbit/s una conexión de 10mbit/s, el enlace
debería estar ocioso el 90% del tiempo. Si no lo está, necesitamos
acelerar de manera que realmente ESTE ocioso el 90% del tiempo.
</Para>

<Para>
Esto es bastante difícil de medir, de manera que en su lugar CBQ deriva el
tiempo ocioso del número de microsegundos que se tarda entre cada petición
de más datos por parte de la capa de hardware. Combinados, se pueden usar
para aproximar cómo de lleno o vacío está el enlace.
</Para>

<Para>
Esto es bastante circunspecto y no siempre lleva a resultados adecuados.
Por ejemplo, ¿qué pasaría si la verdadera velocidad del enlace no es capaz
de transmitir realmente todos los 100mbit/s de datos, quizá debido a un
driver mal implementado? Una tarjeta de red PCMCIA tampoco alcanzará nunca
los 100mbit/s debido a la manera en que está diseñado el bus (de nuevo,
¿cómo calculamos el tiempo?)
</Para>

<Para>
Se vuelve aún peor si consideramos dispositivos de red no del todo reales,
como PPP sobre Ethernet o PPTP sobre TCP/IP. El ancho de banda efectivo en
ese caso probablemente se determina por la eficiencia de los canales al
espacio de usuario (que es enorme).
</Para>

<Para>
La gente que ha hecho mediciones ha descubierto que CBQ no es siempre muy
preciso, y a veces se pierde del todo.
</Para>

<Para>
Sin embargo, en muchas circunstancias funciona bien. Con la documentación
que proporcionamos aquí, debería ser capaz de configurarlo para que
funcione bien en la mayoría de los casos.
</Para>

<Sect3>
<Title>El «shaping» de CBQ en detalle</Title>

<Para>
Como dije antes, CBQ trabaja asegurándose de que el enlace está ocioso
sólo lo necesario para reducir el ancho de banda real hasta la tasa
configurada. Para hacerlo, calcula el tiempo que debería pasar entre los
paquetes medios.
</Para>

<Para>
Mientras opera, se mide el tiempo ocioso efectivo usando una media de
movimiento por exponencial proporcional (EWMA - exponential weighted moving
average), que considera los paquetes recientes exponencialmente más
importantes que los pasados. La media de carga de UNIX (loadaverage) se
calcula de la misma manera.
</Para>

<Para>
El tiempo ocioso calculado se resta al medido mediante EWMA, y el número
resultante se llama «avgidle». Un enlace cargado perfectamente tiene un
avgidle de cero: los paquetes llegan exactamente una vez cada intervalo
calculado.
</Para>

<Para>
Un enlace sobrecargado tiene un avgidle negativo y si se vuelve muy
negativo, CBQ lo cierra durante un rato y entonces se produce un
«sobrelímite».
</Para>

<Para>
Por el contrario, un enlace ocioso puede amasar un avgidle enorme, lo que
permitiría anchos de banda infinitos tras unas horas de silencio. Para
evitarlo, avgidle se trunca en maxidle.
</Para>

<Para>
Si hay un sobrelímite, en teoría, la CBQ debería acelerarse a sí misma
durante exactamente el tiempo que se ha calculado que pasa entre paquetes,
entonces pasa un paquete, y se acelera de nuevo. Pero lea más adelante
sobre el parámetro «minburst».
</Para>

<Para>
Estos son parámetros que puede especificar para configurar el ajuste:
<VariableList>

<VarListEntry>
<Term>avpkt</Term>
<ListItem>
<Para>
Tamaño medio de un paquete, medido en bytes. Se necesita para calcular
maxidle, que se deriva de maxburst, que va especificado en paquetes.
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>bandwidth</Term>
<ListItem>
<Para>
El ancho de banda físico de su dispositivo, necesario para cálculos de
tiempo ocioso.
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>cell</Term>
<ListItem>
<Para>
El tiempo que tarda un paquete en ser transmitido sobre un dispositivo
está escalonado, y se basa en el tamaño del paquete. Un paquete de tamaño
800 y uno de 806 pueden tardar lo mismo en ser enviados, por ejemplo (esto
establece la granularidad). A menudo está a "8". Debe ser una potencia
entera de dos.
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>maxburst</Term>
<ListItem>
<Para>
Este número de paquetes se usa para calcular maxidel de manera que cuando
avgidle esté a maxidel, se puede enviar una ráfaga de esta cantidad de
paquetes medios antes de que avgidle caiga a 0. Póngalo alto si quiere que
sea tolerante a ráfagas. No puede establecer maxidel directamente, sino
sólo mediante este parámetro.
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>minburst</Term>
<ListItem>
<Para>
Como se mencionó previamente, CBQ necesita acelerar en caso de
sobrelímite. La solución ideal es hacerlo exactamente durante el tiempo
ocioso calculado, y pasar un paquete. Sin embargo, los núcleos de Unix
normalmente lo pasan mal organizando eventos menores a 10ms, de manera que
es mejor acelerar durante un periodo algo mayor, y hacer pasar entonces
"minburst" paquetes de una sóla tanda, para después dormir "minburst"
veces más.
</Para>

<Para>
El tiempo de espera se denomina offtime. Los valores altos de minburst
llevan a ajustes más precisos a largo plazo, pero a ráfagas más grandes a
escala de milisegundos.
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>minidle</Term>
<ListItem>
<Para>
Si avgidle está por debajo de 0, estaremos en sobrelímite y necesitaremos
esperar hasta que avgidle sea suficientemente grande como para mandar un
paquete. Para prevenir una ráfaga súbita después de haber detenido el
enlace durante un periodo prolongado, avgidle se reinicia a minidle si cae
demasiado bajo.
</Para>

<Para>
Minidle se especifica en microsegundos negativos, de manera que 10
significa que avgidle se corta a -10us.
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>mpu</Term>
<ListItem>
<Para>
Tamaño mínimo del paquete (necesario porque incluso los paquetes de tamaño
cero se rellenan con 64 bytes en ethernet, y por tanto lleva cierto tiempo
transmitirlos). CBQ necesita saber esto para calcular de forma adecuada el
tiempo ocioso.
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>rate</Term>
<ListItem>
<Para>
La tasa deseada de tráfico saliente de esta qdisc (¡éste es el control de
velocidad!)
</Para></ListItem>
</VarListEntry>
</VariableList>
</Para>

<Para>
Internamente, CBQ tiene un montón de ajustes más precisos. Por ejemplo,
a las clases que se sabe no contienen datos encolados no se les pregunta.
Se penaliza a las clases sobrelimitadas reduciendo su prioridad efectiva.
Todo muy inteligente y complicado.
</Para>

</Sect3>

<Sect3>
<Title>Comportamiento de la CBQ con clases</Title>

<Para>
Aparte del ajuste, usando las aproximaciones de tiempo ocioso ya
mencionadas, CBQ también actúa igual que la cola PRIO en el sentido de que
sus clases pueden tener diferentes prioridades y que los números pequeños
de prioridad se examinan antes que los grandes.
</Para>

<Para>
Cada vez que la capa de hardware pide un paquete para enviarlo a la red,
se inicia un proceso de round robin por pesos («WRR»), comenzando por las
clases de prioridad con menor número.
</Para>

<Para>
Estas se agrupan y se les pregunta si tienen datos disponibles. En tal
caso, se devuelven. Después de que se haya permitido desencolar una serie
de bytes a una clase, se prueba con la siguiente clase de esa misma
prioridad.
</Para>

<Para>
Los siguientes parámetros controlan el proceso WRR:
<VariableList>

<VarListEntry>
<Term>allot</Term>
<ListItem>
<Para>
Cuando se le pide a la CBQ externa un paquete para enviar por la interfaz,
buscará por turnos en todas sus qdisc internas (en las clases), en el
orden del parámetro de «prioridad». Cada vez que le toca el turno a una
clase, sólo puede enviar una cantidad limitada de datos. «Allot» es la
unidad básica de esta cantidad. Vea el parámetro «weight» para más
información.
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>prio</Term>
<ListItem>
<Para>
La CBQ también puede actuar como un dispositivo PRIO. Primero se prueba
con las clases internas de mayor prioridad y mientras tengan tráfico, no
se mira en las otras clases.
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>weight</Term>
<ListItem>
<Para>
Weight ayuda en el proceso de Weighted Round Robin. Cada clase tiene una
oportunidad por turnos para enviar. Si tiene una clase con un ancho de
banda significativamente menor que las otras, tiene sentido permitirle
enviar más datos en su ronda que a las otras.
</Para>

<Para>
Una CBQ suma todos los pesos bajo una clase, y los normaliza, de manera
que puede usar números arbitrarios: sólo son importantes las equivalencias.
La gente viene usando «tasa/10» como regla general y parece que funciona
bien. El peso renormalizado se multiplica por el parámetro «allot» para
determinar cuántos datos se envían en una ronda.
</Para></ListItem>
</VarListEntry>
</VariableList>
</Para>

<Para>
¡Tenga en cuenta que todas las clases dentro de una jerarquía CBQ
necesitan compartir el mismo número mayor!
</Para>

</Sect3>

<Sect3>
<Title>Parámetros CBQ que determinan la compartición y préstamo de
enlaces</Title>

<Para>
Aparte de meramente limitar determinados tipos de tráfico, también es
posible especificar qué clases pueden tomar prestada capacidad de otras
clases o, al revés, prestar ancho de banda.
</Para>

<Para>
<VariableList>

<VarListEntry>
<Term>Isolated/sharing</Term>
<ListItem>
<Para>
Una clase que está configurada como «isolated» (aislada) no prestará ancho
de banda a sus hermanas. Uselo si tiene varios agentes competidores o
mutuamente hostiles sobre el enlace que no quieren dejarse espacio entre
sí.
</Para>

<Para>
El programa de control tc también conoce el «sharing», que es lo contrario
que «isolated».
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>bounded/borrow</Term>
<ListItem>
<Para>
Una clase también puede estar «bounded» (limitada), lo que significa que
no tratará de tomar ancho de banda prestado de sus clases hermanas. tc
también conoce «borrow», que es lo contrario de «bounded».
</Para></ListItem>
</VarListEntry>
</VariableList>
En una situación típica podríamos encontrarnos a dos agentes sobre un
mismo enlace que al mismo tiempo son «isolated» y «bounded», lo que
significa que están realmente limitadas a sus tasas aisladas, y que no
permitirán préstamos entre sí.
</Para>

<Para>
Junto a tales clases, puede haber otras que tengan permiso de ceder ancho
de banda.
</Para>

</Sect3>

<Sect3>
<Title>Configuración de ejemplo</Title>
<Screen>

               1:           qdisc raíz
               |
              1:1           clase hija
             /   \
            /     \
          1:3     1:4       clases terminales
           |       |
          30:     40:       qdisc
         (sfq)   (sfq)
</Screen>

<Para>
Esta configuración limita el tráfico del servidor web a 5mbit y el SMTP a
3mbit. Juntos, no pueden alcanzar más de 6mbit. Tenemos una NIC de 100mbit
y las clases pueden tomar ancho de banda prestado unas de otras.

<Screen>
# tc qdisc add dev eth0 root handle 1:0 cbq bandwidth 100Mbit         \
  avpkt 1000 cell 8
# tc class add dev eth0 parent 1:0 classid 1:1 cbq bandwidth 100Mbit  \
  rate 6Mbit weight 0.6Mbit prio 8 allot 1514 cell 8 maxburst 20      \
  avpkt 1000 bounded
</Screen>

Esta parte instala la raíz y la clase convenida 1:1. La clase 1:1 está
limitada, de manera que su ancho de banda no puede pasar de 6mbit.
</Para>

<Para>
Como se dijo antes, CBQ necesita un *montón* de ajustes. Todos los
parámetros quedaron explicados anteriormente, de todas maneras. La
configuración HTB correspondiente es mucho más sencilla.
</Para>

<Para>

<Screen>
# tc class add dev eth0 parent 1:1 classid 1:3 cbq bandwidth 100Mbit  \
  rate 5Mbit weight 0.5Mbit prio 5 allot 1514 cell 8 maxburst 20      \
  avpkt 1000                       
# tc class add dev eth0 parent 1:1 classid 1:4 cbq bandwidth 100Mbit  \
  rate 3Mbit weight 0.3Mbit prio 5 allot 1514 cell 8 maxburst 20      \
  avpkt 1000
</Screen>

</Para>

<Para>
Estas son nuestras dos clases terminales. Fíjese en cómo escalamos el peso
con la tasa configurada. Ninguna clase está limitada, pero están conectadas
a la clase 1:1, que sí lo está. De manera que la suma de anchos de banda de
las dos clases pasará nunca de 6mbit. ¡Por cierto!, los identificadores de
clase deben estar dentro del mismo número mayor que su qdisc madre.
</Para>

<Para>

<Screen>
# tc qdisc add dev eth0 parent 1:3 handle 30: sfq
# tc qdisc add dev eth0 parent 1:4 handle 40: sfq
</Screen>

</Para>

<Para>
Ambas clases llevan una qdisc FIFO por defecto. Pero las hemos reemplazado
con una cola SFQ de manera que cada flujo de datos sea tratado de igual
forma.

<Screen>
# tc filter add dev eth0 parent 1:0 protocol ip prio 1 u32 match ip \
  sport 80 0xffff flowid 1:3
# tc filter add dev eth0 parent 1:0 protocol ip prio 1 u32 match ip \
  sport 25 0xffff flowid 1:4
</Screen>

</Para>

<Para>
Estas órdenes, asociadas directamente a al raíz, envían el tráfico a las
qdisc correctas.
</Para>

<Para>
Fíjese que usamos «tc class add» para CREAR clases dentro de una qdisc,
pero que usamos «tc qdisc add» para añadir qdiscs a estas clases.
</Para>

<Para>
Puede preguntarse qué sucede al tráfico que no se clasifica en ninguna de
esasa dos reglas. Parecería que en este caso, los datos serán procesados
dentro de 1:0, y estarán sin límites.
</Para>

<Para>
Si el tráfico SMTP+web conjunto intenta exceder el límite impuesto de
6mbit/s, el ancho de banda se dividirá de acuerdo al parámetro de peso,
dando 5/8 del tráfico al servidor web y 3/8 al servidor de correo.
</Para>

<Para>
Con esta configuración también podemos decir que el tráfico del servidor
web tendrá como mínimo 5/8 * 6 mbit = 3.75 mbit.
</Para>

</Sect3>

<Sect3>
<Title>Otros parámetros de CBQ: split y defmap</Title>

<Para>
Como mencioné anteriormente, una qdisc con clases necesita llamar a los
filtros para determinar en qué clase encolar un paquete.
</Para>

<Para>
Aparte de llamar al filtro, CBQ ofrece otras opciones: defmap y split. Es
bastante complicado de entender, y no es vital. Pero como éste es el único
sitio conocido donde se explican adecuadamente defmap y split, intentaré
hacerlo lo mejor posible.
</Para>

<Para>
Como es probable que a menudo sólo quiera filtrar el Tipo de Servicio, se
proporciona una sintaxis especial. Cuando CBQ necesita averiguar dónde
encolar un paquete, comprueba si éste es un «split node». Si lo es, una de
las sub-qdisc ha indicado que desea recibir todos los paquetes con una
determinada prioridad, que se podría derivar del campo TOS, o por
opciones de socket establecidas por las aplicaciones.
</Para>

<Para>
Se hace un AND con los bit de prioridad de los paquetes y el campo defmap
para ver si coinciden. En otras palabras, es un atajo para crear filtros
muy rápidos, que sólo se ajustan a ciertas prioridades. Un defmap de ff
(hex) coincidirá con todo, un mapa de 0, con nada. Quizá una configuración
de ejemplo ayude a aclarar las cosas:
</Para>

<Para>

<Screen>
# tc qdisc add dev eth1 root handle 1: cbq bandwidth 10Mbit allot 1514 \
  cell 8 avpkt 1000 mpu 64
 
# tc class add dev eth1 parent 1:0 classid 1:1 cbq bandwidth 10Mbit    \
  rate 10Mbit allot 1514 cell 8 weight 1Mbit prio 8 maxburst 20        \
  avpkt 1000
</Screen>

Preámbulo estándar de CBQ. ¡Nunca me acostumbraré a la inmensa cantidad de
cosas que necesita!
</Para>

<Para>
Defmap se refiere a los bits TC_PRIO, que se definen así:
</Para>

<Para>

<Screen>
TC_PRIO..          Num  Corresponde al TOS
-------------------------------------------------
BESTEFFORT         0    Maximizar fiabilidad
FILLER             1    Minimizar coste
BULK               2    Maximizar transferencia (0x8)  
INTERACTIVE_BULK   4                               
INTERACTIVE        6    Minimizar retrasos (0x10)      
CONTROL            7                               
</Screen>

</Para>

<Para>
El número TC_PRIO.. se corresponde a bits, contando desde la derecha. Vea
la sección pfifo_fast si desea más detalles sobre cómo se convierten los
bits de TOS en prioridades.
</Para>

<Para>
Ahora, las clases interactiva y masiva:
</Para>

<Para>

<Screen>
# tc class add dev eth1 parent 1:1 classid 1:2 cbq bandwidth 10Mbit     \
  rate 1Mbit allot 1514 cell 8 weight 100Kbit prio 3 maxburst 20        \
  avpkt 1000 split 1:0 defmap c0

# tc class add dev eth1 parent 1:1 classid 1:3 cbq bandwidth 10Mbit     \
  rate 8Mbit allot 1514 cell 8 weight 800Kbit prio 7 maxburst 20        \
  avpkt 1000 split 1:0 defmap 3f
</Screen>

</Para>

<Para>
La «split qdisc» es la 1:0, que es donde se va a hacer la elección. C0 es
el valor binario 11000000, 3F es 00111111, de manera que entre los dos
coinciden con todo. La primera clase coincide con los bits 7 y 6, y por
tanto se corresponde con el tráfico «interactivo» y «de control». La
segunda clase coincide con el resto.
</Para>

<Para>
El nodo 1:0 tiene ahora una tabla como ésta:

<Screen>
prioridad	enviar a
0		1:3
1		1:3
2		1:3
3		1:3
4		1:3
5		1:3
6		1:2
7		1:2
</Screen>

</Para>

<Para>
Si desea más diversión, también puede pasar una «change mask» (máscara de
cambio), que indica qué prioridades desea cambiar. Sólo necesita usar esto
si está ejecutando «tc class change». Por ejemplo, para añadir los mejores
esfuerzos al tráfico de 1:2, podría ejecutar esto:
</Para>

<Para>

<Screen>
# tc class change dev eth1 classid 1:2 cbq defmap 01/01
</Screen>

</Para>

<Para>
El mapa de prioridades de 1:0 ahora es así:
</Para>

<Para>

<Screen>
prioridad	enviar a
0		1:2
1		1:3
2		1:3
3		1:3
4		1:3
5		1:3
6		1:2
7		1:2
</Screen>

</Para>

<Para>
FIMXE: no he probado «tc class change», sólo he mirado los fuentes.
</Para>

</Sect3>

</Sect2>

<Sect2>
<Title>Hierarchical Token Bucket</Title>

<Para>
Martin Devera (&lt;devik&gt;) se dio cuenta de que CBQ es complejo y que
no parece óptimo en varias situaciones típicas. Su enfoque Jerárquico se
ajusta bien a configuraciones donde se tiene una cantidad fija de ancho de
banda a dividir para diferentes propósitos, dándole a cada propósito un
ancho de banda garantizado, con la posibilidad de especificar cuánto ancho
se puede tomar prestado.
</Para>

<Para>
HTB funciona igual que CBQ, pero no recurre a cálculos de tiempo ocioso
para los ajustes. En su lugar, es un Token Bucket Filter con clases (de
ahí el nombre). Sólo tiene unos pocos parámetros que están bien
documentados en su
<ULink URL="http://luxik.cdi.cz/~devik/qos/htb/">sitio</ULink>.
</Para>

<Para>
Según se complique su configuración HTB, verá que escala bien. ¡Con CBQ
ya es complejo incluso en casos simples! HTB3 (vea los detalles sobre las
versiones de HTB en
<ulink url="http://luxik.cdi.cz/~devik/qos/htb/">su página web</ulink>) es
ahora parte de las fuentes oficiales del núcleo (desde 2.4.20-pre1 y
2.5.31 en adelante). Sin embargo, quizá necesite una versión de «tc»
parcheada para HTB3: la versión de las partes del núcleo y espacio de
usuario de HTB3 deben tener el mismo número mayor, o «tc» no trabajará con
HTB.

</Para>

<Para>
Si ya tiene un núcleo moderno, o está en posición de parchear el núcleo,
considere seriamente usar HTB.
</para>


<Sect3>
<Title>Configuración de ejemplo</Title>

<Para>
Funcionalmente es casi idéntica a la configuración de ejemplo anterior de
CBQ:
</Para>

<Para>

<Screen>
# tc qdisc add dev eth0 root handle 1: htb default 30

# tc class add dev eth0 parent 1: classid 1:1 htb rate 6mbit burst 15k

# tc class add dev eth0 parent 1:1 classid 1:10 htb rate 5mbit burst 15k
# tc class add dev eth0 parent 1:1 classid 1:20 htb rate 3mbit ceil 6mbit burst 15k
# tc class add dev eth0 parent 1:1 classid 1:30 htb rate 1kbit ceil 6mbit burst 15k </Screen>

</Para>

<Para>
El autor recomienda SFQ por debajo de estas clases:

<Screen>
# tc qdisc add dev eth0 parent 1:10 handle 10: sfq perturb 10
# tc qdisc add dev eth0 parent 1:20 handle 20: sfq perturb 10
# tc qdisc add dev eth0 parent 1:30 handle 30: sfq perturb 10
</Screen>
 
</Para>

<Para>
Añada los filtros que dirigirán el tráfico a las clases correctas:

<Screen>
# U32="tc filter add dev eth0 protocol ip parent 1:0 prio 1 u32"
# $U32 match ip dport 80 0xffff flowid 1:10
# $U32 match ip sport 25 0xffff flowid 1:20
</Screen>

Y esto es todo (nada de números desagradables sin explicación, ni
parámetros sin documentar).
</Para>

<Para>
Realmente, HTB parece maravilloso (si 10: y 20: tienen ambos su ancho de
banda garantizado, y se deja más a dividir, tomarán prestado en una
relación de 5:3, tal como cabría esperar).
</Para>

<Para>
El tráfico sin clasificar va a parar a 30:, que tiene poco ancho de banda
por sí mismo, pero que puede tomar prestado todo lo que queda. Como hemos
escogido SFQ internamente, ¡de paso obtendremos equitatividad!
</Para>

</Sect3>

</Sect2>

</Sect1>

<Sect1 id="lartc.qdisc.filters">
  <Title>Clasificar paquetes con filtros</Title>

<Para>
Para determinar qué clase deberá procesar un paquete, se llama a una
«cadena clasificadora» cada vez que hay que tomar una decisión. Esta
cadena consiste en todos los filtros asociados a la qdisc con clases que
debe decidir.
</Para>

<Para>Repitamos el árbol, que no es un árbol:
</Para>

<Screen width="80">
                    root 1:
                      |
                    _1:1_
                   /  |  \
                  /   |   \
                 /    |    \
               10:   11:   12:
              /   \       /   \
           10:1  10:2   12:1  12:2
</Screen>

<Para>
Cuando encolamos un paquete, se consulta la cadena de filtros para cada
rama para que de las instrucciones relevantes. Una configuración típica
podría tener un filtro en 1:1 que dirija un paquete a 12:, y uno en 12:
que envíe el paquete a 12:2.
</Para>

<Para>
También podría asociar esta última regla a 1:1, pero puede ganar
eficiencia haciendo pruebas más específicas más abajo en la cadena.
</Para>

<Para>
No se puede filtrar un paquete "hacia arriba", por cierto. Además, con
HTB, ¡debería asociar todos los filtros a la raíz!
</Para>

<Para>
Y de nuevo: ¡los paquetes sólo se encolan hacia abajo! Cuando se
desencolan, vuelven hacia arriba, donde está la interfaz. ¡No caen desde
el final del árbol directamente al adaptador de red!
</Para>

<Sect2>
<Title>Algunos ejemplos sencillos de filtrado</Title>

<Para>
Como se explicó en el capítulo del Clasificador, puede hacer coincidencias
con literalmente cualquier cosa, usando una sintaxis bastante complicada.
Para empezar, le mostraremos cómo hacer cosas obvias, que por suerte es
muy sencillo.
</Para>

<Para>
Digamos que tenemos una qdisc PRIO llamada «10:» que contiene tres clases,
y queremos asignar todo el tráfico desde y hacia el puerto 22 a la banda
de prioridad más alta. Los filtros podrían ser:
</Para>

<Para>

<Screen>
# tc filter add dev eth0 protocol ip parent 10: prio 1 u32 match \ 
  ip dport 22 0xffff flowid 10:1
# tc filter add dev eth0 protocol ip parent 10: prio 1 u32 match \
  ip sport 80 0xffff flowid 10:1
# tc filter add dev eth0 protocol ip parent 10: prio 2 flowid 10:2
</Screen>

</Para>

<Para>
¿Qué dice esto? Dice: asociar a eth0, nodo 10: un filtro u32 de prioridad
1 que coincide *exactamente* con el puerto IP de destino 22 y enviarlo a la
banda 10:1. Y luego repetimos lo mismo para el puerto de origen 80. La
última orden dice que cualquier cosa que no coincida debería ir a la banda
10:2, la de siguiente prioridad.
</Para>

<Para>
Necesita añadir «eth0», o como sea que se llame la interfaz, porque cada
interfaz tiene un espacio de controladores propio.
</Para>

<Para>
Para escoger sobre una dirección IP, use esto:

<Screen>
# tc filter add dev eth0 parent 10:0 protocol ip prio 1 u32 \ 
  match ip dst 4.3.2.1/32 flowid 10:1
# tc filter add dev eth0 parent 10:0 protocol ip prio 1 u32 \
  match ip src 1.2.3.4/32 flowid 10:1
# tc filter add dev eth0 protocol ip parent 10: prio 2      \
  flowid 10:2
</Screen>

</Para>

<Para>
Esto asigna el tráfico hacia 4.3.2.1 y desde 1.2.3.4 a la cola de más alta
prioridad, y el resto a la de siguiente prioridad.
</Para>

<Para>
Puede concatenar coincidencias, para capturar el tráfico desde 1.2.3.4,
puerto 80. Se hace así:

<Screen>
# tc filter add dev eth0 parent 10:0 protocol ip prio 1 u32 match ip src 4.3.2.1/32
  match ip sport 80 0xffff flowid 10:1
</Screen>

</Para>

</Sect2>

<Sect2 id="lartc.filtering.simple">
<Title>Todas las órdenes de filtrado que necesitará normalmente</Title>

<Para>
La mayoría de las órdenes de ajuste que se presentan aquí empiezan con
éste preámbulo:

<Screen>
# tc filter add dev eth0 parent 1:0 protocol ip prio 1 u32 ..
</Screen>

Estas son las coincidencias llamadas «u32», que pueden coincidir con
CUALQUIER parte de un paquete.
<VariableList>

<VarListEntry>
<Term>Sobre la dirección de origen/destino</Term>
<ListItem>
<Para>
Máscara de origen «match ip src 1.2.3.0/24», máscara de destino «match ip
dst 4.3.2.0/24». Para coincidir con una única máquina, use /32 u omita la
máscara.
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>Sobre puerto de origen/destino, todos los protocolos de IP</Term>
<ListItem>
<Para>
Origen: «match ip sport 80 0xffff», destino: «match ip dport 0xffff»
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>Sobre protocolo IP (tcp, udp, icmp, gre, ipsec)</Term>
<ListItem>
<Para>
Use los números de /etc/protocols. Por ejemplo, icmp es 1: «match ip
protocol 1 0xff».
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>Sobre fwmark</Term>
<ListItem>
<Para>
Puede marcar los paquetes tanto con ipchains como con iptables y hacer que
la marca sobreviva al rutado a través de interfaces. Esto es realmente
útil para por ejemplo ajustar el tráfico de eth1 sólo si viene de eth0.
Sintaxis:
<screen>
# tc filter add dev eth1 protocol ip parent 1:0 prio 1 handle 6 fw flowid
1:1
</screen>
¡Fíjese que ésta no es una coincidencia u32!
</Para>

<Para>
Puede poner una marca así:

<Screen>
# iptables -A PREROUTING -t mangle -i eth0 -j MARK --set-mark 6
</Screen>

El número 6 es arbitrario.
</Para>

<Para>
Si no desea entender toda la sintaxis de tc, limítese a usar iptables, y
aprenda sólo a seleccionar sobre fwmark.
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>Sobre el campo TOS</Term>
<ListItem>
<Para>
Para escoger el tráfico interactivo, de retraso mínimo:

<Screen>
# tc filter add dev ppp0 parent 1:0 protocol ip prio 10 u32 \
      match ip tos 0x10 0xff \
     flowid 1:4
</Screen>

Use 0x08 0xff para el tráfico masivo.
</Para></ListItem>
</VarListEntry>
</VariableList>
</Para>

<Para>
Si desea ver más órdenes de filtrado, vea el capítulo de Filtros
avanzados.
</Para>

</Sect2>

</Sect1>
<Sect1 id="lartc.imq">
<Title>El dispositivo intermedio de encolado (IMQ)</Title>

<Para>
El dispositivo intermedio de encolado (Intermediate queueing device) no es
una qdisc pero su uso está muy unido a las qdisc. Dentro de Linux, las
qdisc se asocian a dispositivos de red y todo lo que se encola en el
dispositivo se encola antes en la qdisc. Partiendo de este concepto,
surgen dos limitaciones:
</Para>

<Para>
1. Sólo se pueden hacer ajustes de salida (existe una qdisc de entrada,
pero sus posibilidades son muy limitadas comparadas a las qdisc con
clases).
</Para>

<Para>
2. Una qdisc sólo puede ver el tráfico de una interfaz, de manera que no
se pueden imponer limitaciones globales.
</Para>

<Para>
IMQ está aquí para resolver ambas limitaciones. En breve, se puede poner
todo lo que se quiera en una qdisc. Los paquetes marcados de forma
especial los interceptan las ranuras NF_IP_PRE_ROUTING y
NF_IP_POST_ROUTING de netfilter y pasan por una qdisc asociada a un
dispositivo imq. Se usa un objetivo de iptables para marcar los paquetes.
</Para>

<Para>
Esto permite que haga ajustes de entrada ya que puede marcar los paquetes
que vienen de cualquier sitio o tratar las interfaces como clases para
imponer límites globales. También puede hacer muchas otras cosas como
poner el tráfico http en una qdisc, poner las peticiones de conexiones
nuevas en una qdisc, ...
</Para>

<Sect2>
<Title>Configuración de ejemplo</Title>

<Para>
La primera cosa que me viene a la mente es usar el ajuste de entrada para
darnos a nosotros mismos un ancho de banda garantizado. ;)
La configuración es igual que la de cualquier otra interfaz:

<Screen>
tc qdisc add dev imq0 root handle 1: htb default 20

tc class add dev imq0 parent 1: classid 1:1 htb rate 2mbit burst 15k

tc class add dev imq0 parent 1:1 classid 1:10 htb rate 1mbit
tc class add dev imq0 parent 1:1 classid 1:20 htb rate 1mbit

tc qdisc add dev imq0 parent 1:10 handle 10: pfifo
tc qdisc add dev imq0 parent 1:20 handle 20: sfq

tc filter add dev imq0 parent 10:0 protocol ip prio 1 u32 match \
		ip dst 10.0.0.230/32 flowid 1:10
</Screen>

En este ejemplo, se usa u32 para la clasificación. Otros clasificadores
podrían funcionar como queremos. Lo siguiente es escoger y marcar el
tráfico para encolarlo en imq0.

<Screen>
iptables -t mangle -A PREROUTING -i eth0 -j IMQ --todev 0

ip link set imq0 up
</Screen>

</Para>

<Para>
Los objetivos IMQ de iptables son válidos en las cadenas PREROUTING y
POSTROUTING de la tabla mangle. Su sintaxis es

<Screen>
IMQ [ --todev n ]	n : número del dispositivo imq
</Screen>

También se proporciona un objetivo para ip6tables.
</Para>

<Para>
Tenga en cuenta que el tráfico no se encola cuando coincide con el
objetivo, sino después. La localización exacta del punto donde el tráfico
entra en el dispositivo imq depende de la dirección del tráfico
(entrada/salida).
Estas son las ranuras predefinidas de netfilter que usa iptables:

<Screen>
enum nf_ip_hook_priorities {
        NF_IP_PRI_FIRST = INT_MIN,
        NF_IP_PRI_CONNTRACK = -200,
        NF_IP_PRI_MANGLE = -150,
        NF_IP_PRI_NAT_DST = -100,
        NF_IP_PRI_FILTER = 0,
        NF_IP_PRI_NAT_SRC = 100,
        NF_IP_PRI_LAST = INT_MAX,
};
</Screen>

</Para>

<Para>
Para el tráfico de entrada, imp se registra con prioridad NF_IP_PRI_MANGLE
+ 1, lo que significa que los paquetes entran en el dispositivo imq justo
después de que se haya pasado de la cadena PREROUTING de mangle.
</Para>

<Para>
Para la salida imq usa NF_IP_PRI_LAST, que obedece al hecho de que los
paquetes eliminados por la tabla filter no deben ocupar ancho de banda.
</Para>

<Para>
Encontrará parches e información en el
<ULink
URL="http://luxik.cdi.cz/~patrick/imq/"
>sitio de imq</ULink>.
</Para>

</Sect2>

</Sect1>

</chapter>

<chapter id="lartc.loadshare">
<Title>Compartir la carga sobre varias interfaces</Title>

<Para>
Hay varias maneras de hacer esto. Una de las más sencillas y directas es
«TEQL» ("True" - o "trivial" - link equalizer). Como la mayoría de las
cosas que tienen que ver con las colas, la división de cargas va en ambos
sentidos. Puede que ambos extremos del enlace deban participar para
conseguir un efecto completo.
</Para>

<Para>
Imagine esta situación:
</Para>

<Para>

<Screen>
                 +-------+   eth1   +-------+
                 |       |==========|       |
     'red 1' ----|   A   |          |   B   |---- 'red 2'
                 |       |==========|       |
                 +-------+   eth2   +-------+
</Screen>

</Para>

<Para>
A y B son routers, y por el momento asumiremos que ambos funcionan con
Linux. Si el tráfico va de la red 1 a la red 2, el router A necesita
distribuir los paquetes sobre ambos enlaces hacia B. Se necesita
configurar el router B para que acepte esto. Lo mismo sucede en la otra
dirección: cuando los paquetes van desde la red 2 a la red 1, el router B
necesita enviar paquetes tanto sobre eth1 como eth2.
</Para>

<Para>
La parte de distribución la hace un dispositivo «TEQL», así (no podría ser
más sencillo):
</Para>

<Para>

<Screen>
# tc qdisc add dev eth1 root teql0
# tc qdisc add dev eth2 root teql0
# ip link set dev teql0 up
</Screen>

</Para>

<Para>
¡No olvide la orden «ip link set up»!
</Para>

<Para>
Esto debe hacerse en ambas máquinas. El dispositivo teql0 básicamente es
un distribuidor roundrobin sobre eth1 y eth2, para enviar paquetes. Nunca
aparecerán datos viniendo por un dispositivo teql, sino que simplemente
aparecen en las eth1 y eth2 "básicas".
</Para>

<Para>
Pero ahora sólo tenemos dispositivos, de manera que necesitamos hacer un
rutado adecuado. Una manera de hacerlo es asignar una red /31 para ambos
enlaces, y también al dispositivo teql0.
</Para>

<Para>
En el router A:

<Screen>
# ip addr add dev eth1 10.0.0.0/31
# ip addr add dev eth2 10.0.0.2/31
# ip addr add dev teql0 10.0.0.4/31
</Screen>

</Para>

<Para>
En el router B:

<Screen>
# ip addr add dev eth1 10.0.0.1/31
# ip addr add dev eth2 10.0.0.3/31
# ip addr add dev teql0 10.0.0.5/31
</Screen>

</Para>

<Para>
El router A debería ser capaz ahora de hacer ping a 10.0.0.1, 10.0.0.3 y
10.0.0.5 sobre los dos enlaces reales y el ecualizado. El router B debería
ser capaz de hacer ping a 10.0.0.0, 10.0.0.2 y 10.0.0.4 sobre los enlaces.
</Para>

<Para>
Si esto funciona, el router A debería hacer que 10.0.0.5 sea su ruta para
alcanzar la red 2, y el router B debería hacer de 10.0.0.4 su ruta para
alcanzar la red 1. Para el caso especial en que la red 1 sea su red casera
y la red 2 Internet, el router A debería hacer de 10.0.0.5 su ruta por
defecto.
</Para>

<Sect1 id="lartc.loadshare.caveats">
  <Title>Problemas</Title>

<Para>
Nada es tan fácil como parece. Se necesita desactivar el filtrado de
ruta de vuelta (return path filtering) en eth1 y eth2 de ambos router,
porque en caso contrario descartarán los paquetes destinados direcciones
IP que no sean las suyas:
</Para>

<Para>

<Screen>
# echo 0 &#62; /proc/sys/net/ipv4/conf/eth1/rp_filter
# echo 0 &#62; /proc/sys/net/ipv4/conf/eth2/rp_filter
</Screen>

</Para>

<Para>
Entonces nos encontramos con el desagradable problema de la reordenación
de paquetes. Digamos que A envía 6 paquetes a B (eth1 podría llevar los 1,
3 y 5. eth2 llevaría entonces los 2, 4 y 6). En un mundo ideal, el router
B los recibiría en este orden, 1, 2, 3, 4, 5, 6. Pero hay una posibilidad
muy cierta de que el núcleo haga esto: 2, 1, 4, 3, 6, 5. El problema es
que esto confunde a TCP/IP. Mientras que esto no es un problema para
enlaces que llevan sesiones TCP/IP diferentes, no será capaz de juntar
varios enlaces y conseguir enviar un único fichero por ftp mucho más
rápido, a menos que el SO emisor o receptor sea Linux, que no se asusta
fácilmente por un reordenado sencillo.
</Para>

<Para>
Sin embargo, para muchas aplicaciones, el equilibrio de carga sobre
enlaces es una gran idea.
</Para>

</Sect1>
<Sect1 id="lartc.loadshare.other">
  <Title>Otras posibilidades</Title>
<para>
William Stearns ha usado una configuración avanzada de túneles para
conseguir un buen uso simultáneo de varias conexiones de internet sin
relación entre ellas. Puede encontrarlo en
<ULink
URL="http://www.stearns.org/tunnel/">su página sobre túneles</ULink>.
</para>
<para>
Puede que en el futuro este Cómo diga más cosas a este respecto.
</para>
</Sect1>
</chapter>

<chapter id="lartc.netfilter">
<Title>Netfilter e iproute (marcado de paquetes)</Title>

<Para>
Hasta ahora hemos visto cómo funciona iproute, y hemos mencionado algunas
veces netfilter. Este podría ser un buen momento para mirar las <ULink
URL="http://netfilter.samba.org/unreliable-guides/"
>Rusty's Remarkably Unreliable Guides</ULink
>. Netfilter en sí lo puede encontrar <ULink
URL="http://netfilter.filewatcher.org/"
>aquí</ULink
>.
</Para>

<Para>
Netfilter nos permite filtrar paquetes, o cambiar sus cabeceras. Una
capacidad especial es que podemos marcar un paquete con un número. Esto se
hace con la estructura --set-mark.
</Para>

<Para>
Como ejemplo, esta orden marca todos los paquetes destinados al puerto 25,
correo saliente:
</Para>

<Para>

<Screen>
# iptables -A PREROUTING -i eth0 -t mangle -p tcp --dport 25 \
 -j MARK --set-mark 1
</Screen>

</Para>

<Para>
Ahora digamos que tenemos varias conexiones, una que es rápida (y cara,
por megabyte), y otra más lenta, pero de tarifa fija. Lo más seguro es que
queramos hacer salir el correo mediante la ruta barata.
</Para>

<Para>
Ya hemos marcado los paquetes con un «1», y ahora le daremos instrucciones
a la base de normas de rutado para que actúe sobre esto:
</Para>

<Para>

<Screen>
# echo 201 mail.out &#62;&#62; /etc/iproute2/rt_tables
# ip rule add fwmark 1 table correo.salida
# ip rule ls
0:	from all lookup local 
32764:	from all fwmark        1 lookup correo.salida
32766:	from all lookup main 
32767:	from all lookup default 
</Screen>

</Para>

<Para>
Ahora generaremos la tabla correo.salida con una ruta al enlace lento pero
barato:

<Screen>
# /sbin/ip route add default via 195.96.98.253 dev ppp0 table# correo.salida
</Screen>

</Para>

<Para>
Y ya está. Si quisiéramos hacer algunas excepciones, hay muchas maneras de
conseguirlo. Podemos modificar la orden de netfilter para excluir ciertas
máquinas, o podemos insertar una regla con mayor prioridad que apunte a la
tabla principal para dichas máquinas.
</Para>

<Para>
También podemos usar esta características para obedecer a los bits TOS
marcando los paquetes con un tipo diferente de servicio con diferentes
números, y creando reglas que actúen sobre esto. De esta manera podría
dedicar, digamos, una línea RDSI a las sesiones interactivas.
</Para>

<Para>
No hace falta decir que esto funciona bien en una máquina que esté
haciendo NAT («enmascaramiento»).
</Para>

<Para>
IMPORTANTE: Hemos recibido informes de que al menos MASQ y SNAT colisionan
con el marcado de paquetes. Rusty Russell lo explica en
<ULink
URL="http://lists.samba.org/pipermail/netfilter/2000-November/006089.html"
>este mensaje</ULink
>. Deshabilite el filtro de ruta inversa (reverse path filter) para que
funcione correctamente.
</Para>

<Para>
Nota: para marcar paquetes, necesita activar algunas opciones en el
núcleo:
</Para>

<Para>

<Screen>
IP: advanced router (CONFIG_IP_ADVANCED_ROUTER) [Y/n/?]
IP: policy routing (CONFIG_IP_MULTIPLE_TABLES) [Y/n/?]
IP: use netfilter MARK value as routing key (CONFIG_IP_ROUTE_FWMARK) [Y/n/?]
</Screen>

</Para>

<Para>
Vea también el <xref linkend="lartc.cookbook.squid"> en el
<citetitle><xref linkend="lartc.cookbook"></citetitle>.
</Para>

</chapter>

<chapter id="lartc.adv-filter"
  xreflabel="Advanced filters for (re-)classifying packets">
  <Title>Filtros avanzados para (re)clasificar paquetes</Title>

<Para>
Como se explicó en la sección de disciplinas de cola con clases, se
necesitan filtros para clasificar los paquetes en cualquiera de las
subcolas. Estos filtros se llaman desde dentro de las qdisc con clases.
</Para>

<Para>
Aquí tiene una lista incompleta de los clasificadores disponibles:
<VariableList>

<VarListEntry>
<Term>fw</Term>
<ListItem>
<Para>
Basa la decisión en la forma en que el cortafuegos ha marcado el paquete.
Es una manera sencilla si no quiere aprender la sintaxis de filtros de tc.
Vea el capítulo de Colas para más detalles.
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>u32</Term>
<ListItem>
<Para>
Basa la decisión en campos del interior del paquete (dirección IP de
origen, etc)
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>route</Term>
<ListItem>
<Para>
Basa la decisión en la ruta a la que será enviado el paquete.
Bases the decision on which route the packet will be routed by
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>rsvp, rsvp6</Term>
<ListItem>
<Para>
Encamina los paquetes basándose en <ULink
URL="http://www.isi.edu/div7/rsvp/overview.html"
>RSVP </ULink
>. Sólo es útil
en las redes que usted controle (Internet no respeta RSVP).
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>tcindex</Term>
<ListItem>
<Para>
Se usa con la qdisc DSMARK. Vea la sección relevante.
</Para></ListItem>
</VarListEntry>
</VariableList>
</Para>

<Para>
Fíjese que en general hay muchas maneras de clasificar los paquetes y que
generalmente el sistema de que desea usar se reduce a sus preferencias.
</Para>

<Para>
En general los clasificadores aceptan unos pocos argumentos comunes.
Aparecen aquí por conveniencia:
</Para>

<Para>
<VariableList>

<VarListEntry>
<Term>protocol</Term>
<ListItem>
<Para>
El protocolo que aceptará este clasificador. Generalmente sólo querrá
aceptar tráfico IP. Se requiere.
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>parent</Term>
<ListItem>
<Para>
El controlador al que estará asociado este clasificador. Este controlador
debe ser una clase ya existente. Requerido.
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>prio</Term>
<ListItem>
<Para>
La prioridad de este clasificador. Los números más bajos se comprueban
antes.
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>handle</Term>
<ListItem>
<Para>
Este controlador significa cosas diferentes para filtros diferentes.
</Para></ListItem>
</VarListEntry>
</VariableList>
</Para>

<Para>
Todas las secciones que siguen asumen que está intentando dar forma al
tráfico que va hacia <Literal remap="tt">MáquinaA</Literal>. Asumen que se
ha configurado la clase raíz en 1: y que la clase a la que desea enviar el
tráfico elegido es 1:1.
</Para>

<Sect1 id="lartc.adv-filter.u32">
  <Title>El clasificador <option>u32</option></Title>

<Para>
El filtro U32 es el más avanzado disponible en la implementación actual.
Se basa completamente en tablas hash, lo que lo hace robusto cuando hay
muchas reglas de filtrado.
</Para>

<Para>
En su forma más simple el filtro U32 es una lista de registros,
consistente cada una en dos campos: un selector y una acción. Los
selectores, descritos más adelante, se comparan con el paquete IP que se
está procesando hasta encontrar la primera coincidencia, y entonces se
ejecuta la acción asociada. El tipo más sencillo de acción sería dirijir
el paquete en una clase CBQ definida.
</Para>

<Para>
La línea de órdenes del programa <Literal remap="tt">tc filter</Literal>,
que se usa para configura el filtro, consiste en tres partes:
especificación del filtro, selector y acción. La especificación del filtro
puede definirse así:
</Para>

<Para>

<Screen>
tc filter add dev IF [ protocol PROTO ]
                     [ (preference|priority) PRIO ]
                     [ parent CBQ ]
</Screen>

</Para>

<Para>
El campo <Literal remap="tt">protocol</Literal> describe el protocolo al
que se aplicará el filtro. Sólo comentaremos el caso del protocolo
<Literal remap="tt">ip</Literal>. El campo <Literal
remap="tt">preference</Literal> (alternativamente se puede usar <Literal
remap="tt">priority</Literal>) establece la prioridad del filtro escogido.
Esto es importante, porque puede tener varios filtros (listas de reglas)
con diferentes prioridades. Se pasará por cada lista en el orden en que se
agreguen las reglas, y entonces se procesarán las listas de menor
prioridad (numero "preference" más alto). El campo <Literal
remap="tt">parent</Literal> define la cima del árbol CBQ (por ejemplo,
1:0), a la que se asociará el filtro.
</Para>

<Para>
Las opciones descritas anterioremente se aplican a todos los filtros, no
sólo a los U32.
</Para>

<Sect2>
<Title>Selector U32</Title>

<Para>
El selector U32 contiene definiciones de los patrones, que serán
comparados con el paquete procesado en cada momento. Para ser más
precisos, define qué bits hay que comparar en la cabecera del paquete y
nada más, pero este método sencillo es muy poderoso. Veamos los ejemplos
siguientes, tomados directamente de un filtro muy complejo, del mundo
real:
</Para>

<Para>

<Screen>
# tc filter add dev eth0 protocol ip parent 1:0 pref 10 u32 \
  match u32 00100000 00ff0000 at 0 flowid 1:10
</Screen>

</Para>

<Para>
Por ahora, olvidémonos de la primera línea (todos estos parámetros
describen las tablas hash del filtro). Centrémonos en la línea del
selector, que contiene la palabra clave <Literal
remap="tt">match</Literal>. Este selector coincidirá con cabeceras IP cuyo
segundo byte sea 0x10 (0010). Como puede adivinar, el número 00ff es la
máscara de comparación, que le dice al filtro qué bits exactamente tiene
que comparar. Aquí es 0xff, de manera que el byte coincidirá si es
exactamente 0x10. La clave <Literal remap="tt">at</Literal> indica que la
coincidencia debe comenzar en un desplazamiento específico (en bytes) (en
este caso, al principio del paquete). Traduciendo todo esto a lenguaje
humano, el paquete coincidirá si su campo Tipo de Servicio tiene los bits
de «poco retraso» activos. Analicemos otra regla:
</Para>

<Para>

<Screen>
# tc filter add dev eth0 protocol ip parent 1:0 pref 10 u32 \
  match u32 00000016 0000ffff at nexthdr+0 flowid 1:10
</Screen>

</Para>

<Para>
La opción <Literal remap="tt">nexthdr</Literal> indica la siguiente
cabecera encapsulada en el paquete IP, esto es, la cabecera del protocolo
de la capa superior. La coincidencia también debe empezar al principio de
la siguiente cabecera. La coincidencia debería ocurrir en la segunda
palabra de 32 bits te la cabecera. En los protocolos TCP y UDP este campo
contiene el puerto de destino del paquete. El puerto se da en formato
big-endian, es decir, los bits más significativos primero, de manera que
simplemente leemos 0x0016 como 22 decimal, lo que indicaría el servicio SSH
si fuera TCP. Como puede adivinar, esta coincidencia es ambigua sin un
contexto, y de eso hablaremos más tarde.
</Para>

<Para>
Habiendo entendido todo lo anterior, encontraremos fácil de leer el
siguiente selector: <Literal remap="tt">match c0a80100 ffffff00 at
16</Literal>. Lo que tenemos aquí es una coincidencia de tres bytes
partiendo del decimoséptimo byte, contando desde el principio de la
cabecera IP. Coincidirá con los paquetes cuya dirección de destino sea
cualquiera dentro de la red 192.168.1/24. Tras analizar los ejemplo,
podemos resumir lo que hemos aprendido.
</Para>

</Sect2>

<Sect2>
<Title>Selectores generales</Title>

<Para>
Los selectores generales definen el patrón, máscara y desplazamiento del
patrón que será comparado con el contenido del paquete. Usando los
selectores generales se puede coincidir con virtualmente cualquier bit de
la cabecera IP (o capas superiores). Sin embargo, son más difíciles de
leer y escribir que los selectores específicos descritos más adelante. La
sintaxis general del selector es:
</Para>

<Para>

<Screen>
match [ u32 | u16 | u8 ] PATRON MASCARA [ at DESPL | nexthdr+DESPL]
</Screen>

</Para>

<Para>
Una de las palabras clave <Literal remap="tt">u32</Literal>, <Literal
remap="tt">u16</Literal> o <Literal remap="tt">u8</Literal> especifica la
longitud en bits de los patrones. Deberían seguirle PATRON y MASCARA, de
la longitud definida por la palabra clave anterior. El parámetro DESPL es
el desplazamiento, en bytes, desde donde empezar a comparar. Si se da la
palabra clave <Literal remap="tt">nexthdr+</Literal>, el desplazamiento es
relativo al inicio de una cabecera de capa superior.
</Para>

<Para>
Algunos ejemplos:
</Para>

<Para>

<Screen>
# tc filter add dev ppp14 parent 1:0 prio 10 u32 \
     match u8 64 0xff at 8 \
     flowid 1:4
</Screen>

</Para>

<Para>
Un paquete coincidirá con esta regla si su tiempo de vida (TTL) es 64.
TTL es el campo que empieza justo después del octavo byte de la cabecera
IP.
</Para>


<Para>
Coincide con todos los paqutes TCP que tienen activo el bit ACK:
</Para>

<Para>

<Screen>
# tc filter add dev ppp14 parent 1:0 prio 10 u32 \
     match ip protocol 6 0xff \
     match u8 0x10 0xff at nexthdr+13 \
     flowid 1:3 
</Screen>

</Para>

<Para>
Use esto para capturar los ACK en paquetes menores de 64 bytes:
</Para>

<Para>

<Screen>
## captura de acks a la manera difícil:
## IP protocol 6,
## IP header length 0x5(32 bit words),
## IP Total length 0x34 (ACK + 12 bytes of TCP options)
## TCP ack set (bit 5, offset 33)
# tc filter add dev ppp14 parent 1:0 protocol ip prio 10 u32 \
            match ip protocol 6 0xff \
            match u8 0x05 0x0f at 0 \
            match u16 0x0000 0xffc0 at 2 \
            match u8 0x10 0xff at 33 \
            flowid 1:3
</Screen>

</Para>

<Para>
Esta regla sólo coincidirá con paquetes TCP cuando esté activo el bit ACK,
y no haya contenido. Aquí podemos ver un ejemplo de uso de dos selectores,
siendo el resultado final el AND lógico de sus resultados. Si echamos un
vistazo al diagrama de la cabecera TCP, podemos ver que el bit ACK es el
tercer bit de más peso (0x10) en el catorceavo byte de la cabecera TCP
(<Literal remap="tt">at nexthdr+13</Literal>). En lo que respecta al
segundo selector, si quisiéramos hacernos la vida más complicada,
podríamos escribir <Literal remap="tt">match u8 0x06 0xff at 9</Literal>
en lugar de usar el selector específico <Literal remap="tt">protocol
tcp</Literal>, porque 6 es el número del protocolo TCP, presente en el
décimo byte de la cabecera IP. Por otro lado, en este ejemplo no podríamos
usar selectores específicos para la primera coincidencia (simplemente
porque no hay selectores específicos para el bit ACK de TCP).
</Para>

<Para>
El siguiente filtro es una versión modificada del filtro anterior. La
diferencia está en que no comprueba la longitud de la cabecera. ¿Por qué?
Porque el filtro anterior sólo funciona en máquinas de 32 bits.
</Para>

<Para>

<Screen>
tc filter add dev ppp14 parent 1:0 protocol ip prio 10 u32 \
     match ip protocol 6 0xff \
     match u8 0x10 0xff at nexthdr+13 \
     match u16 0x0000 0xffc0 at 2 \
     flowid 1:3
</Screen>

</Para>


</Sect2>

<Sect2>
<Title>Selectores específicos</Title>

<Para>
La siguiente tabla contiene una lista de todos los selectores específicos
que ha encontrado el autor de esta sección en el código fuente del
programa <Literal remap="tt">tc</Literal>. Simplemente te hacen la vida
más sencilla e incrementan la legibilidad de la configuración de los
filtros.
</Para>

<Para>
FIXME: aquí iría la tabla (la tabla está en un fichero aparte,
"selector.html"
</Para>

<Para>
FIXME: y todavía está en polaco :-(
</Para>

<Para>
FIXME: debe ser sgmlizada
</Para>

<Para>
Algunos ejemplos:
</Para>

<Para>

<Screen>
# tc filter add dev ppp0 parent 1:0 prio 10 u32 \
     match ip tos 0x10 0xff \
     flowid 1:4
</Screen>

</Para>

<Para>
FIXME: el filtro tcp dport no funciona como se describe:
</Para>

<Para>
La regla anterior coincidirá con paquetes que tengan el campo TOS a 0x10.
El campo TOS empieza en el segundo byte del paquete y es de un byte de
largo, de manera que podríamos escribir un selector general equivalente:
<Literal remap="tt">match u8 0x10 0xff at 1</Literal>. Esto nos da una
pista de las interioridades del filtro U32 (las reglas específicas siempre
se traducen a generales, y es de esta manera que se almacenan en la
memoria del núcleo). Lo que nos lleva a otra conclusión: los selectores
<Literal remap="tt">tcp</Literal> y <Literal remap="tt">udp</Literal> son
exactamente el mismo, y ésta es la razón de que no podamos usar un único
selector <Literal remap="tt">match tcp dport 53 0xffff</Literal> para
capturar paquetes TCP enviados a dicho puerto (también coincidiría con los
paquetes UDP). También debe recordar especificar el protocolo y terminará
con la siguiente regla:
</Para>

<Para>

<Screen>
# tc filter add dev ppp0 parent 1:0 prio 10 u32 \
        match tcp dport 53 0xffff \
        match ip protocol 0x6 0xff \
        flowid 1:2
</Screen>

</Para>

</Sect2>

</Sect1>

<Sect1 id="lartc.adv-filter.route">
  <Title>El clasificador <option>route</option></Title>

<Para>
Este clasificador filtra basándose en los resultados de las tablas de
rutas. Cuando un paquete que está pasando por las clases llega a uno
marcado con el filtro «route», queda clasificado basándose en la
información de la tabla de rutas.
</Para>

<Para>

<Screen>
# tc filter add dev eth1 parent 1:0 protocol ip prio 100 route
</Screen>

</Para>

<Para>
Aquí añadimos un clasificador de rutas al nodo padre 1:0 con prioridad
100. Cuando un paquete alcanza este nodo (que, como es el raíz, sucederá
de inmediato) consultará la tabla de rutas y si una coincide, lo enviará a
la clase dada y le dará prioridad 100. Entonces, para entrar en acción del
todo, deberá añadir la ruta apropiada:
</Para>

<Para>
El truco aquí es definir «realm» (dominio) basándose en el destino o el
origen. La forma de hacerlo es ésta:
</Para>

<Para>

<Screen>
# ip route add Máquina/Red via Pasarela dev Dispositivo realm NúmeroDominio
</Screen>

</Para>

<Para>
Por ejemplo, podemos definir nuestra red de destino 192.168.10.0 con un
número de dominio 10:
</Para>

<Para>

<Screen>
# ip route add 192.168.10.0/24 via 192.168.10.1 dev eth1 realm 10
</Screen>
  
</Para>

<Para>
Cuando añadimos filtros de rutas, podemos usar números de dominios para
representar las redes o máquinas y especificar cómo se comparan estas
redes con los filtros.
</Para>

<Para>

<Screen>
# tc filter add dev eth1 parent 1:0 protocol ip prio 100 \
  route to 10 classid 1:10
</Screen>
  
</Para>

<Para>
La regla anterior dice que los paquetes que vayan a la red 192.168.10.0
coinciden con la clase de id 1:10.
</Para>

<Para>
El filtro de rutas también se puede usar para coincidir con rutas de
origen. Por ejemplo, hay una subred asociada al router Linux en eth2.
</Para>

<Para>

<Screen>
# ip route add 192.168.2.0/24 dev eth2 realm 2
# tc filter add dev eth1 parent 1:0 protocol ip prio 100 \
  route from 2 classid 1:2
</Screen>

</Para>

<Para>
Aquí el filtro especifica que el paquete de la subred 192.168.2.0 (dominio
2) coincidirá con la clase de id 1:2.
</Para>

</Sect1>

<Sect1 id="lartc.adv-filter.policing">
  <Title>Filtros de control (Policing filters)</Title>

<Para>
Para hacer las configuraciones incluso más complicadas, puede tener
filtros que sólo funcionen hasta un determinado ancho de banda, o que sólo
salten cuando el ancho de banda exceda una tasa determinada.
</Para>

<Para>
De manera que si decide controlar 4mbit/s pero hay 5mbit/s de tráfico,
puede dejar de comprobar los 5mbit/s al completo, o sólo 1mbit/s y enviar
4mbit/s del total a la clase configurada.
</Para>

<Para>
Si el ancho de banda excede la tasa configurada, puede descartar un
paquete, reclasificarlo, o ver si algún otro filtro lo captura.
</Para>

<Sect2>
<Title>Formas de control</Title>

<Para>
Básicamente hay dos formas de control. Si compiló «Estimadores» en el
núcleo, entonces se puede medir cuánto tráfico está pasando por cada
filtro, más o menos. Estos estimadores consumen poca CPU, ya que sólo
cuentan cuántos datos han estado pasando 25 veces por segundo, y con eso
calculan la tasa de bits.
</Para>

<Para>
La otra forma es de nuevo mediante un Token Bucket Filter, que esta vez
residirá dentro del filtro. El TBF sólo trabaja con tráfico HASTA el ancho
de banda configurado, y si se ofrece más, sólo el exceso es sujeto a la
acción de sobrelímite configurada.
</Para>

<Sect3>
<Title>Con el estimador del núcleo</Title>

<Para>
Es muy simple y sólo tiene un parámetro: avrate. O el flujo se mantiene
por debajo de avrate, y el filtro clasifica el tráfico en el id de clase
indicado, o la tasa excede en cuyo caso se ejecuta la acción especificada,
que es «reclassify» por defecto.
</Para>

<Para>
El núcleo usa una Media de Movimiento Exponencial Proporcional
(Exponential Weighted Moving Average) que lo hace menos sensible a ráfagas
cortas.
</Para>

</Sect3>

<Sect3>
<Title>Con Token Bucket Filter</Title>

<Para>
Usa los siguientes parámetros:

<ItemizedList>
<ListItem>

<Para>
buffer/maxburst
</Para>
</ListItem>
<ListItem>

<Para>
mtu/minburst
</Para>
</ListItem>
<ListItem>

<Para>
mpu
</Para>
</ListItem>
<ListItem>

<Para>
rate
</Para>
</ListItem>

</ItemizedList>

</Para>

<Para>
Que se comportan de forma casi idéntica que las descritas en la sección
del Token Bucket Filter. Sin embargo, tenga en cuenta que si establece
demasiado bajo el mtu de un control TBF, no pasará *ningún* paquete,
mientras que la qdisc TBF de salida se limitará a pasarlos más lentamente.
</Para>

<Para>
Otra diferencia es que un filtro de control sólo puede dejar pasar un
paquete, o descartarlo. No puede mantenerlo dentro de sí para retrasarlo.
</Para>

</Sect3>

</Sect2>

<Sect2>
<Title>Acciones de sobrelímite</Title>

<Para>
Si nuestro filtro decide que está sobrelimitado, puede tomar «acciones».
Actualmente, disponemos de tres:
<VariableList>

<VarListEntry>
<Term>continue</Term>
<ListItem>
<Para>
Hace que el filtro no de coincidencia, aunque puede que lo hagan otros
filtros.
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>drop</Term>
<ListItem>
<Para>
Esta es una opción muy salvaje que se limita a descartar el tráfico que
excede de una cierta tasa. Se usa a menudo en el control deentrada y tiene
usos limitados. Por ejemplo, puede tener un servidor de nombres que se cae
si se le pasa más de 5mbit/s de paquetes, en cuyo caso se debería usar un
filtro de entrada para asegurarse de que no se le ofrecen más.
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>Pass/OK</Term>
<ListItem>
<Para>
Dejar pasar el tráfico. Se puede usar para desactivar un filtro
complicado, sin eliminarlo de su sitio.
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>reclassify</Term>
<ListItem>
<Para>
Más a menudo se tiene a una reclasificación al Mejor Esfuerzo. Esta es la
acción por defecto.
</Para></ListItem>
</VarListEntry>
</VariableList>
</Para>

</Sect2>

<Sect2>
<Title>Ejemplos</Title>

<Para>
El único ejemplo real conocido se menciona en la sección «Protección de la
máquina frente a inundaciones por SYN».
</Para>

<Para>
FIXME: si ha usado esto, comparta su experiencia con nosotros
</Para>

</Sect2>

</Sect1>

<Sect1 id="lartc.adv-filter.hashing">
<Title>Filtros de hash para filtrado masivo muy rápido</Title>

<Para>
Si alguna vez ha necesitado miles de reglas, por ejemplo si tiene muchos
clientes o máquinas, todas con especificaciones QoS diferentes, habrá
comprobado que el núcleo se pasa mucho tiempo comprobando todas esas
reglas.
</Para>

<Para>
Por defecto, muchos filtros residen en una gran cadena que se comprueba en
orden descendiente de prioridad. Si tiene 1000 reglas, puede hacer falta
1000 comprobaciones para determinar qué hacer con un paquete.
</Para>

<Para>
La comprobación podría ser mucho más rápida si tuviera 256 reglas cada una
con cuatro reglas (si pudiera dividir los paquetes en esas 256 cadenas, de
manera que ajustasen).
</Para>

<Para>
El hash hace esto posible. Digamosq ue tiene 1024 clientes de cable módem
en su red, con direcciones IP desde 1.2.0.0 a 1.2.3.255, y que cada una va
en otra categoría, por ejemplo «pequeña», «normal» y «premium». Entonces
podría tener 1024 reglas como ésta:
</Para>

<Para>

<Screen>
# tc filter add dev eth1 parent 1:0 protocol ip prio 100 match ip src \
  1.2.0.0 classid 1:1
# tc filter add dev eth1 parent 1:0 protocol ip prio 100 match ip src \
  1.2.0.1 classid 1:1
...
# tc filter add dev eth1 parent 1:0 protocol ip prio 100 match ip src \
  1.2.3.254 classid 1:3
# tc filter add dev eth1 parent 1:0 protocol ip prio 100 match ip src \
  1.2.3.255 classid 1:2
</Screen>

</Para>

<Para>
Para acelerar esto, podemos usar la última parte de la dirección IP como
una "clave hash". Entonces obtenemos 256 tablas, la primera de las cuales
sería así:

<Screen>
# tc filter add dev eth1 parent 1:0 protocol ip prio 100 match ip src \
  1.2.0.0 classid 1:1
# tc filter add dev eth1 parent 1:0 protocol ip prio 100 match ip src \
  1.2.1.0 classid 1:1
# tc filter add dev eth1 parent 1:0 protocol ip prio 100 match ip src \
  1.2.2.0 classid 1:3
# tc filter add dev eth1 parent 1:0 protocol ip prio 100 match ip src \
  1.2.3.0 classid 1:2
</Screen>

</Para>

<Para>
La siguiente empezaría así:

<Screen>
# tc filter add dev eth1 parent 1:0 protocol ip prio 100 match ip src \
  1.2.0.1 classid 1:1
...
</Screen>

</Para>

<Para>
De esta manera, sólo se necesitan cuatro comprobaciones como mucho, y dos
de media.
</Para>

<Para>
La configuración es muy complicada, pero valdrá la pena cuando llegue el
momento en que tenga tantos clientes. Primero hacemos un filtro raíz, y
luego creamos una tabla con 256 entradas:

<Screen>
# tc filter add dev eth1 parent 1:0 prio 5 protocol ip u32
# tc filter add dev eth1 parent 1:0 prio 5 handle 2: protocol ip u32 divisor 256
</Screen>

</Para>

<Para>
Ahora añadimos algunas reglas a las entradas que hemos creado en la tabla:
</Para>

<Para>

<Screen>
# tc filter add dev eth1 protocol ip parent 1:0 prio 5 u32 ht 2:7b: \
        match ip src 1.2.0.123 flowid 1:1
# tc filter add dev eth1 protocol ip parent 1:0 prio 5 u32 ht 2:7b: \
        match ip src 1.2.1.123 flowid 1:2
# tc filter add dev eth1 protocol ip parent 1:0 prio 5 u32 ht 2:7b: \
        match ip src 1.2.3.123 flowid 1:3
# tc filter add dev eth1 protocol ip parent 1:0 prio 5 u32 ht 2:7b: \
        match ip src 1.2.4.123 flowid 1:2
</Screen>

Esta es la entrada 123, que contiene coincidencias para 1.2.0.123,
1.2.1.123, 1.2.2.123, 1.2.3.123, y las envía a 1:1, 1:2, 1:3 y 1:2
respectivamente. Fíjese que necesitamos especificar nuestro hash en
hexadecimal, 0x7b is 123.
</Para>

<Para>
Luego creamos un «filtro de hash» que dirige el tráfico a la entrada
adecuada de la tabla de hash:

<Screen>
# tc filter add dev eth1 protocol ip parent 1:0 prio 5 u32 ht 800:: \
        match ip src 1.2.0.0/16 \
        hashkey mask 0x000000ff at 12 \
        link 2:
</Screen>

Bueno, hace falta explicar algunos números. La tabla de hash por defecto
se llama 800:: y todo el filtrado empieza aquí. Entonces escogemos la
dirección de origen, que reside en las posiciones 12, 13, 14 y 15 de la
cabecera IP, e indicamos que sólo estamos interesados en la última parte.
Entonces lo enviamos a la tabla de hash 2:, que creamos previamente.
</Para>

<Para>
Es bastante complicado, pero funciona en la práctica y el rendimiento será
asombroso. Sepa que este ejemplo se puede mejorar hasta el caso ideal en
que cada cadena ¡sólo contenga 1 filtro!
</Para>

</Sect1>


<Sect1 id="lartc.adv-filter.ipv6">
<Title>Filtrado de tráfico IPv6</Title>

<Sect2>
<Title>¿Cómo es que no funcionan los filtros tc para IPv6?</Title>

<Para>
La Routing Policy Database (RPDB) reemplazó el encaminamiento IPv4 y la
estructura de direccionamiento dentro del Núcleo de Linux, lo que llevó a
todas las capacidades maravillosas que describe este COMO.
Desafortunadamente, la estructura de IPv6 dentro de Linux se implementó
fuera de esta estructura central. Aunque comparten algunos servicios, la
estructura esencial de RPDB no participa en o con las estructuras de
direccionamiento y encaminamiento de IPv6.
</Para>

<Para>
Esto cambiará, seguramente, sólo que tenemos que esperar un poco más.
</Para>

<Para>
FIXME: ¿Alguna idea sobre si hay alguien trabajando en esto? ¿Planes?
</Para>

</Sect2>

<Sect2>
<Title>Marcar paquetes IPv6 usando ip6tables</Title>

<Para>
ip6tables puede marcar un paquete y asignarle un número:
</Para>

<Screen>
# ip6tables -A PREROUTING -i eth0 -t mangle -p tcp -j MARK --mark 1
</Screen>

<Para>
Pero de todas maneras, esto no ayuda porque el paquete no pasará por la
estructura RPDB.
</Para>

</Sect2>

<Sect2>
<Title>Usar el selector u32 para filtrar paquetes IPv6</Title>

<Para>
Normalmente IPv6 va encapsulado en un túnel SIT y transportado sobre redes
IPv4. Lea la sección sobre Túneles IPv6 si desea información sobre cómo
establecer uno de esos túneles. Esto nos permite filtrar los paquetes IPv4
que contienen los paquetes IPv6 como carga.
</Para>

<Para>
Los siguientes filtros coinciden con todo el IPv6 encapsulado en paquetes
IPv4:
</Para>

<Screen>
# tc filter add dev $DEV parent 10:0 protocol ip prio 10 u32 \
            match ip protocol 41 0xff flowid 42:42
</Screen>

<Para>
Sigamos con esto. Asumamos que nuestros paquetes IPv6 salen sobre IPv4 y
que estos paquetes no tienen establecidas opciones. Se podría usar el
siguiente filtro para encontrar ICMPv6 sobre IPv6 sobre IPv4 sin opciones.
0x3a (58) es el tipo de Next-Header para ICMPv6.
</Para>

<Screen>
# tc filter add dev $DEV parent 10:0 protocol ip prio 10 u32 \
           match ip protocol 41 0xff \
           match u8 0x05 0x0f at 0 \
           match u8 0x3a 0xff at 26 \
           flowid 42:42
</Screen>

<Para>
Encontrar la dirección IPv6 de destino precisa de un poco más de trabajo.
El siguiente filtro coincide con la dirección de destino
3ffe:202c:ffff:32:230:4fff:fe08:358d:
</Para>

<Screen>
# tc filter add dev $DEV parent 10:0 protocol ip prio 10 u32 \
            match ip protocol 41 0xff \
            match u8 0x05 0x0f at 0 \
            match u8 0x3f 0xff at 44 \
            match u8 0xfe 0xff at 45 \
            match u8 0x20 0xff at 46 \
            match u8 0x2c 0xff at 47 \
            match u8 0xff 0xff at 48 \
            match u8 0xff 0xff at 49 \
            match u8 0x00 0xff at 50 \
            match u8 0x32 0xff at 51 \
            match u8 0x02 0xff at 52 \
            match u8 0x30 0xff at 53 \
            match u8 0x4f 0xff at 54 \
            match u8 0xff 0xff at 55 \
            match u8 0xfe 0xff at 56 \
            match u8 0x08 0xff at 57 \
            match u8 0x35 0xff at 58 \
            match u8 0x8d 0xff at 59 \
            flowid 10:13
</Screen>

<Para>
Se usa la misma técnica para buscar subredes. Por ejemplo 2001::
</Para>

<Screen>
# tc filter add dev $DEV parent 10:0 protocol ip prio 10 u32 \
            match ip protocol 41 0xff \
            match u8 0x05 0x0f at 0 \
            match u8 0x20 0xff at 28 \
            match u8 0x01 0xff at 29 \
            flowid 10:13
</Screen>

</Sect2>

</Sect1>

</chapter>

<chapter id="lartc.kernel">
<Title>Parámetros de red del núcleo</Title>

<Para>
 
El núcleo tiene muchos parámetros que se
pueden ajustar para diferentes circunstancias. Aunque, como de costumbre,
los parámetros por defecto sirven muy bien para el 99% de las
instalaciones, ¡no llamamos a éste el Cómo Avanzado sólo por diversión!
</Para>

<Para>
Las cosas interesantes están en /proc/sys/net, así que eche un vistazo
ahí. No todo lo documentaremos aquí al principio, pero estamos trabajando
en ello.
</Para>

<Para>
Mientras tanto, puede que quiera echar un vistazo a las fuentes del núcleo
de Linux; lea el fichero Documentation/filesystems/proc.txt. La mayoria de
las características se explican allí.
</Para>

<Para>
(FIXME)
</Para>

<Sect1 id="lartc.kernel.rpf"
  xreflabel="Reverse Path Filtering">
  <Title>Reverse Path Filtering</Title>

<Para>
Por defecto, los routers encaminan todo, incluyendo paquetes que
«obviamente» no pertenecen a nuestra red. Un ejemplo común es un escape de
un espacio IP privado a Internet. Si tiene una interfaz con una ruta de
195.96.96.0/24 hacia ella, no esperará que lleguen allí paquetes de
212.64.94.1.
</Para>

<Para>
Mucha gente querría desactivar esto, de manera que los hacker núcleo lo
han hecho sencillo. Hay ficheros en /proc donde decir que quiere que el
núcleo haga esto por usted. El método se llama «"Reverse Path Filtering».
Básicamente, si la respuesta a un paquete no debería haber salido de la
interfaz por la que vino, entonces este paquete es erróneo y debería ser
ignorado.
</Para>

<Para>
El siguiente fragmento lo activará para todas las interfaces actuales y
futuras.
</Para>

<Para>

<Screen>
# for i in /proc/sys/net/ipv4/conf/*/rp_filter ; do
&gt;  echo 2 &#62; $i 
&gt; done
</Screen>

</Para>

<Para>
Siguiendo el ejemplo anterior, si un paquete llega al router Linux por
eth1 diciendo que viene de la red Oficina+ISP, debería ser eliminado. De
forma similar, si un paquete viene de la subred Oficina, diciendo que
viene de algún sitio de fuera del cortafuegos, también debería ser
eliminado.
</Para>

<Para>
Lo anterior es un «reverse path filtering» completo. La acción por defecto
es filtrar basándose sólo en direcciones IP que estén en las redes
conectadas directamente. Esto se debe a que el filtrado completo a veces
no funciona en el caso de encaminamiento asimétrico, cuando los paquetes
vienen por una vía y salen por otra, como tráfico de satélite, o si tiene
rutas dinámicas (bgp, ospf, rip) en la red. Los datos vienen por la antena
del satélite y las respuestas van mediante líneas terrestres normales.
</Para>

<Para>
Si esta excepción se le aplica (y probablemente lo sabrá si esto es así)
sencillamente puede desactivar el rp_filter de la interfaz por donde
vienen los datos del satélite. Si quiere ver si se están descartando
paquetes, el fichero log_martians de ese mismo directorio le dirá al
núcleo que los registre mediante syslog.
</Para>

<Para>

<Screen>
# echo 1 &#62;/proc/sys/net/ipv4/conf/&#60;nombredeinterfaz&#62;/log_martians
</Screen>

</Para>

<Para>
FIXME: ¿basta con activar los ficheros conf/&lcub;default,all&rcub;/*? -
martijn
</Para>

</Sect1>

<Sect1 id="lartc.kernel.obscure">
  <Title>Configuraciones oscuras</Title>

<Para>
Bien, hay muchos parámetros que se pueden modificar. Intentaremos dar una
lista de todos. También están documentados (parcialmente) en
Documentation/ip-sysctl.txt.
</Para>

<Para>
Algunas de estas configuraciones tienen valores por defecto diferentes
dependiendo de si ha respondido «Sí» a la pregunta «Configure as router
and not host» al compilar el núcleo.
</Para>

<para>
Oskar Andreasson también tiene una página con todas estas opciones y
parece que es mejor que lo nuestro, de manera que mire también en
<ulink url="http://ipsysctl-tutorial.frozentux.net/">
http://ipsysctl-tutorial.frozentux.net/</ulink>.
</para>

<Sect2>
<Title>ipv4 genérica</Title>

<Para>
Como nota general, la mayoría de las capacidades de limitación de
velocidad no funcionan sobre el loopback, de manera que no las pruebe de
forma local. Los límites se indican en «jiffies», y se fuerzan usando el
token bucket filter que mencionamos anteriormente.
</Para>

<Para>
El núcleo tiene un reloj interno que funciona a «HZ» tics (o «jiffies»)
por segundo. En Intel, «HZ» suele ser 100. De manera que cambiar el
fichero _rate a, digamos 50, permitirá 2 paquetes por segundo. El token
bucket filter está configurado también para permitir ráfagas de como mucho
6 paquetes, si se han recibido ya suficientes paquetes.
</Para>

<Para>
Mucho del contenido de la siguiente lista se ha copiado de
/usr/src/linux/Documentation/networking/ip-sysctl.txt, escrito por Alexey
Kuznetsov &lt;kuznet@ms2.inr.ac.ru&gt; y Andi Kleen &lt;ak@muc.de&gt;
<VariableList>

<VarListEntry>
<Term>/proc/sys/net/ipv4/icmp_destunreach_rate</Term>
<ListItem>
<Para>
Si el núcleo decide que no puede entregar un paquete, lo descartará, y
enviará a su origen un aviso ICMP al efecto.
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>/proc/sys/net/ipv4/icmp_echo_ignore_all</Term>
<ListItem>
<Para>
No actuar sobre los paquetes de eco. Por favor, no active esto por
defecto, pero en caso de ser usado como reenvío para un ataque DoS, puede
ser útil.
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>/proc/sys/net/ipv4/icmp_echo_ignore_broadcasts &lsqb;Util&rsqb;</Term>
<ListItem>
<Para>
Si hace ping a la dirección de difusión de una red, se supone que
responderán todas las máquinas. Esto se convierte en una herramienta de
negación de servicio bastante buena. Póngalo a 1 para ignorar estos
mensajes de difusión.
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>/proc/sys/net/ipv4/icmp_echoreply_rate</Term>
<ListItem>
<Para>
La tasa a la que se envían mensajes de eco hacia cualquier destino.
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>/proc/sys/net/ipv4/icmp_ignore_bogus_error_responses</Term>
<ListItem>
<Para>
Active esto para ignorar los errores ICMP causados por máquinas de la red
que reaccionen mal a tramas enviadas a lo que perciben como la dirección
de difusión.
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>/proc/sys/net/ipv4/icmp_paramprob_rate</Term>
<ListItem>
<Para>
Un mensaje ICMP relativamente desconocido, que se envía en respuesta a
paquetes incorrectos con cabeceras IP o TCP inválidas. Con este fichero
puede controlar la tasa a la que son enviados.
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>/proc/sys/net/ipv4/icmp_timeexceed_rate</Term>
<ListItem>
<Para>
Esta es la causa de la famosa «estrella del centro de Solaris» en las
trazas de ruta. Limita el número de mensajes Time Exceeded ICMP que se
envían.
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>/proc/sys/net/ipv4/igmp_max_memberships</Term>
<ListItem>
<Para>
Número máximo de sockets igmp (multicast) a la escucha en la máquina.
FIXME: ¿Es esto cierto?
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>/proc/sys/net/ipv4/inet_peer_gc_maxtime</Term>
<ListItem>
<Para>
FIXME: ¿Añadir una breve explicación sobre el almacenamiento de inet peer?

Intervalo mínimo entre las pasadas de recolección de basuras. Este
intervalo toma efecto mientras hay baja (o no hay) presión de memoria en
la reserva. Se mide en jiffies.
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>/proc/sys/net/ipv4/inet_peer_gc_mintime</Term>
<ListItem>
<Para>
Intervalo mínimo entre pasadas de recolección de basura. Este intervalo
tiene efecto durante presiones altas de memoria en la reserva. Se mide en
jiffies.
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>/proc/sys/net/ipv4/inet_peer_maxttl</Term>
<ListItem>
<Para>
Tiempo máximo de vida de las entradas. Las que no se usan expirarán tras
este periodo de tiempo si no hay presión de memoria en la reserva (osea,
cuando el número de entradas en la reserva sea muy pequeño). Se mide en
jiffies.
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>/proc/sys/net/ipv4/inet_peer_minttl</Term>
<ListItem>
<Para>
Tiempo mínimo de vida de las entradas. Debería ser suficiente para cubrir
el tiempo de vida de los fragmentos en el lado del reensamblaje. Este
tiempo de vida mínimo queda garantizado si el tamaño de la reserva es
menor que inet_peer_threshold. Se mide en jiffies.
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>/proc/sys/net/ipv4/inet_peer_threshold</Term>
<ListItem>
<Para>
Tamaño aproximado del almacenamiento INET peer. Pasado este umbral, se
eliminarán entradas de forma agresiva. Este umbral también determina el
tiempo de vida de las entradas y los intervalos de tiempo entre pasadas de
la recolección de basura. Más entradas, menos tiempo de vida, menos
intervalos de recolección de basuras.
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>/proc/sys/net/ipv4/ip_autoconfig</Term>
<ListItem>
<Para>
Este fichero contiene el número 1 si la máquina recibió su configuración
IP mediante RARP, BOOTP, DHCP o un mecanismo similar. En caso contrario,
es cero.
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>/proc/sys/net/ipv4/ip_default_ttl</Term>
<ListItem>
<Para>
Tiempo de vida de los paquetes. Viene con un valor sensato de 64.
Auméntelo si tiene una red enorme. No lo haga por diversión (los bucles de
rutas causan mucho más daño de esta manera). Incluso podría considerar
reducirlo bajo ciertas circunstancias.
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>/proc/sys/net/ipv4/ip_dynaddr</Term>
<ListItem>
<Para>
Necesita configurarlo si usa llamada bajo demanda (dial on demand) con una
dirección de interfaz dinámica. Una vez que la demanda levanta la
interfaz, se reenlazará con la dirección correcta cualquier socket TCP
local que no haya visto respuestas. Esto resuelve el problema de que la
conexión que levanta la interfaz en sí misma no funcione, sino al segundo
intento.
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>/proc/sys/net/ipv4/ip_forward</Term>
<ListItem>
<Para>
Si el núcleo debería intentar reenviar paquetes. Inactivo por defecto.
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>/proc/sys/net/ipv4/ip_local_port_range</Term>
<ListItem>
<Para>
Rango de puertos locales para las conexiones de salida. En realidad es muy
pequeño por defecto, 1024 a 4999.
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>/proc/sys/net/ipv4/ip_no_pmtu_disc</Term>
<ListItem>
<Para>
Active esto si desea desactivar Path MTU discovery (una técnica para
determinar la Maximum Transfer Unit más grande posible en su ruta.
Consulte también la sección sobre Path MTU discovery en el capítulo
<citetitle><xref linkend="lartc.cookbook"></citetitle>.
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>/proc/sys/net/ipv4/ipfrag_high_thresh</Term>
<ListItem>
<Para>
Cantidad máxima de memoria a usar para reensamblar los fragmentos IP.
Cuando se llegan a reservar ipfrag_high_thresh bytes de memoria para este
propósito, el gestor de fragmentos descartará paquetes hasta que se
alcance ipfrag_low_thresh.
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>/proc/sys/net/ipv4/ip_nonlocal_bind</Term>
<ListItem>
<Para>
Active esto si desea que sus aplicaciones sean capaces de asociarse a una
dirección que no pertenezca a un dispositivo de su sistema. Esto puede ser
útil cuando la máquina esté en un enlace no permanente (o incluso
dinámico), de manera que los servicios puedan arrancar y asociarse a una
dirección específica incluso cuando el enlace no está presente.
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>/proc/sys/net/ipv4/ipfrag_low_thresh</Term>
<ListItem>
<Para>
Memoria mínima usada para reensamblar fragmentos IP.
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>/proc/sys/net/ipv4/ipfrag_time</Term>
<ListItem>
<Para>
Tiempo en segundos que se mantendrá un fragmento IP en memoria.
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>/proc/sys/net/ipv4/tcp_abort_on_overflow</Term>
<ListItem>
<Para>
Marca booleana que controla el comportamiento bajo gran cantidad de
peticiones de conexión. Cuando se activa, hace que el núcleo envíe
paquetes RST de forma activa si un servicio está sobrecargado.
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>/proc/sys/net/ipv4/tcp_fin_timeout</Term>
<ListItem>
<Para>
Tiempo que se mantendrá un socket en estado FIN-WAIT-2, si ha sido cerrado
en su lado. El otro extremo puede estar mal y no cerrar nunca por ese
lado, o incluso terminar de forma inesperada. El valor por defecto es de
60 segundos. El valor habitual usado en 2.2 era 180 segundos, y puede
restaurarlo, pero recuerde que incluso si su máquina es un servidor WEB de
poca carga, se arriesga a inundar la memoria con kilotones de sockets
muertos, ya que aunque los sockets FIN-WAIT-2 son menos peligrosos que los
FIN-WAIT-1, porque consumen 1.5K de memoria, tienden a vivir más. Vea
tcp_max_orphans.
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>/proc/sys/net/ipv4/tcp_keepalive_time</Term>
<ListItem>
<Para>
Frecuencia con que TCP envía mensajes keepalive cuando se activa
keepalive.

Por defecto: 2 horas.
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>/proc/sys/net/ipv4/tcp_keepalive_intvl</Term>
<ListItem>
<Para>
Con qué frecuencia se retransmiten sondas, cuando no son recibe respuesta
a ellas.

Por defecto: 75 segundos.
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>/proc/sys/net/ipv4/tcp_keepalive_probes</Term>
<ListItem>
<Para>
Cuantas sondas keepalive enviará TCP, hasta que decida que la conexión
está mal.

Valor por defecto: 9. 

Multiplicada por tcp_keepalive_intvl, nos da el tiempo que puede estar un
enlace sin responder tras haber enviado un keepalive.
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>/proc/sys/net/ipv4/tcp_max_orphans</Term>
<ListItem>
<Para>
Número máximo de sockets TCP que no están asociados con ningún controlador
de fichero de usuario, mantenido por el sistema. Si se excede de este
número, se reinician inmediatamente las conexiones huérfanas y se imprime
un mensaje de aviso. Este límite existe sólo para prevenir ataques DoS
sencillos, y _no debe_ depender de él o reducirlo de forma artificial,
sino incrementarlo, en todo caso (probablemente, tras un aumento de la
memoria instalada), si las condiciones de red precisan más que el valor
por defecto, y ajuste los servicios de red para que hagan persistir y
destruyan tales estados de forma más enérgica. Permítame recordárselo de
nuevo: cada huérfano consume hasta &nbsp;64K de memoria física no
intercambiable.
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>/proc/sys/net/ipv4/tcp_orphan_retries</Term>
<ListItem>
<Para>
Cuántas veces hay que reintentar antes de matar una conexión TCP, cerrada
por su lado. El valor por defecto de 7 corresponde a &nbsp;50seg-16min
dependiendo en el RTO. Si la máquina es un servidor web muy cargado,
debería pensar en reducir este valor, ya que tales sockets pueden consumir
recursos significativos. Vea tcp_max_orphans.
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>/proc/sys/net/ipv4/tcp_max_syn_backlog</Term>
<ListItem>
<Para>
Número máximo de peticiones de conexión a recordar, que aún no hayan
recibido confirmación del cliente que conecta. El valor por defecto es
1023 para sistemas con más de 128Mb de memoria, y 128 para máquinas con
poca memoria. Si el servidor sufre sobrecargas, intente aumentar este
número. ¡Cuidado! Si lo hace más grande que 1024, sería mejor que cambiase
TCP_SYNQ_HSIZE en include/net/tcp.h para hacer que
TCP_SYNQ_HSIZE*16&#60;=tcp_max_syn_backlog y después recompile el núcleo.
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>/proc/sys/net/ipv4/tcp_max_tw_buckets</Term>
<ListItem>
<Para>
Número máximo de sockets en estado time-wait mantenidos de forma
simultánea por el sistema. Si se excede este número se destruyen estos
sockets inmediatamente y se imprime un aviso. Este límite existe sólo para
prevenir ataques DoS sencillos, y _no debe_ bajar el límite de forma
artificial, sino en todo caso aumentarlo (probablemente, tras incrementar
la memoria instalada), si las condiciones de la red precisan más que el
valor por defecto.
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>/proc/sys/net/ipv4/tcp_retrans_collapse</Term>
<ListItem>
<Para>
Compatibilidad fallo-por-fallo con determinadas impresoras defectuosas.
Durante la retransmisión intentará enviar paquetes más grandes para
saltarse los fallos de ciertas pilas TCP.
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>/proc/sys/net/ipv4/tcp_retries1</Term>
<ListItem>
<Para>
Cuántas veces hay que reintentar antes de decidir que algo está mal y que
se necesita informar de esta sospecha a la capa de red. El valor mínimo
según el RFC es 3, y es el valor por defecto, que corresponde con
&nbsp;3seg-8min dependiendo del RTO.
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>/proc/sys/net/ipv4/tcp_retries2</Term>
<ListItem>
<Para>
Cuántas veces hay que reintentar antes de matar una conexión TCP viva.
El <ULink
URL="http://www.ietf.org/rfc/rfc1122.txt"
>RFC 1122</ULink
>
dice que este límite debería ser mayor de 100 segundos.
Este número es demasiado pequeño. El valor por defecto de 15 corresponde a
&nbsp;13-30min dependiendo del RTO.
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>/proc/sys/net/ipv4/tcp_rfc1337</Term>
<ListItem>
<Para>
Este booleano activa una corrección para los «riesgos de asesinato de
time-wait en tcp», descritos en el RFC
1337. Si se activa, hace que el núcleo descarte paquetes RST para los
sockets que están en el estado time-wait.

Por defecto: 0
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>/proc/sys/net/ipv4/tcp_sack</Term>
<ListItem>
<Para>
Usar ACK Selectivo que puede servir para comprobar si se están perdiendo
paquetes específicos (por tanto, ayuda a una recuperación rápida).
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>/proc/sys/net/ipv4/tcp_stdurg</Term>
<ListItem>
<Para>
Usa la interpretación de requerimientos de la máquina del campo puntero
urg de TCP.

Muchas máquinas usan la interpretación BSD antigua, de manera que si pone
esto en marcha en Linux podría no comunicarse correctamente con ellas.

Por defecto: FALSO
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>/proc/sys/net/ipv4/tcp_syn_retries</Term>
<ListItem>
<Para>
Número de paquete SYN que enviará el núcleo antes de rendirse durante el
inicio de una conexión.
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>/proc/sys/net/ipv4/tcp_synack_retries</Term>
<ListItem>
<Para>
Para abrir el otro lado de una conexión, en núcleo envía un SYN junto con
un ACK, para confirmar el SYN que recibió anteriormente. Esta es la
segunda parte del saludo de tres vías <footnote><para>N. del T: threeway
handshake, el inicio de una conexión TCP</para></footnote>.
Esta configuración determina el número de paquetes SYN+ACK a enviar antes
de que el kernel decida rendirse.
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>/proc/sys/net/ipv4/tcp_timestamps</Term>
<ListItem>
<Para>
Los registros de tiempo se usan, entre otras cosas, para protegerse contra
números de secuencia que se solapen. Es concebible que un enlace de 1
gigabit reencuentre un número de secuencia previo con un valor fuera de
línea, porque fue de una generación previa. El registro de tiempo le
ayudará a reconocer este "paquete antiguo".
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>/proc/sys/net/ipv4/tcp_tw_recycle</Term>
<ListItem>
<Para>
Activar un reciclado rápido de sockets TIME-WAIT. El valor por defecto es
1. No debería cambiarlo si no es por consejo/petición de expertos
técnicos.
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>/proc/sys/net/ipv4/tcp_window_scaling</Term>
<ListItem>
<Para>
TCP/IP normalmente permite ventanas de hasta 65535 bytes. En redes
realmente rápido, esto podría no ser suficiente. Las opciones de escalado
permiten ventanas de hasta casi un gigabyte, lo cual es bueno para
productos con gran ancho de banda y mucho retraso.
</Para></ListItem>
</VarListEntry>
</VariableList>
</Para>

</Sect2>

<Sect2>
<Title>Configuración por dispositivo</Title>

<Para>
DEV puede significar una interfaz real, o "todas" o "por defecto". Por
defecto también cambia la configuración de las interfaces que aún están
por crear.
<VariableList>

<VarListEntry>
<Term>/proc/sys/net/ipv4/conf/DEV/accept_redirects</Term>
<ListItem>
<Para>
Si un router decide que estamos usándolo para un propósigo equivocado
(necesita reenviar los paquetes por la misma interfa que los recibión),
nos enviará un ICMP Redirect. Sin embargo, esto implica un pequeño riesgo
de seguridad, y puede que quiera desactivarlo, o usar secure redirects.
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>/proc/sys/net/ipv4/conf/DEV/accept_source_route</Term>
<ListItem>
<Para>
Ya no se usa mucho. Antes se podía dar a un paquete una lista de
direcciones IP que debería visitar por el camino. Linux puede obedecer a
esta opción de IP.
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>/proc/sys/net/ipv4/conf/DEV/bootp_relay</Term>
<ListItem>
<Para>
Aceptar paquetes con dirección de origen 0.b.c.d y destino diferente a
esta máquina como si fueran locales. Se supone que un demonio de reenvío
de BOOTP atrapará y reenviará estos paquetes.
</Para>

<Para>
Por defecto es 0, ya que esta característica no está implementada aún
(hablamos de la versión del núcleo 2.2.12).
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>/proc/sys/net/ipv4/conf/DEV/forwarding</Term>
<ListItem>
<Para>
Activar o desactivar el reenvío de IP por esta interfaz.
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>/proc/sys/net/ipv4/conf/DEV/log_martians</Term>
<ListItem>
<Para>
Vea la sección sobre
<citetitle><xref linkend="lartc.kernel.rpf"></citetitle>.
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>/proc/sys/net/ipv4/conf/DEV/mc_forwarding</Term>
<ListItem>
<Para>
Para hacer reenvío de multicast en esta interfaz.
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>/proc/sys/net/ipv4/conf/DEV/proxy_arp</Term>
<ListItem>
<Para>
Si lo pone a 1, esta interfaz responderá a consultas ARP para direcciones
hacia las que el núcleo tiene rutas. Puede ser útil cuando se construyen
"pseudo bridges ip". ¡Tenga cuidado de que las máscaras de red sean
correctas antes de activar esto! ¡Tenga en cuenta también que rp_filter,
mencionado anteriormente, también opera sobre las consultas ARP!
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>/proc/sys/net/ipv4/conf/DEV/rp_filter</Term>
<ListItem>
<Para>
Vea la sección sobre
<citetitle><xref linkend="lartc.kernel.rpf"></citetitle>.
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>/proc/sys/net/ipv4/conf/DEV/secure_redirects</Term>
<ListItem>
<Para>
Aceptar mensajes ICMP redirect sólo en las pasarelas, que aparecen en la
lista de pasarelas por defecto. Activo por defecto.
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>/proc/sys/net/ipv4/conf/DEV/send_redirects</Term>
<ListItem>
<Para>
Si vamos a enviar las redirecciones mencionadas previamente.
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>/proc/sys/net/ipv4/conf/DEV/shared_media</Term>
<ListItem>
<Para>
Si no está activo, el núcleo no asume que que las diferentes subredes a
las que accede este dispositivo se puedan comunicar directamente. El valor
por defecto es «sí».
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>/proc/sys/net/ipv4/conf/DEV/tag</Term>
<ListItem>
<Para>
FIXME: hay que rellenar esto
</Para></ListItem>
</VarListEntry>
</VariableList>
</Para>

</Sect2>

<Sect2>
<Title>Normas de vecinos (Neighbor policy)</Title>

<Para>
Dev puede significar una interfaz real, o "todas" o "por defecto". Por
defecto también cambia la configuración de las interfaces que aún están
por crear.
<VariableList>

<VarListEntry>
<Term>/proc/sys/net/ipv4/neigh/DEV/anycast_delay</Term>
<ListItem>
<Para>
Retraso aleatorio máximo de las respuestas a los mensajes Neigbor
Solicitation en jiffies (1/100 seg). Aún no está
implementado (Linux todavía no soporta anycast).
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>/proc/sys/net/ipv4/neigh/DEV/app_solicit</Term>
<ListItem>
<Para>
Determina el número de peticiones a enviar al demonio ARP de nivel de
usuario. Use 0 para apagarlo.
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>/proc/sys/net/ipv4/neigh/DEV/base_reachable_time</Term>
<ListItem>
<Para>
Un valor de base usado para calcular al azar el tiempo de accesibilidad
(Reachable Time) tal como se especifica en el RFC2461.
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>/proc/sys/net/ipv4/neigh/DEV/delay_first_probe_time</Term>
<ListItem>
<Para>
Retraso de la primera sonda de tiempo si se puede acceder al vecino (vea
gc_stale_time)
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>/proc/sys/net/ipv4/neigh/DEV/gc_stale_time</Term>
<ListItem>
<Para>
Determina con qué frecuencia se comprueban las entradas congeladas en ARP.
Tras congelarse una entrada ARP se intentará resolver de nuevo (lo cual es
útil cuando una dirección IP pasa a otra máquina). Cuando ucast_solicit es
mayor que 0, primero intenta enviar un paquete ARP directamente a la
máquina conocida. Si esto falla y mcast_solicit es mayor que 0, se
difunde una petición ARP.
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>/proc/sys/net/ipv4/neigh/DEV/locktime</Term>
<ListItem>
<Para>
Una entrada de ARP/neighbor sólo se reemplaza con una nueva si el valor
antiguo es de hace al menos "locktime". Esto evita sacudidas en la caché
ARP.
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>/proc/sys/net/ipv4/neigh/DEV/mcast_solicit</Term>
<ListItem>
<Para>
Número máximo de reintetnos para una solicitud multicast.
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>/proc/sys/net/ipv4/neigh/DEV/proxy_delay</Term>
<ListItem>
<Para>
Tiempo máximo (el tiempo real es aleatorio &lsqb;0..proxytime]) antes de
contestar a una consulta ARP para la cual tenemos una entrada proxy ARP.
En algunos casos, se usa para evitar inundaciones de red.
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>/proc/sys/net/ipv4/neigh/DEV/proxy_qlen</Term>
<ListItem>
<Para>
Longitud máxima de la cola del temporizador proxy arp retrasado. (vea
proxy_delay).
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>/proc/sys/net/ipv4/neigh/DEV/retrans_time</Term>
<ListItem>
<Para>
El tiempo, expresado en jiffies (1/100 sec), entre mensajes Neighbor
Solicitation retransmitidos. Se usa para resolver direcciones y determinar
si se puede alcanzar a un vecino.
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>/proc/sys/net/ipv4/neigh/DEV/ucast_solicit</Term>
<ListItem>
<Para>
Número máximo de reintentos para una solicitud unicast.
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>/proc/sys/net/ipv4/neigh/DEV/unres_qlen</Term>
<ListItem>
<Para>
Tamaño máximo de la cola para una consulta arp pendiente (el número de
paquetes que se aceptan de otras capas mientras aún está por resolver una
dirección ARP).
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>Internet QoS: Architectures and Mechanisms for Quality of Service,
Zheng Wang, ISBN 1-55860-608-4</Term>
<ListItem>
<Para>
Libro en tapas duras que cubre temas
relacionados con la Calidad de Servicio. Bueno para comprender los
conceptos básicos.
</Para></ListItem>
</VarListEntry>
</VariableList>
</Para>

</Sect2>

<Sect2>
<Title>Configuración de encaminamiento</Title>

<Para>
<VariableList>

<VarListEntry>
<Term>/proc/sys/net/ipv4/route/error_burst</Term>
<ListItem>
<Para>
Estos parámetros se usan para limitar los mensajes de aviso escritos desde
el código de encaminamiento al registro del núcleo. Cuanto más grande sea
error_cost, menos mensajes se escriben. Error_burst controla cuando
descartar mensajes. Los valores por defecto limitan los mensajes de aviso
a uno cada cinco segundos.
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>/proc/sys/net/ipv4/route/error_cost</Term>
<ListItem>
<Para>
Estos parámetros se usan para limitar los mensajes de aviso escritos desde
el código de encaminamiento al registro del núcleo. Cuanto más grande sea
error_cost, menos mensajes se escriben. Error_burst controla cuando
descartar mensajes. Los valores por defecto limitan los mensajes de aviso
a uno cada cinco segundos.
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>/proc/sys/net/ipv4/route/flush</Term>
<ListItem>
<Para>
Escribir en este fichero hace que se vacíe la caché de rutas.
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>/proc/sys/net/ipv4/route/gc_elasticity</Term>
<ListItem>
<Para>
Valores para controlar la frecuencia y comportamiento del algoritmo
recolector de basuras de la caché de rutas. Puede ser importante en alta
disponibilidad cuando se hace el cambio de máquina. Pasarán al menos
gc_timeout segundos antes de que Linux salte a otra ruta porque la
anterior ha muerto. Por defecto se pone a 300, pero puede que quiera
rebajarla para tener un cambio rápido.
</Para>

<Para>
Vea también <ULink
URL="http://mailman.ds9a.nl/pipermail/lartc/2002q1/002667.html"
>este mensaje</ULink
> de Ard van Breemen.
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>/proc/sys/net/ipv4/route/gc_interval</Term>
<ListItem>
<Para>
Vea /proc/sys/net/ipv4/route/gc_elasticity.
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>/proc/sys/net/ipv4/route/gc_min_interval</Term>
<ListItem>
<Para>
Vea /proc/sys/net/ipv4/route/gc_elasticity.
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>/proc/sys/net/ipv4/route/gc_thresh</Term>
<ListItem>
<Para>
Vea /proc/sys/net/ipv4/route/gc_elasticity.
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>/proc/sys/net/ipv4/route/gc_timeout</Term>
<ListItem>
<Para>
Vea /proc/sys/net/ipv4/route/gc_elasticity.
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>/proc/sys/net/ipv4/route/max_delay</Term>
<ListItem>
<Para>
Retrasos para vaciar la caché de rutas.
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>/proc/sys/net/ipv4/route/max_size</Term>
<ListItem>
<Para>
Tamaño máximo de la caché de rutas. Las entradas viejas se purgan una vez
que la caché alcance este tamaño.
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>/proc/sys/net/ipv4/route/min_adv_mss</Term>
<ListItem>
<Para>
FIXME: rellenar esto
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>/proc/sys/net/ipv4/route/min_delay</Term>
<ListItem>
<Para>
Retrasos al vaciar la caché de rutas.
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>/proc/sys/net/ipv4/route/min_pmtu</Term>
<ListItem>
<Para>
FIXME: rellenar esto
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>/proc/sys/net/ipv4/route/mtu_expires</Term>
<ListItem>
<Para>
FIXME: rellenar esto
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>/proc/sys/net/ipv4/route/redirect_load</Term>
<ListItem>
<Para>
Factores que determinan si se deberían enviar más ICMP Redirect a una
máquina específica. No se enviarán más redirect una vez que se haya
alcanzado el límite de carga o el número máximo de redirecciones.
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>/proc/sys/net/ipv4/route/redirect_number</Term>
<ListItem>
<Para>
Vea /proc/sys/net/ipv4/route/redirect_load.
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>/proc/sys/net/ipv4/route/redirect_silence</Term>
<ListItem>
<Para>
Límite de tiempo para los redirect. Tras este periodo se enviará de nuevo
un redirect, incluso si se había parado por alcanzar el límite de carga o
de envíos.
</Para></ListItem>
</VarListEntry>
</VariableList>
</Para>

</Sect2>

</Sect1>

</chapter>

<chapter id="lartc.adv-qdisc">
  <Title>Disciplinas de cola avanzadas y poco conocidas</Title>

<Para>
Si encuentra que tiene necesidades que no cubren las colas mencionadas
anteriormente, el núcleo contiene algunas otras colas más especializadas
que se mencionan aquí.
</Para>

<Sect1 id="lartc.adv-qdisc.bfifo-pfifo">
  <Title><literal>bfifo</literal>/<literal>pfifo</literal></Title>

<Para>
Estas colas sin clases son incluso más sencillas que pfifo_fast ya que no
tienen bandas internas (realmente todo el tráfico es igual). Sin embargo
tienen un beneficio importante, dan estadísticas. De manera que si no
necesita ajustar o priorizar tráfico, puede usar estas colas para
determinar cuán llena está la interfaz.
</Para>

<Para>
pfifo mide en paquetes, y bfifo en bytes.
</Para>

<Sect2>
<Title>Parámetros y uso</Title>

<Para>
<VariableList>

<VarListEntry>
<Term>limit</Term>
<ListItem>
<Para>
Especifica la longitud de la cola. Se mide en bytes para bfifo, y en
paquetes para pfifo. Por defecto es txqueuelen de la interfaz (vea el
capítulo sobre pfifo_fast) en paquetes o txqueuelen*mtu bytes para bfifo.
</Para></ListItem>
</VarListEntry>
</VariableList>
</Para>

</Sect2>

</Sect1>

<Sect1 id="lartc.adv-qdisc.csz">
  <Title>Algoritmo Clark-Shenker-Zhang (CSZ)</Title>

<Para>
Es tan teórico que ni siquiera Alexey (el autor principal de CBQ) dice
entenderlo. De su código fuente:
</Para>

<blockquote>
<Para>
David D. Clark, Scott Shenker y Lixia Zhang
<citetitle>Soporte para aplicaciones de tiempo real en una red de paquetes
de servicios integrados: Arquitectura y mecanismos</citetitle>.
</Para>

<Para>
Hasta donde lo entiendo, la idea principal es crear flujos WFQ para cada
servicio garantizado y reservar el resto de ancho de banda para el
flujo-0. El flujo-0 comprende los servicios predictivos y el tráfico de
mejor esfuerzo; lo controla un organizador de prioridades con la banda de
máxima prioridad reservada para los servicios restringidos, y el resto a
los paquetes de mejor esfuerzo.
</Para>

<Para>
Tenga en cuenta que en CSZ los flujos NO están limitados a su ancho de
banda. Se supone que el flujo pasa un control de admisión al borde de la
red QoS y no necesita más ajustes. Cualquier intento de mejorar el flujo o
de ajustarlo a un tocken bucket en saltos intermedios producirá retrasos
indeseados y aumentará las variaciones (jitter).
</Para>

<Para>
Por el momento CSZ es el único organizador que proporciona servicio
garantizado real. Otros esquemas (incluido CBQ) no proporcionan un retraso
garantizado ni variaciones aleatorias."
</Para>

<Para>
No parece un buen candidato para ser usado, a menos que haya leído y
entendido el artículo mencionado.
</Para>
</blockquote>

</Sect1>

<Sect1 id="lartc.adv-qdisc.dsmark"
  xreflabel="DSMARK">
  <Title>DSMARK</Title>

  <abstract>
    <Para>
      <author><firstname>Esteve</firstname><surname>Camps</surname></author>
      <address><email>marvin@grn.es</email></address>
      Este texto es un extracto de mi tesis sobre
      <citetitle>Soporte de QoS en Linux</citetitle>, septiembre de 2000.
    </Para>
  </abstract>

<Para>Documentos fuente:
</para>

<ItemizedList>
<ListItem>
  <Para>
    <ULink URL="ftp://icaftp.epfl.ch/pub/linux/diffserv/misc/dsid-01.txt.gz">
      Draft-almesberger-wajhak-diffserv-linux-01.txt</ULink>.
  </Para>
</ListItem>
<ListItem>
  <Para>Ejemplos en la distribución de iproute2.
  </Para>
</ListItem>
<ListItem>
  <Para>
    <ULink URL="http://www.qosforum.com/white-papers/qosprot_v3.pdf">
      White Paper sobre protoclos y arquitecturas QoS</ULink> y
    <ULink URL="http://www.qosforum.com/docs/faq">
      Preguntas frecuentes sobre QoS IP</ULink> ambos del
    <citetitle>Quality of Service Forum</citetitle>.
  </Para>
</ListItem>
</ItemizedList>

<Para>
Este capítulo ha sido escrito por Esteve Camps
&lt;esteve@hades.udg.es&gt;.
</Para>

<Sect2>
<Title>Introducción</Title>

<Para>
Antes de nada, sería una buena idea leer los RFC escritos a este respecto
(RFC2474, RFC2475, RFC2597 y RFC2598) que encontrará en el
<ULink URL="http://www.ietf.org/html.charters/diffserv-charter.html">
  sitio web del Grupo de trabajo IETF DiffServ</ULink> y
<ULink URL="http://diffserv.sf.net/">
  el sitio web de Werner Almesberger</ULink>
(ha escrito el código para dar soporte en Linux a los Servicios
Diferenciados).
</Para>

</Sect2>

<Sect2>
<Title>¿Con qué se relaciona Dsmark?</Title>

<Para>
Dsmark es una disciplina de colas que ofrece las capacidades necesarias
para los Servicios Diferenciados (también conocidos como DiffServ o
simplemente DS). DiffServ es una de las dos arquitecturas QoS actuales (la
otra se llama Servicios Integrados) que se basa en un valor transportado
por los paquetes en el campo DS de la cabecera IP.
</Para>

<Para>
Una de las primeras soluciones en IP diseñadas a ofrecer algún nivel de
QoS fue el campo Type of Service (el byte TOS) de la cabecera IP.
Cambiando este valor, podíamos escoger un nivel alto/bajo de
transferencia, retraso o fiabilidad. Pero esto no proporcionaba suficiente
flexibilidad para las necesidades de los nuevos servicios (como las
aplicaciones en tiempo real, las interactivas y otras). Tras esto,
aparecieron nuevas arquitecturas. Una de ellas fue DiffServ, que mantuvo
los bits TOS y los renombró como el campo DS.
</Para>

</Sect2>

<Sect2>
<Title>Principios de los Servicios Diferenciados</Title>

<Para>
Los Servicios Diferenciados están orientados al grupo. Quiero decir, no
sabemos nada sobre flujos (éste es el propósito de los Servicios
Integrados); sólo sabemos sobre agregaciones de flujos y aplicaremos
diferentes comportamientosdependiendo a qué agregación pertenezca un
paquete.
</Para>

<Para>
Cuando llega un paquete a un nodo exterior (edge node - nodo de entrada a
un dominio DiffServ) entrando a un Dominio DiffServ, tendremos que
controlar, ajustar o marcar estos paquetes (el marcado se refiere a
asignar un valor al campo DS; exactamente igual que con las vacas :-) ).
Esta será la marca/valor que mirarán los nodos internos de nuestro Dominio
DiffServ para determinar qué comportamiento o nivel de QoS aplicar.
</Para>

<Para>
Como puede deducir, los Servicios Diferenciados implican un dominio dentro
del cual se deberán aplicar todas las reglas de DS. En realidad, puede
pensar que voy a clasificar todos los paquetes que entran en mi dominio.
Una vez que entran todos estarán sujetos a las normas que mi clasificación
dicta y cada nodo que atraviesen aplicará ese nivel de QoS.
</Para>

<Para>
En realidad, se pueden aplicar normas propias en los dominios locales,
pero se deben tener en cuenta algunos <Emphasis>Acuerdos de nivel de
servicio</Emphasis> (Service Level Agreements) cuando se conecta a otros
dominios DS.
</Para>

<Para>
En este punto, debe tener muchas preguntas. DiffServ es más de lo que he
explicado. En realidad, entenderá que no puedo resumir más de 3 RFC en
sólo 50 líneas :-).
</Para>

</Sect2>

<Sect2>
<Title>Trabajar con Dsmark</Title>

<Para>
Como especifica la bibliografía de DiffServ, diferenciamos entre nodos
externos (o limítrofes) e internos. Son dos puntos importantes en el
camino del tráfico. Ambos tipos realizan una clasificación cuando llega el
paquete. Su resultado puede usarse en diferentes lugares a lo largo del
proceso de DS antes de que se envié el paquete a la red. Es por esto que
el código de diffserv proporciona una estructura llamada sk_buff, que
incluye un campo nuevo llamado skb-&gt;tc_index donde almacenaremos el
resultado de la clasificación inicial que puede usarse en varios momentos
del tratamiento DS.
</Para>

<Para>
El valor de skb-&gt;tc_index lo establecerá inicialmente la qdisc DSMARK,
sacándola del campo DS de la cabecera IP de cada paquete recibido. Aparte,
el clasificador cls_tcindex leerá todo o parte del valor de
skb-&gt;tcindex y lo usará para escoger las clases.
</Para>

<Para>
Pero antes que nada, echemos un vistazo a la orden de la qdisc DSMAR y sus
parámetros:

<Screen>
... dsmark indices INDICES [ default_index INDICE_DEFECTO ] [ set_tc_index ]
</Screen>

¿Qué significan estos parámetros?

<ItemizedList>
<ListItem>

<Para>
<Emphasis remap="bf">indices</Emphasis>: tamaño de la tabla de pares
(máscara,valor). El tamaño máximo es 2&circ;n, siendo n&gt;=0.
</Para>
</ListItem>
<ListItem>

<Para>
<Emphasis remap="bf">default_index</Emphasis>: La entrada por defecto del
índice de la tabla si el clasificador no encuentra coincidencia.
</Para>
</ListItem>
<ListItem>

<Para>
<Emphasis remap="bf">Set_tc_index</Emphasis>: instruye a la disciplina
dsmark para que obtenga el campo DS y lo almacene en skb-&gt;tc_index.
</Para>
</ListItem>

</ItemizedList>

Veamos el proceso de DSMARK.
</Para>

</Sect2>

<Sect2>
<Title>Cómo trabaja SCH_DSMARK.</Title>

<Para>
Esta qdisc seguirá los siguientes pasos:

<ItemizedList>
<ListItem>

<Para>
Si hemos declarado la opción set_tc_index en la orden de la qdisc, se
obtiene el campo DS y se almacena en la variable skb-&gt;tc_index.
</Para>
</ListItem>
<ListItem>

<Para>
Se invoca al clasificador. Será ejecutado y devolverá un ID de clase que
será almacenado en la variable skb-&gt;tc_index. Si no se encuentra ningún
filtro que concuerde, optaremos por la opción default_index como classId
a almacenar. Si no se ha declarado ni set_tc_index ni default_index el
resultado puede ser impredecible.
</Para>
</ListItem>
<ListItem>

<Para>
Despues de ser enviado a las qdisc internas donde se puede reutilizar el
resultado del filtro, se almacena el classid devuelto por la qdisc interna
en skb-&gt;tc_index. Usaremos este valor en adelante para indizar una
tabla máscara-valor. El resultado final a asignar al paquete será el que
resulte de la siguiente operación:

<Screen>
Nuevo_Campo_Ds = ( Viejo_Campo_Ds &#38; máscara ) | valor
</Screen>


</Para>
</ListItem>
<ListItem>

<Para>
Por tanto, el nuevo valor saldrá de aplicar AND a los valores ds_field y
máscara, para después aplicar al resultado un OR con el parámetro valor.
Vea el siguiente diagrama para entender todo el proceso:
</Para>
</ListItem>

</ItemizedList>


<Screen>
                         skb-&gt;ihp-&gt;tos
- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - &gt;
     |                                                       |     ^
     | -- Si declara set_tc_index, almacenamos el            |     |  &lt;-----Puede cambiar
     |    valor de DS en la variable skb-&gt;tc_index           |     |O       el campo DS
     |                                                      A|     |R
   +-|-+      +------+    +---+-+     Qdisc     +-+     +---N|-----|----+
   | | |      |filtro|---&gt;|   | |--&gt;  . . .  --&gt;| |     |   D|     |    |
   | | |-----&gt;|índice|---&gt;|   | |    Interna    | |----&gt;|    v     |    |
   | | |      | tc   |---&gt;| | | +---------------+ |   ----&gt;(másc,valor) |
--&gt;| O |      +------+    +-|-+--------------^----+  /  |  (.  ,  .)    |
   | | |          ^         |                |       |  |  (.  ,  .)    |
   | | +----------|---------|----------------|-------|--+  (.  ,  .)    |
   | | sch_dsmark |         |                |       |                  |
   +-|------------|---------|----------------|-------|------------------+
     |            |         | &lt;- tc_index -&gt; |       |
     |            |(leer)   |  puede cambiar |       |  &lt;--------------Indice a la
     |            |         |                |       |                    tabla de pares
     v            |         v                v       |                    (másc,valor)
- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -&gt;
                         skb-&gt;tc_index
</Screen>

</Para>

<Para>
¿Cómo se marca? Cambie la máscara y el valor de la clase que quiere
remarcar. Vea la siguiente línea de código:

<Screen>
tc class change dev eth0 classid 1:1 dsmark mask 0x3 value 0xb8
</Screen>

Esto cambia el par (másc,valor) de la tabla hash, para remarcar paquete
que pertenecen a la clase 1:1. Tiene que "cambiar" estos valores por los
valores por defecto que obtiene inicialmente (másc,valor). (Vea la tabla
más adelante)
</Para>

<Para>
Ahora, explicaremos cómo funciona el filtro TC_INDEX y cómo cuadra en todo
esto. Además, se puede usar el filtro TC_INDEX en otras configuraciones
aparte de las que incluyen servicios DS.
</Para>

</Sect2>

<Sect2>
<Title>Filtro TC_INDEX</Title>

<Para>
Esta es la orden básica para declarar un filtro TC_INDEX:

<Screen>
... tcindex [ hash TAMAÑO ] [ mask MASCARA ] [ shift SHIFT ]
            [ pass_on | fall_through ]
            [ classid CLASSID ] [ police ESPEC_NORMA ]
</Screen>

Luego, mostramos unos ejemplos para explicar el modo de operación de
TC_INDEx. Preste atención a las palabras resaltadas:


tc qdisc add dev eth0 handle 1:0 root dsmark indices 64 <Emphasis remap="bf">set_tc_index</Emphasis>

tc filter add dev eth0 parent 1:0 protocol ip prio 1 tcindex <Emphasis remap="bf">mask 0xfc  shift 2</Emphasis>

tc qdisc add dev eth0 parent 1:0 handle 2:0 cbq bandwidth 10Mbit cell 8 avpkt 1000 mpu 64

&num; class de tráfico EF

tc class add dev eth0 parent 2:0 classid 2:1 cbq bandwidth 10Mbit rate 1500Kbit avpkt 1000 prio 1 bounded isolated allot 1514 weight 1 maxburst 10

&num; qdisc fifo de paquetes para tráfico EF

tc qdisc add dev eth0 parent 2:1 pfifo limit 5

tc filter add dev eth0 parent 2:0 protocol ip prio 1 <Emphasis remap="bf">handle 0x2e</Emphasis> tcindex <Emphasis remap="bf">classid 2:1 pass_on</Emphasis>



(Este código no está completo. Es sólo un extracto del ejemplo EFCBQ
incluido en la distribución de iproute2).
</Para>

<Para>
Antes de nada, supongamos que recibimos un paquete marcado como EF. Si lee
el RFC2598, verá que el valor DSCP recomendado para el tráfico EF es
101110. Esto significa que el campo DS será 101110 (recuerde que los bits
menos significativos en el byte TOS no se usan en DS) o 0xb8 en código
hexadecimal.
</Para>

<Para>

<Screen>
              FILTRO
              TC INDEX
   +---+      +-------+    +---+-+    +------+                +-+    +-------+
   |   |      |       |    |   | |    |MANEJA|  +-+    +-+    | |    |       |
   |   |-----&gt;| MASC  | -&gt; |   | | -&gt; |FILTRO|-&gt;| |    | | -&gt; | | -&gt; |       |
   |   |  .   | =0xfc |    |   | |    |0x2E  |  | +----+ |    | |    |       |
   |   |  .   |       |    |   | |    +------+  +--------+    | |    |       |
   |   |  .   |       |    |   | |                            | |    |       |
--&gt;|   |  .   | SHIFT |    |   | |                            | |    |       |--&gt;
   |   |  .   | =2    |    |   | +----------------------------+ |    |       |
   |   |      |       |    |   |       CBQ 2:0                  |    |       |
   |   |      +-------+    +---+--------------------------------+    |       |
   |   |                                                             |       |
   |   +-------------------------------------------------------------+       |
   |                          DSMARK 1:0                                     |
   +-------------------------------------------------------------------------+

</Screen>

</Para>

<Para>
Entonces llega el paquete con el valor del campo DS puesto a 0xb8. Como
explicamos anteriormente, la qdisc dsmark identificada por el id 1:0 en el
ejemplo toma el campo DS y lo almacena en la variable skb-&gt;tc_index. El
siguiente paso del ejemplo corresponde al filtro asociado con esta qdisc
(segunda línea del ejemplo).
Esto realizará las siguientes operaciones:

<Screen>
Valor1 = skb-&#62;tc_index &#38; MASK
Clave = Valor1 &#62;&#62; SHIFT
</Screen>

</Para>

<Para>
En el ejemplo, MASC=0xFC i SHIFT=2.

<Screen>
Valor1 = 10111000 &#38; 11111100 = 10111000
Clave = 10111000 &#62;&#62; 2 = 00101110 -&#62; 0x2E en hexadecimal
</Screen>

</Para>

<Para>
El valor de recotno corresponderá a un controlador de filtro de una qdisc
interna (en el ejemplo, el identificador 2:0). Si existe un filtro con
este id, se verificarán las condiciones de control y medida (en caso de
que el filtro las incluya) y se devolverá y almacenará en la variable
skb-&gt;tc_index el classid (en nuestro ejemplo, classid 2:1).
</Para>

<Para>
Pero si se encuentra un filtro con ese identificador, el resultado
dependerá de la declaración de fall_through. Si la hay, se devolverá como
classid el valor clave. Si no, se devuelve un error y continúa el proceso
con el resto de filtros. Sea cuidadoso si usa fall_through; se puede hacer
si existe una relación simple entre los valores de la variable
skb-&gt;tc_index y el id de la clase.
</Para>

<Para>
Los últimos parámetros que hay que comentar son hash y pass_on. El primero
se refiere al tamaño de la tabla hash. Pass_on se usa para indicar que si
no se encuentra un classid igual al resultado de este filtro, se debe
intentar con el siguiente filtro. La acción por defecto es fall_through
(vea la siguiente tabla)
</Para>

<Para>
Por último, veamos qué valores posibles se pueden dar a todos estos
parámetros de TCINDEX:

<Screen>
Nombre TC               Valor           Por defecto
-----------------------------------------------------------------
Hash                    1...0x10000     Dependiente de la implementación
Mask                    0...0xffff      0xffff
Shift                   0...15          0
Fall through / Pass_on  Flag            Fall_through
Classid                 Mayor:menor     Nada
Police                  .....           Nada
</Screen>

</Para>

<Para>
Este tipo de filtro es muy poderoso. Es necesario explorar todas sus
posibilidades. Más aún, este filtro no se usa sólo en las configuraciones
con DiffServ. Lo puede usar como cualquier otro tipo de filtro.
</Para>

<Para>
Recomiendo que mire todos los ejemplos de DiffServ que se incluyen en la
distribución de iproute2. Prometo que trataré de completar este texto lo
más pronto que pueda. Además, todo lo que he explicado es el resultado de
muchas pruebas. Le agradecería que me dijese si me he equivocado en algún
momento.
</Para>

</Sect2>

</Sect1>

<Sect1 id="lartc.adv-qdisc.ingress">
  <Title>Qdisc de entrada (Ingress)</Title>

<Para>
Todas las qdisc comentadas hasta ahora eran de salida. Sin embargo, cada
interfaz tiene también una qdisc de entrada que no se usa para enviar
paquetes hacia el adaptador de red. En su lugar, permite aplicar filtros
de tc a los paquetes que vienen desde la interfaz, independientemente de
si su destino es local o han de ser reenviados.
</Para>

<Para>
Como los filtros de tc contienen una implementación completa del Token
Bucket Filter, y también son capaces de trabajar con el estimador de flujo
del núcleo, hay mucha funcionalidad disponible. Esto permite de forma
efectiva controlar el tráfico entrante, antes incluso de que entre en la
pila IP.
</Para>

<Sect2>
<Title>Parámetros y uso</Title>

<Para>
La qdisc de entrada en sí misma no precisa parámetros. Difiere de las otas
qdisc en que no ocupa la raíz de un dispositivo. Asóciela de esta manera:

<Screen>
# tc qdisc add dev eth0 ingress
</Screen>

Esto le permite tener otras qdisc de envío en el dispositivo aparte de la
de entrada.
</Para>

<Para>
Encontrará un ejemplo contribuido sobre el posible uso de la qdisc de
entrada en el Recetario.
</Para>

</Sect2>

</Sect1>

<Sect1 id="lartc.adv-qdisc.red">
  <Title>Random Early Detection (RED)</Title>

<Para>
Esta sección pretende ser una introducción al encaminamiento en
«backbones» <footnote><para>N. del T.: espinas dorsales, las vías más
anchas y rápidas de Internet</para></footnote>, que a menudo implica
anchos de banda de &gt;100 megabits, lo que precisa de un enfoque
diferente que para el módem ADSL de casa.
</Para>

<Para>
El comportamiento normal de las colas de router en la Internet se denomina
"tail-drop". El tail-drop (descarte de últimos) funciona encolando hasta
una cierta cantidad, y descartando después todo el tráfico que "se
rebose". Esto es bastante poco justo, y lleva a sincronización de
retransmisión. Cuando sucede esta sincronización, la súbita ráfaja de
descartes del router que ha llegado a su tope causa una ráfaga retardada
de retransmisiones, que vuelve a llenar en exceso el router congestionado.
</Para>

<Para>
Para copar con la congestión transitoria de los enlaces, los router de
backbone a menudo implementan grandes colas. Desafortunadamente, mientras
que estas colas están bien para la transferencia, pueden incrementar
sustancialmente la latencia y causar que las conexiones TCP se comporten
a ráfagas durante la congestión.
</Para>

<Para>
Los problemas de tail-drop están empezando a ser cada vez más acuciantes
en Internet debido al uso creciente de aplicaciones poco amigables para
las redes. El núcleo de Linux nos ofrece RED, abreviatura de Random Early
Detect (detección aleatoria temprana), también denominada Random Early
Drop (descarte aleatorio temprano), ya que es así como funciona.
</Para>

<Para>
RED no es un remedio milagroso para todo esto, y las aplicaciones que no
implementen esperas tras colisión (backoff) exponenciales seguirán
llenando una porción demasiado grande del ancho de banda, pero con RED no
causan tanto daño a la transferencia y la latencia de otras conexiones.
</Para>

<Para>
RED descarta paquetes de los flujos estadísticamente antes de que lleguen
a un límite absoluto (hard). Esto hace que un enlace congestionado en un
backbone reduzca la marcha de una manera más elegante, y evita la
sincronización de retransmisiones. También ayuda a TCP a encontrar su
velocidad "correcta" más rápido permitiendo que algunos paquetes caigan
pronto manteniendo bajo el tamaño de las colas y la latencia bajo control.
La probabilidad de que se descarte un paquete de una conexión particular
es proporcional a su uso de ancho de banda en lugar de al número de
paquetes que transmite.
</Para>

<Para>
RED es una buena cola para backbones, donde no te puedes permitir la
complejidad de supervisar el estado por sesión que se necesita para un
encolado correcto.
</Para>

<Para>
Para usar RED, debe decidir tres parámetros: Min, Max, y burst. Min
establece el tamaño mínimo de la cola en bytes antes de que empiecen los
descartes, Max es un máximo preventivo (soft) bajo el que intenta
mantenerse el algoritmo, y burst especifica el número máximo de paquetes
que pueden "pasar en ráfaga".
</Para>

<Para>
Debería establecer min calculando la latencia básica más alta aceptable
que desea en las colas, multiplicándola por el ancho de banda. Por
ejemplo, en mi enlace RDSI de 64kbit/s, querría una latencia base de cola
de 200ms de manera que pongo un mínimo de 1600 bytes. Poner un min
demasiado pequeño degradará la transferencia y demasiado grande degradará
la latencia. Poner un min pequeño no es un reemplazo de la reducción de la
MTU en un enlace lento para mejorar la respuesta interactiva.
</Para>

<Para>
Debería poner un max de al menos el doble que min para evitar la
sincronización. En enlaces lentos con Min pequeño quizá fuera más sensato
hacer max cuatro o cinco veces más grande que min.
</Para>

<Para>
Burst controla cómo responde el algoritmo RED a las ráfagas. Burst se debe
hacer más grande que min/avpkt. De forma experimental he establecido que
(min+min+max)/(3*avpkt) funciona bien.
</Para>

<Para>
Además, necesita indicar limit y avpkt. Limit es un valor de seguridad, y
tras pasar la cola de limit bytes, RED "se pone en modo" tail-drop.
Normalmente pongo el límite en ocho veces max. Avpkt debería ser el tamaño
medio de los paquetes. 1000 funciona BIEN en enlaces de Internet de alta
velocidad con una MTU de 1500.
</Para>

<Para>
Lea el <ULink
URL="http://www.aciri.org/floyd/papers/red/red.html"
>documento sobre colas RED</ULink
> de Sally Floyd y Van Jacobson si de sea información
técnica.
</Para>

</Sect1>

<Sect1 id="lartc.adv-qdisc.gred">
<Title>Generic Random Early Detection</Title>

<Para>
No se sabe mucho sobre GRED. Se parece a RED con varias colas internas,
siendo escogidas estas colas internas basándose en el campo tcindex de
DiffServ. De acuerdo a una transparencia que se encuentra
<ULink URL="http://www.davin.ottawa.on.ca/ols/img22.htm">aquí</ULink>,
contiene las capacidades del «Distributed Weighted RED» de Cisco, así como
del RIO de Dave Clark.
</Para>

<Para>
Cada paquete virtual puede tener especificados sus propios parámetros de
descarte (Drop Parameters).
</Para>

<Para>
FIXME: hacer que Jamal o Werner nos cuenten más
</Para>

</Sect1>

<Sect1 id="lartc.adv-qdisc.vc-atm">
  <Title>Emulación VC/ATM</Title>

<Para>
Este es un gran esfuerzo de Werner Almesberger para permitirle construir
Circuitos Virtuales sobre sockets TCP/IP. Un Circuito Virtual es un
concepto que viene de la teoría de redes ATM.
</Para>

<Para>
Si desea más información, consulte la <ULink
URL="http://linux-atm.sourceforge.net/"
>página web de ATM sobre Linux</ULink
>. 
</Para>

</Sect1>

<Sect1 id="lartc.adv-qdisc.wrr">
  <Title>Weighted Round Robin (WRR)</Title>

<Para>
Esta qdisc no se incluye en los núcleos estándar pero la puede descargar
de <ULink URL="http://wipl-wrr.dkik.dk/wrr/">aquí</ULink>.
Actualmente la qdisc sólo está probada con núcleos Linux 2.2 pero
probablemente funcionará también con núcleos 2.4/2.5.
</Para>

<Para>
La qdisc WRR distribuye ancho de banda entre sus clases usando el esquema
de weighted round robin. Osea, que al igual que la qdisc CBQ contiene
clases dentro de las cuales se pueden colocar qdisc arbitrarias. Todas las
clases que tengan suficiente demanda obtendrán un ancho de banda
proporcional a los pesos asociados con las clases.
Se puede establecer los pesos de forma manual usando el programa <Literal
remap="tt">tc</Literal>. Pero también pueden decrementarse de forma
automática para clases que transfieran demasiados datos.
</Para>

<Para>
La qdisc incluye un clasificador que asigna a diferentes clases los
paquetes que vienen o van a diferentes máquinas. Se puede usar tanto la
MAC como la IP y las direcciones de origen o destino. Sin embargo, la
dirección MAC sólo se puede usar cuando la máquina Linux esté actuando
como bridge ethernet. Las clases se van asignando automáticamente a
máquinas basándose en los paquetes vistos.
</Para>

<Para>
Esta qdisc puede ser muy útil en sitios como una residencia estudiantil
donde muchos individuos sin relación alguna comparten una conexión a
Internet. La distribución de WRR contiene como uno de sus elementos
centrales varios script que configuran un comportamiento relevante a tales
sitios.
</Para>

</Sect1>

</chapter>

<chapter id="lartc.cookbook"
  xreflabel="Cookbook">
  <Title>Recetario</Title>

<Para>
Esta sección contiene "recetas" que pueden ayudarle a resolver problemas.
Aún así, un recetario no reemplaza al conocimiento, de manera que intente
comprender qué es lo que sucede.
</Para>

<Sect1 id="lartc.cookbook.sla">
<Title>Llevar varios sitios con diferentes SLA<footnote><para>N del T: SLA es Service Level Agreement. Se refiere a
clientes que han firmado por tener diferentes servicios.</para></footnote></Title>

<Para>
Esto se puede hacer de varias maneras. Apache tiene soporte para esto en
un módulo, pero mostraremos cómo puede hacerse con Linux, y por tanto con
otros servicios. Estas órdenes las robamos de una presentación de Jamal
Hadi a la que se hace referencia más adelante.
</Para>

<Para>
Digamos que tenemos dos clientes, con http, ftp y streaming de sonido, y
queremos venderle una cantidad limitada de ancho de banda. Lo haremos en
el propio servidor. 
</Para>

<Para>
El cliente A debería tener al menos 2 megabits, el cliente B ha pagado por
5 megabits. Separamos nuestros clientes creando IP virtuales en nuestro
servidor.
</Para>

<Para>

<Screen>
# ip address add 188.177.166.1 dev eth0
# ip address add 188.177.166.2 dev eth0
</Screen>

</Para>

<Para>
Es su responsabilidad asociar los diferentes servidores a la dirección IP
correcta. Todos los demonios populares soportan esto.
</Para>

<Para>
Primero asociamos una qdisc CBQ a eth0:

<Screen>
# tc qdisc add dev eth0 root handle 1: cbq bandwidth 10Mbit cell 8 avpkt 1000 \
  mpu 64
</Screen>

</Para>

<Para>
Entonces creamos clases para nuestros clientes:
</Para>

<Para>

<Screen>
# tc class add dev eth0 parent 1:0 classid 1:1 cbq bandwidth 10Mbit rate \
  2MBit avpkt 1000 prio 5 bounded isolated allot 1514 weight 1 maxburst 21
# tc class add dev eth0 parent 1:0 classid 1:2 cbq bandwidth 10Mbit rate \
  5Mbit avpkt 1000 prio 5 bounded isolated allot 1514 weight 1 maxburst 21
</Screen>

</Para>

<Para>
Luego añadimos filtros para nuestras dos clases:

<Screen>
##FIXME: ¿Por qué esta línea, qué hace?, ¿qué es un divisor?:
##FIXME: Un divisor tiene algo que ver con una tabla hash, y el número de
#        buckets - ahu
# tc filter add dev eth0 parent 1:0 protocol ip prio 5 handle 1: u32 divisor 1
# tc filter add dev eth0 parent 1:0 prio 5 u32 match ip src 188.177.166.1
  flowid 1:1
# tc filter add dev eth0 parent 1:0 prio 5 u32 match ip src 188.177.166.2
  flowid 1:2
</Screen>

</Para>

<Para>
Y ya está.
</Para>

<Para>
FIXME: ¿por qué no usar el token bucket filter? ¿hay alguna pfifo_fast por
defecto de respaldo en algún lado?
</Para>

</Sect1>

<Sect1 id="lartc.cookbook.synflood-protect"
  xreflabel="Protecting your host from SYN floods">
  <Title>Proteger la máquina frente a inundaciones SYN</Title>

<Para>
De la documentación de Alexey sobre iproute, adaptado a netfilter y con
más vías plausibles. Si usa esto, asegúrese de ajustar los números a
valores razonables para su sistema.
</Para>

<Para>
Si quiere proteger una red entera, sáltese este script, que se ajusta
mejor a una única máquina.
</Para>

<Para>
Parece que se necesita la última versión de las herramientas iproute2 para
que esto funcione con 2.4.0.
</Para>

<Para>

<Screen>
#! /bin/sh -x
#
# sample script on using the ingress capabilities
# this script shows how one can rate limit incoming SYNs
# Useful for TCP-SYN attack protection. You can use
# IPchains to have more powerful additions to the SYN (eg 
# in addition the subnet)
#
#path to various utilities;
#change to reflect yours.
#
TC=/sbin/tc
IP=/sbin/ip
IPTABLES=/sbin/iptables
INDEV=eth2
#
# tag all incoming SYN packets through $INDEV as mark value 1
############################################################ 
$iptables -A PREROUTING -i $INDEV -t mangle -p tcp --syn \
  -j MARK --set-mark 1
############################################################ 
#
# install the ingress qdisc on the ingress interface
############################################################ 
$TC qdisc add dev $INDEV handle ffff: ingress
############################################################ 

#
# 
# SYN packets are 40 bytes (320 bits) so three SYNs equals
# 960 bits (approximately 1kbit); so we rate limit below
# the incoming SYNs to 3/sec (not very useful really; but
#serves to show the point - JHS
############################################################ 
$TC filter add dev $INDEV parent ffff: protocol ip prio 50 handle 1 fw \
police rate 1kbit burst 40 mtu 9k drop flowid :1
############################################################ 


#
echo "---- qdisc parameters Ingress  ----------"
$TC qdisc ls dev $INDEV
echo "---- Class parameters Ingress  ----------"
$TC class ls dev $INDEV
echo "---- filter parameters Ingress ----------"
$TC filter ls dev $INDEV parent ffff:

#deleting the ingress qdisc
#$TC qdisc del $INDEV ingress
</Screen>

</Para>

</Sect1>

<Sect1 id="lartc.cookbook.icmp-ratelimit">
  <Title>Limitar la tasa de ICMP para prevenir dDoS</Title>

<Para>
Recientemente, los ataques distribuidos de negación de servicio se han
convertido en una amenaza importante para la Internet. Filtrando y
limitando tasas de forma adecuada en nuestra red, podemos evitar tanto ser
una víctima como la causa de uno de estos ataques.
</Para>

<Para>
Debería filtrar sus redes de manera que no permita abandonarlas a ningún
paquete con IP de origen no local. Esto hace que la gente no pueda enviar
porquería a la Internet de forma anónima.
</Para>

<Para>
La limitación de tasas va como dijimos antes. Para refrescarle la memoria,
aquí tiene de nuevo nuestro ASCIIgrama.
</Para>

<Para>

<Screen>
[La Internet] ---&#60;E3, T3, da igual&#62;--- [router Linux] --- [Oficina+ISP]
                                      eth1          eth0
</Screen>

</Para>

<Para>
Primero configuramos los prerequisitos:
</Para>

<Para>

<Screen>
# tc qdisc add dev eth0 root handle 10: cbq bandwidth 10Mbit avpkt 1000
# tc class add dev eth0 parent 10:0 classid 10:1 cbq bandwidth 10Mbit rate \
  10Mbit allot 1514 prio 5 maxburst 20 avpkt 1000
</Screen>

</Para>

<Para>
Si tenemos interfaces de 100Mbit o más, hay que ajustar estos números.
Ahora tenemos que determinar cúanto tráfico ICMP deseamos permitir. Se
pueden hacer mediciones con tcpdump, haciendo que escriba en un fichero
durante un rato, y viendo cuánto ICMP pasa por la red. ¡No olvide aumentar
la longitud de la captura!
</Para>

<Para>
Si hacer mediciones es poco práctico, quizá quiera escoger un 5%
del ancho de banda disponible. Configuremos nuestra clase:

<Screen>
# tc class add dev eth0 parent 10:1 classid 10:100 cbq bandwidth 10Mbit rate \
  100Kbit allot 1514 weight 800Kbit prio 5 maxburst 20 avpkt 250 \
  bounded
</Screen>

</Para>

<Para>
Esto limita a 100Kbit. Ahora necesitamos un filtro para asignarle el
tráfico ICMP a esta clase:

<Screen>
# tc filter add dev eth0 parent 10:0 protocol ip prio 100 u32 match ip
  protocol 1 0xFF flowid 10:100

</Screen>

</Para>

</Sect1>

<Sect1 id="lartc.cookbook.interactive-prio">
<Title>Priorizado de tráfico interactivo</Title>

<Para>
Si están saliendo muchos datos por su enlace, o entrando que para el caso
es lo mismo, y está intentando hacer mantenimiento vía telnet o ssh, puede
que la cosa no vaya muy bien. Los otros paquetes están bloqueando nuestras
pulsaciones. ¿No sería maravilloso si hubiera una manera de que nuestros
paquetes interactivois se colasen por entre el tráfico masivo? ¡Linux
puede hacerlo!
</Para>

<Para>
Como antes, necesitamos gestionar el tráfico que va en ambas direcciones.
Evidentemente, esto funciona mejor si hay máquinas Linux a ambos lados del
enlace, aunque otros UNIX son capaces de hacerlo. Consulte a su gurú local
de Solaris/BSD al respecto.
</Para>

<Para>
El organizador pfifo_fast estándar tiene 3 "bandas" diferentes. El tráfico
del a banda 0 se transmite antes, tras lo cual se toma en consideración el
tráfico de las bandas 1 y 2. ¡Es vital que nuestro tráfico interactivo
vaya a la banda 0!
</Para>

<Para>
Hemos adaptado esto desvergonzadamente directamente del ipchains HOWTO
(que pronto estará obsoleto):
</Para>

<Para>
Hay cuatro bits en la cabecera IP que se usan rara vez, llamados los bits
de Tipo de Servicio (TOS). Afectan la manera en que se trata un paquete;
los cuatro bits son "Retraso Mínimo", "Transferencia Máxima", "Fiabilidad
Máxima" y "Coste Mínimo". Sólo se permite activar uno de estos bits. Rob
van Nieuwkerk, el autor del código de ipchains que trabaja con el TOS, lo
dice así:
</Para>

<Para>

<Screen>
El "Mínimum Delay" es especialmente importante para mí. Lo activo para
paquetes "interactivos" en mi router (Linux) de salida. Estoy tras un
enlace por módem a 33k6. Linux prioriza los paquetes en tres colas. De
esta manera, consigo un rendimiento interactivo aceptable mientras realizo
descargas masivas al mismo tiempo.
</Screen>

</Para>

<Para>
El uso más común es marcar las conexiones de telnet y control de ftp con
"Retraso Mínimo", y la de datos de FTP a "Transferencia Máxima". Esto
debería hacerse de la siguiente manera, en el router de salida:
</Para>

<Para>

<Screen>
# iptables -A PREROUTING -t mangle -p tcp --sport telnet \
  -j TOS --set-tos Minimize-Delay
# iptables -A PREROUTING -t mangle -p tcp --sport ftp \
  -j TOS --set-tos Minimize-Delay
# iptables -A PREROUTING -t mangle -p tcp --sport ftp-data \
  -j TOS --set-tos Maximize-Throughput
</Screen>

</Para>

<Para>
Lo hecho hasta ahora sólo sirve para los datos que vienen de la máquina
remota hacia la suya. Para los que van en el otro sentido parece que ya
está hecho, ya que telnet, ssh y amigos activan el campo TOS
automáticamente en los paquetes que salen.
</Para>

<Para>
Si tuviera una aplicación que no lo hace, siempre puede controlarlo con
netfilter. En la máquina local:
</Para>

<Para>

<Screen>
# iptables -A OUTPUT -t mangle -p tcp --dport telnet \
  -j TOS --set-tos Minimize-Delay
# iptables -A OUTPUT -t mangle -p tcp --dport ftp \
  -j TOS --set-tos Minimize-Delay
# iptables -A OUTPUT -t mangle -p tcp --dport ftp-data \
  -j TOS --set-tos Maximize-Throughput
</Screen>

</Para>

    </Sect1>

    <Sect1 id="lartc.cookbook.squid">
      <Title>Caché transparente de web usando <application>netfilter</application>,
	<application>iproute2</application>, <application>ipchains</application> y
	<application>squid</application></Title>
      
      <Para>
        Esta sección nos la envió el lector Ram Narula de Internet para la
	Educación (Tailandia).
      </Para>
      
      <Para>
	La técnica habitual para conseguir esto en Linux probablemente
	es usar ipchains DESPUES de asegurarse que el tráfico de "salida"
	del puerto 80(web) se dirige al servidor que ejecuta el squid.
      </Para>

      <Para>
	Hay 3 métodos comunes para asegurarse de que el tráfico "saliente"
	del puerto 80 se envía al servidor que ejecuta el squid, y aquí
	vamos a introducir una cuarta.
      </Para>
      
      <Para>
	<VariableList>
	  <VarListEntry>
	    <Term>Que el router pasarela lo haga por tí.</Term>
	    <ListItem>
	      <Para>
		Si puede decirle a su pasarela que haga que los
		paquetes que salen hacia el puerto 80 sean enviados
		hacia la dirección IP del servidor squid.
	      </Para>
	      
	      <Para>
		PERO
	      </Para>

	      <Para>
	        Esto añadiría una carga adicional al router y algunos
		router comerciales podrían no soportarlo siquiera.
	      </Para>
	    </ListItem>
	  </VarListEntry>
	  <VarListEntry>
	    <Term>Usar un switch de capa 4.</Term>
	    <ListItem>
	      <Para>
		Los switchs de capa 4 pueden gestionar esto sin problemas.
	      </Para>
	      
	      <Para>
		PERO
	      </Para>
	      
	      <Para>
		El coste de este equipamiento suele ser muy alto. Un
		switch de capa 4 típico normalmente costará más que el
		router típico + un buen servidor linux.
	      </Para>
	    </ListItem>
	  </VarListEntry>
	  <VarListEntry>
	    <Term>Usar un servidor caché como pasarela de la red.</Term>
	    <ListItem>
	      <Para>
		Puede forzar que TODO el tráfico pase por el servidor
		caché.
	      </Para>
	      <Para>
		PERO
	      </Para>
	      <Para>
		Esto es muy arriesgado porque Squid utiliza gran cantidad
		de CPU y podría acabar ralentizando el rendimiento de la
		red entera o que el propio servidor se caiga, y nadie de
		la red podrá acceder a Internet si esto ocurre.
	      </Para>
	    </ListItem>
	  </VarListEntry>
	  <VarListEntry>
	    <Term>Linux+router NetFilter.</Term>
	    <ListItem>
	      <Para>
		Con NetFilter se puede implementar otra técnica que usa
		NetFilter para "marcar" los paquetes con puerto de destino
		80 e iproute2 para encaminar los paquetes marcados al
		servidor Squid.
	      </Para>
	    </ListItem>
	  </VarListEntry>
	</VariableList>
	<Screen>
|----------------|
| Implementación |
|----------------|

 Direcciones usadas
 10.0.0.1 naret (Servidor NetFilter)
 10.0.0.2 silom (Servidor Squid)
 10.0.0.3 donmuang (Router conectado a Internet)
 10.0.0.4 kaosarn (otro servidor de la red)
 10.0.0.5 RAS
 10.0.0.0/24 red principal
 10.0.0.0/19 red total

|---------------|
|Diagrama de red|
|---------------|

Internet
|
donmuang
|
------------hub/switch----------
|        |             |       |
naret   silom        kaosarn  RAS etc.
	</Screen>

	Primero, hagamos pasar todo el tráfico a través de naret
	asegurándonos de que es la pasarela por defecto excepto para
	silom. La pasarela por defecto de silom será donmuang (10.0.0.3) o
	crearíamos un bucle de tráfico.
      </Para>
      <Para>
	(todos los servidores de mi red tienen como pasarela por defecto a
	10.0.0.1, que era la anterior dirección IP del router donmuang,
	así que lo que he hecho es cambiar la dirección IP de donmuang a
	10.0.0.3 y darle a naret la dirección ip 10.0.0.1)
      </Para>
      <Para>
	<Screen>
Silom
-----
-configurar squid e ipchains
	</Screen>
      </Para>
      <Para>
	Configuramos el servidor Squid de silom, y nos aseguramos de que soporte
	proxy/caché transparente; el puerto por defecto suele ser 3218, de
	manera que se tiene que redirigir localmente todo el tráfico hacia
	el puerto 80 al puerto 3128. Esto se puede hacer con ipchains con
	lo siguiente:
      </Para>
      <Para>
	<Screen>
silom# ipchains -N allow1
silom# ipchains -A allow1 -p TCP -s 10.0.0.0/19 -d 0/0 80 -j REDIRECT 3128
silom# ipchains -I input -j allow1
	</Screen>
      </Para>
      <Para>
O, en el idioma de netfilter:
	<Screen>
silom# iptables -t nat -A PREROUTING -i eth0 -p tcp --dport 80 -j REDIRECT --to-port 3128
	</Screen>
      </Para>
      <Para>
	(nota: podría tener otras entradas también)
      </Para>
      <Para>
	Si desea más información sobre configuración del servidor Squid,
	por favor, remítase a la página de las FAQ de Squid en <ULink
	  URL="http://squid.nlanr.net">http://squid.nlanr.net</ULink>).
      </Para>
      <Para>
	Nos aseguramos de que este servidor tiene activo el reenvío de ip
	(forwarding) y de que su pasarela por defecto es el router
	donmuang (NO naret).
      </Para>
      <Para>
	<Screen>
Naret
-----
-configurar iptables e iproute2
-desactivar los mensajes icmp REDIRECT (si es necesario)
	</Screen>
      </Para>
      <Para>
	<OrderedList>
	  <ListItem>
	    <Para>
	      "Marca" con el valor 2 los paquetes con destino al puerto 80
	      <Screen>
naret# iptables -A PREROUTING -i eth0 -t mangle -p tcp --dport 80 \
 -j MARK --set-mark 2
	      </Screen>
	    </Para>
	  </ListItem>
	  <ListItem>
	    <Para>
	      Configuramos iproute2 para que envíe los paquetes con la
	      marca 2 a silom
	      <Screen>
naret# echo 202 www.out &#62;&#62; /etc/iproute2/rt_tables
naret# ip rule add fwmark 2 table www.out
naret# ip route add default via 10.0.0.2 dev eth0 table www.out
naret# ip route flush cache
	      </Screen>
	    </para>
	    <Para>
	      Si donmuang y naret están en la misma subred entonces naret
	      no debería enviar mensajes icmp REDIRECT.
	      En este caso, deberíamos desactivar los icmp REDIRECT así:
	      <Screen>
naret# echo 0 &#62; /proc/sys/net/ipv4/conf/all/send_redirects
naret# echo 0 &#62; /proc/sys/net/ipv4/conf/default/send_redirects
naret# echo 0 &#62; /proc/sys/net/ipv4/conf/eth0/send_redirects
	      </Screen>
	    </Para>
	  </ListItem>
	</OrderedList>
      </Para>
      <Para>
	Hemos terminado el montaje, comprobemos la configuración
      </Para>
      <Para>
	<Screen>
En naret:

naret# iptables -t mangle -L
Chain PREROUTING (policy ACCEPT)
target     prot opt source               destination         
MARK       tcp  --  anywhere             anywhere           tcp dpt:www MARK set 0x2 

Chain OUTPUT (policy ACCEPT)
target     prot opt source               destination         

naret# ip rule ls
0:      from all lookup local 
32765:  from all fwmark        2 lookup www.out 
32766:  from all lookup main 
32767:  from all lookup default 

naret# ip route list table www.out
default via 203.114.224.8 dev eth0 

naret# ip route   
10.0.0.1 dev eth0  scope link 
10.0.0.0/24 dev eth0  proto kernel  scope link  src 10.0.0.1
127.0.0.0/8 dev lo  scope link 
default via 10.0.0.3 dev eth0 

(hay que asegurarse de que silom aparece en una de las líneas anteriores,
en este caso es la línea con 10.0.0.0/24)

|-------|
|-HECHO-|
|-------|
	</Screen>
      </Para>
      <Sect2>
<Title>Diagrama de flujo del tráfico tras la implementación</Title>

<Screen width="80">

|----------------------------------------------------|
|Diagrama de flujo del tráfico tras la implementación|
|----------------------------------------------------|

INTERNET
/\
||
\/
-----------------router donmuang---------------------
/\                                      /\         ||
||                                      ||         ||
||                                      \/         ||
naret                                  silom       ||
*tráfico hacia el puerto 80==========&#62;(caché)      ||
/\                                      ||         ||
||                                      \/         \/
\\===================================kaosarn, RAS, etc.

</Screen>

<Para>
Tengan en cuenta que la red es asimétrica ya que hay un salto extra en la
ruta general de salida.
</Para>

<Para>

<Screen>
Este es el camino seguido por los paquetes que atraviesan la red desde
kaosarn hacia y desde Internet.

Tráfico web/http:
consulta http de kaosarn-&#62;naret-&#62;silom-&#62;donmuang-&#62;internet
respuestas http desde Internet-&#62;donmuang-&#62;silom-&#62;kaosarn

consultas no web/http (ej: telnet):
datos salientes de kaosarn-&#62;naret-&#62;donmuang-&#62;internet
datos entrantes de Internet-&#62;donmuang-&#62;kaosarn
</Screen>

</Para>

</Sect2>

</Sect1>

<Sect1 id="lartc.cookbook.mtu-discovery">
<Title>Sortear los problemas de Path MTU Discovery con configuraciones de MTU por ruta</Title>

<Para>
Generalmente, Internet funciona mejor enviando tráfico masivo si se usan
paquetes grandes. Cada paquete implica una decisión de encaminamiento, y
cuando se envía un fichero de 1 megabyte, podemos estar hablando de
alrededor de 700 paquetes si se envían del mayor tamaño posible, o 4000 si
se usa el valor pequeño por defecto.
</Para>

<Para>
Sin embargo, no todas las partes de Internet soportan 1460 bytes de carga
por paquete. Por tanto, se hace necesario probar hasta encontrar el mayor
paquete que "encaje", para optimizar una conexión.
</Para>

<Para>
Este proceso se denomina «Descubrimiento de MTU de la ruta» (Path MTU
Discovery), siendo MTU la «Maximum Transfer Unit».
</Para>

<Para>
Cuando un router encuentra un paquete que es demasiado grande para
enviarlo de una sola pieza, Y que está marcado con el bit «Don't
Fragment», devuelve un mensaje ICMP que indica que se vio obligado a
descartar un paquete por esta causa. La máquina que lo envió reacciona a
esto enviando paquetes más pequeños, y repitiendo puede encontrar el
tamaño de paquete óptimo para una conexión sobre determinada ruta.
</Para>

<Para>
Esto funcionó bien hasta que los hooligans que se dedican a interferir en
las comunicaciones descubrieron la Internet. Esto hizo que los
administradores bloqueasen o ajustasen el tráfico ICMP en un intento
equivocado de mejorar la seguridad o robustez de su servicio de Internet.
</Para>

<Para>
Lo que ocurre ahora es que el Path MTU Discovery funciona cada vez peor y
falla en determinadas rutas, lo que lleva a sesiones TCP/IP extrañas que
mueren al cabo de un tiempo.
</Para>

<Para>
Aunque no tengo pruebas de esto, dos sitios con los que solía tener este
problema tenían Alteon Acedirectors delante de los sistemas afectados
(quizá alguien con más conocimientos pueda darme pistas de por qué sucede
esto).
</Para>

<Sect2>
<Title>Solución</Title>

<Para>
Cuando encuentre sitios que sufren este problema, puede desactivar el Path
MTU discovery configurándolo manualmente. Koos van den Hout, con pequeños
cambios, escribe:
</Para>

<blockquote>
<Para>
El siguiente problema: configuro la mtu/mru de mi línea dedicada con ppp a
296 porque sólo es una 33k6 y no puedo influenciar el encolado en el otro
extremo. A 296, la respuesta a una pulsación de tecla está dentro de un
margen razonable.
</Para>

<Para>
Y por mi lado tengo un masqrouter con Linux (por supuesto).
</Para>

<Para>
Recientemente, separé el "servidor" y el "router", de manera que la mayoría
de mis aplicaciones funcionan en una máquina diferente a la que hace el
encaminamiento.
</Para>

<Para>
Entonces tuve problemas al entrar en irc. ¡Pánico! Escarbando un poco
averigué que sí conectaba a irc, e incluso aparecía como conectado allí,
pero no recibía el motd. Busqué lo que podía estar mal y me acordé que ya
había tenido problemas relacionados con la MTU para acceder a ciertos
sitios web, ya que no tenía problemas para acceder cuando ponía la MTU a
1500, y el problema sólo aparecía cunado la ponía a 296. Como los
servidores de irc bloquean casi cualquier tipo de tráfico que no sea
necesario para su operación inmediata, también bloquean icmp.
</Para>

<Para>
Conseguí convencer a los operadores de un servidor web de que ésta era la
causa del problema, pero los operadores del servidor de irc no iban
arreglarlo.
</Para>

<Para>
De manera que tenía que asegurarme de que el tráfico enmascarado empezaba
con la mtu más baja del enlace externo. Pero quería que mi tráfico
ethernet local tuviera una mtu normal (para cosas como el tráfico nfs).
</Para>

<Para>Solucion:
</Para>

<Screen width="80">
ip route add default via 10.0.0.1 mtu 296
</Screen>

<Para>
(siendo 10.0.0.1 la pasarela por defecto, la dirección interna del router
enmascarador)
</Para>
</blockquote>

<Para>
En general, es posible saltarse el PMTU Discovery configurando rutas
específicas. Por ejemplo, si sólo da problemas cierta subred, esto podría
ayudar:
</Para>

<Screen width="80">
ip route add 195.96.96.0/24 via 10.0.0.1 mtu 1000
</Screen>

</Sect2>

</Sect1>

<Sect1 id="lartc.cookbook.mtu-mss">
  <Title>Sortear los problemas de Path MTU Discovery con MSS Clamping
  (para usuarios de ADSL, cable, PPPoE y PPtP)</Title>

<Para>
Como explicamos anteriormente, el Path MTU Discovery ya no funciona bien.
Si sabe de hecho que algún salto en algún lado de su red tiene una MTU
limitada (&lt;1500), no puede depender de PMTU Discovery para encontrarlo.
</Para>

<Para>
Aparte de la MTU, hay otra manera más de establecer el tamaño máximo de un
paquete, denominada Tamaño Máximo de Segmento (Maximum Segment Size.).
Este es un campo en la parte de Opciones TCP de un paquete SYN.
</Para>

<Para>
Los núcleos Linux recientes, y unos pocos controladores PPPoE (en especial
el excelente de Roaring Penguin), permiten la posibilidad de «fijar el MSS».
</Para>

<Para>
Lo bueno de esto es que estableciendo el valor del MSS, le está diciendo
inequívocamente al otro extremo «nunca intentes siquiera mandarme paquetes
más grandes que este valor». No se necesita tráfico ICMP para que esto
funcione.
</Para>

<Para>
Lo malo es que obviamente es un "hack" (rompe el "end to end" modificando
los paquetes). Dicho esto, usamos este truco en varios sitios, y funciona
de maravilla.
</Para>

<Para>
Para que esto funcione necesitaremos al menos iptables-1.2.1a y Linux
2.4.3 o mayor. La línea de órdenes es:

<Screen>
# iptables -A FORWARD -p tcp --tcp-flags SYN,RST SYN -j TCPMSS  --clamp-mss-to-pmtu
</Screen>

</Para>

<Para>
Esto calcula el MSS adecuado para su enlace. Si nos sentimos valientes, o
pensamos que tenemos más idea, podemos hacer algo como esto:
</Para>

<Para>

<Screen>
# iptables -A FORWARD -p tcp --tcp-flags SYN,RST SYN -j TCPMSS --set-mss 128
</Screen>

</Para>

<Para>
Esto establece el MSS de los paquetes SYN que pasen a 128. Uselo si
tiene VoIP con paquetes pequeños, y grandes paquetes de http están
provocando que sus llamadas se entrecorten.
</Para>

</Sect1>

<Sect1 id="lartc.cookbook.ultimate-tc">
<Title>El acondicionador de tráfico definitivo: baja latencia, envíos y
descargas rápidos</Title>

<Para>
Nota: este script ha sido actualizado recientemente ¡y anteriormente sólo
funcionaba con los clientes Linux de su red! De manera que quizá quiera
actualizarlo, si tiene máquinas Windows o Mac en la red, y ha comprobado
que no son capaces de descargar más rápido mientras los otros están
enviando datos.
</Para>

<Para>
He intentado crear el santo grial:
<VariableList>

<VarListEntry>
<Term>Mantener una latencia baja todo el tiempo para el tráfico
interactivo</Term>
<ListItem>
<Para>
Esto significa que descargar o enviar ficheros no debería molestar a SSH o
incluso a telnet. Estas son las cosas más importantes, y es lentísimo
trabajar incluso con una latencia de 200ms.
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>Permitir la "navegación" a velocidades razonables mientras se envía
o descarga información</Term>
<ListItem>
<Para>
Incluso pensando que http es tráfico "masivo", el resto de tráfico no
debería ahogarlo demasiado.
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>Asegurarse de que los envíos no dañan las descargas, y viceversa</Term>
<ListItem>
<Para>
Se observa a menudo el fenómeno de que el tráfico de subida destruye la
velocidad de descarga.
</Para></ListItem>
</VarListEntry>
</VariableList>
Resulta que todo esto es posible, al coste de una pequeña cantidad de
ancho de banda. La razón de que los envíos, descargas y ssh se maten entre
ellos es la presencia de grandes colas en muchos dispositivos domésticos
de acceso como los módem de cable y DSL.
</Para>

<Para>
La siguiente sección explica en profundidad lo que causa los retrasos, y
cómo podemos corregirlo. Puede saltárselo tranquilamente y pasar
directamente al script si no le importa cómo se realiza esta magia.
</Para>

<Sect2>
<Title>Por qué no funciona bien por defecto</Title>

<Para>
Los ISP saben que se les compara sólamente según lo rápido que puede
descargar la gente. Aparte del ancho de banda disponible, la velocidad de
descarga viene muy influenciada por la pérdida de paquetes, que
obstaculiza seriamente el rendimiento de TCP/IP. Las colas grandes pueden
ayudar a evitar la pérdida de paquetes, y acelera las descargas. De manera
que los ISP configuran colas grandes.
</Para>

<Para>
Sin embargo, estas grandes colas dañan la interactividad. Una pulsación
tiene que pasar primero por la cola de envío, lo que puede tardar varios
segundos (!) y llegar a la máquina remota. Entonces se muestra, lo que
genera un paquete de vuelta, que debe atravesar otra cola, situada en el
ISP, antes de aparecer en la pantalla.
</Para>

<Para>
Esta Cómo le explica cómo cambiar y procesar la cola de varias maneras,
pero tristemente, no todas estas colas están a nuestro alcance. La cola
del ISP está completamente fuera de nuestros límites, mientras que la cola
de envío probablemente reside en el cable módem o en el dispositivo DSL.
Puede ser o no que haya posibilidad de configurarla. Lo más probable es
que no.
</Para>

<Para>
De manera que, ¿qué sigue? Ya que no podemos controlar ninguna de esas
colas, debemos eliminarlas, y trasladarlas a nuestro router Linux. Por
suerte, esto es posible.
</Para>

<Para>
<VariableList>

<VarListEntry>
<Term>Limitar la velocidad de envío</Term>
<ListItem>
<Para>
Limitando nuestra velocidad de envío a poco menos de la verdadera tasa
disponible, no creamos colas en nuestro módem. La cola se ha trasladado al
Linux.
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>Limitar la velocidad de descarga</Term>
<ListItem>
<Para>
Esto tiene algo más de truco, ya que no podemos influenciar realmente lo
rápido que internet nos entrega los datos. Sin embargo, podemos descartar
paquetes que vengan demasiado rápido, lo que hace que TCP/IP frene justo
hasta la tasa que deseamos. Como no deseamos descartar tráfico
innecesariamente, configuraremos el tamaño de la "ráfaga" que permitiremos
a altas velocidades.
</Para></ListItem>
</VarListEntry>
</VariableList>
</Para>

<Para>
Ahora, una vez hecho esto, hemos eliminado totalmente la cola de descarga
(exceptuando pequeñas ráfagas), y ganado la capacidad de gestionar la cola
de envío con todo el potencial que ofrece Linux.
</Para>

<Para>
Lo que queda por hacer es asegurarnos de que el tráfico interactivo pase a
primera línea de la cola de subida. Para asegurarnos de que los envíos no
obstaculizan las descargas, también pasaremos los paquetes ACK a primera
línea. Esto es lo que normalmente produce la gran reducción de velocidad
cuando se genera tráfico masivo en ambas direcciones. Las confirmaciones
(ACKnowledgements) del tráfico de descarga deben competir con el tráfico
de envío, y quedan retrasados en el proceso.
</Para>

<Para>
Si hacemos todo esto, obtenemos las siguientes mediciones usando una
conexión ADSL excelente de xs4all en Holanda:
</Para>

<Para>

<Screen>
Latencia de base:
round-trip min/avg/max = 14.4/17.1/21.7 ms

Sin condicionador de tráfico, mientras descargamos:
round-trip min/avg/max = 560.9/573.6/586.4 ms

Sin condicionador de tráfico, mientras enviamos:
round-trip min/avg/max = 2041.4/2332.1/2427.6 ms

Con el condicionador, durante un envío a 220kbit/s:
round-trip min/avg/max = 15.7/51.8/79.9 ms

Con el condicionador, durante una descarga a 850kbit/s:
round-trip min/avg/max = 20.4/46.9/74.0 ms

Al enviar, las descargas se producen aproximadamente al 80% de la
velocidad disponible. Los envíos alrededor de al 90%. La latencia salta
entonces a 850ms, y aún intentamos averiguar por qué.
</Screen>

</Para>

<Para>
Lo que pueda esperar de este script depende mucho de la velocidad real del
enlace de salida. Cuando se envía a toda velocidad, siempre habrá un único
paquete por delante de sus pulsaciones. Este es el límite inferior de
latencia que puede alcanzar (divida el MTU por la velocidad de subida para
calcularlo). Los valores normales serán algo más altos que esto. ¡Reduzca
la MTU para obtener mejores efectos!
</Para>

<Para>
Ahora, dos versiones del script, una con el excelente HTB de Devik, y la
otra con el CBQ que viene en cada núcleo de Linux, al contrario que HTB.
Hemos probado ambos, y funcionan bien.
</Para>

</Sect2>

<Sect2>
<Title>El script (CBQ)</Title>

<Para>
Funciona en todos los núcleos. Dentro de la qdisk
CBQ colocamos dos Stochastic Fairness Queues que se aseguran de que varios
flujos masivos no se ahoguen uno a otro.
</Para>

<Para>
El tráfico de descarga se ajusta usando un filtro tc que contenga un Token
Bucket Filter.
</Para>

<Para>
Puede mejorar este script añadiendo «bounded» a la línea que comienza con
«tc class add .. classid 1:20». Si disminuyó la MTU, ¡reduzca también los
números allot y avpkt!
</Para>

<Para>

<Screen>
#!/bin/bash 

# The Ultimate Setup For Your Internet Connection At Home
# 
#
# Set the following values to somewhat less than your actual download
# and uplink speed. In kilobits
DOWNLINK=800
UPLINK=220
DEV=ppp0

# clean existing down- and uplink qdiscs, hide errors
tc qdisc del dev $DEV root    2&#62; /dev/null &#62; /dev/null
tc qdisc del dev $DEV ingress 2&#62; /dev/null &#62; /dev/null

###### uplink

# install root CBQ

tc qdisc add dev $DEV root handle 1: cbq avpkt 1000 bandwidth 10mbit 

# shape everything at $UPLINK speed - this prevents huge queues in your
# DSL modem which destroy latency:
# main class

tc class add dev $DEV parent 1: classid 1:1 cbq rate ${UPLINK}kbit \
allot 1500 prio 5 bounded isolated 

# high prio class 1:10:

tc class add dev $DEV parent 1:1 classid 1:10 cbq rate ${UPLINK}kbit \
   allot 1600 prio 1 avpkt 1000

# bulk and default class 1:20 - gets slightly less traffic, 
#  and a lower priority:

tc class add dev $DEV parent 1:1 classid 1:20 cbq rate $[9*$UPLINK/10]kbit \
   allot 1600 prio 2 avpkt 1000

# both get Stochastic Fairness:
tc qdisc add dev $DEV parent 1:10 handle 10: sfq perturb 10
tc qdisc add dev $DEV parent 1:20 handle 20: sfq perturb 10

# start filters
# TOS Minimum Delay (ssh, NOT scp) in 1:10:
tc filter add dev $DEV parent 1:0 protocol ip prio 10 u32 \
      match ip tos 0x10 0xff  flowid 1:10

# ICMP (ip protocol 1) in the interactive class 1:10 so we 
# can do measurements &#38; impress our friends:
tc filter add dev $DEV parent 1:0 protocol ip prio 11 u32 \
	match ip protocol 1 0xff flowid 1:10

# To speed up downloads while an upload is going on, put ACK packets in
# the interactive class:

tc filter add dev $DEV parent 1: protocol ip prio 12 u32 \
   match ip protocol 6 0xff \
   match u8 0x05 0x0f at 0 \
   match u16 0x0000 0xffc0 at 2 \
   match u8 0x10 0xff at 33 \
   flowid 1:10

# rest is 'non-interactive' ie 'bulk' and ends up in 1:20

tc filter add dev $DEV parent 1: protocol ip prio 13 u32 \
   match ip dst 0.0.0.0/0 flowid 1:20

########## downlink #############
# slow downloads down to somewhat less than the real speed  to prevent 
# queuing at our ISP. Tune to see how high you can set it.
# ISPs tend to have *huge* queues to make sure big downloads are fast
#
# attach ingress policer:

tc qdisc add dev $DEV handle ffff: ingress

# filter *everything* to it (0.0.0.0/0), drop everything that's
# coming in too fast:

tc filter add dev $DEV parent ffff: protocol ip prio 50 u32 match ip src \
   0.0.0.0/0 police rate ${DOWNLINK}kbit burst 10k drop flowid :1
</Screen>

Si desea que ppp ejecute este script al conectar, cópielo en 
/etc/ppp/ip-up.d.
</Para>

<Para>
Si las últimas dos líneas dan error, ¡actualice la herramienta tc a una
versión más moderna!
</Para>

</Sect2>

<Sect2>
<Title>El script (HTB)</Title>

<Para>
El siguiente script alcanza todas nuestras metas usando la maravillosa
cola HTB (vea el capítulo relevante). ¡Vale la pena parchear el núcleo!

<Screen>
#!/bin/bash

# The Ultimate Setup For Your Internet Connection At Home
# 
#
# Set the following values to somewhat less than your actual download
# and uplink speed. In kilobits
DOWNLINK=800
UPLINK=220
DEV=ppp0

# clean existing down- and uplink qdiscs, hide errors
tc qdisc del dev $DEV root    2&#62; /dev/null &#62; /dev/null
tc qdisc del dev $DEV ingress 2&#62; /dev/null &#62; /dev/null

###### uplink

# install root HTB, point default traffic to 1:20:

tc qdisc add dev $DEV root handle 1: htb default 20

# shape everything at $UPLINK speed - this prevents huge queues in your
# DSL modem which destroy latency:

tc class add dev $DEV parent 1: classid 1:1 htb rate ${UPLINK}kbit burst 6k

# high prio class 1:10:

tc class add dev $DEV parent 1:1 classid 1:10 htb rate ${UPLINK}kbit \
   burst 6k prio 1

# bulk &#38; default class 1:20 - gets slightly less traffic, 
# and a lower priority:

tc class add dev $DEV parent 1:1 classid 1:20 htb rate $[9*$UPLINK/10]kbit \
   burst 6k prio 2

# both get Stochastic Fairness:
tc qdisc add dev $DEV parent 1:10 handle 10: sfq perturb 10
tc qdisc add dev $DEV parent 1:20 handle 20: sfq perturb 10

# TOS Minimum Delay (ssh, NOT scp) in 1:10:
tc filter add dev $DEV parent 1:0 protocol ip prio 10 u32 \
      match ip tos 0x10 0xff  flowid 1:10

# ICMP (ip protocol 1) in the interactive class 1:10 so we 
# can do measurements &#38; impress our friends:
tc filter add dev $DEV parent 1:0 protocol ip prio 10 u32 \
	match ip protocol 1 0xff flowid 1:10

# To speed up downloads while an upload is going on, put ACK packets in
# the interactive class:

tc filter add dev $DEV parent 1: protocol ip prio 10 u32 \
   match ip protocol 6 0xff \
   match u8 0x05 0x0f at 0 \
   match u16 0x0000 0xffc0 at 2 \
   match u8 0x10 0xff at 33 \
   flowid 1:10

# rest is 'non-interactive' ie 'bulk' and ends up in 1:20


########## downlink #############
# slow downloads down to somewhat less than the real speed  to prevent 
# queuing at our ISP. Tune to see how high you can set it.
# ISPs tend to have *huge* queues to make sure big downloads are fast
#
# attach ingress policer:

tc qdisc add dev $DEV handle ffff: ingress

# filter *everything* to it (0.0.0.0/0), drop everything that's
# coming in too fast:

tc filter add dev $DEV parent ffff: protocol ip prio 50 u32 match ip src \
   0.0.0.0/0 police rate ${DOWNLINK}kbit burst 10k drop flowid :1
</Screen>

</Para>

<Para>
Si desea que ppp ejecute este script al conectar, cópielo en 
/etc/ppp/ip-up.d.
</Para>

<Para>
Si las últimas dos líneas dan error, ¡actualice la herramienta tc a una
versión más moderna!
</Para>

</Sect2>

    </Sect1>
    <sect1 id="lartc.ratelimit.single"><title>Limitar la tasa a una única máquina o máscara de red</title>
      <para>
	Aunque esto se describe con muchísimo detalle en algún otro lado
	en las páginas de manual, a menudo nos hacen esta pregunta y por
	suerte hay una respuesta sencilla que no necesita de una
	comprensión profunda del control de tráfico.
      </para>
      <para>
	Este script de tres líneas hace el truco:
      </para>
      <para>
	<screen>
	  tc qdisc add dev $DEV root handle 1: cbq avpkt 1000 bandwidth 10mbit 

	  tc class add dev $DEV parent 1: classid 1:1 cbq rate 512kbit \
	  allot 1500 prio 5 bounded isolated 

	  tc filter add dev $DEV parent 1: protocol ip prio 16 u32 \
	  match ip dst 195.96.96.97 flowid 1:1
	</screen>
      </para>
      <para>
        La primera línea instala una clase basada en la cola de la
	interfaz, y le dice al núcleo que debe asumir para los cálculos que
	la interfaz es de 10mbit. Si se equivoca con esto, no pasa nada
	malo. Pero dejarlo correctamente hará todo más preciso.
      </para>
      <para>
	La segunda línea crea una clase de 512kbit con algunos valores por
	defecto razonables. Si desea detalles, lea las páginas de manual
	de cbq y
	<xref linkend="lartc.qdisc">.
      </para>
      <para>
	La última línea indica qué tráfico debería ir a la clase ajustada.
	El tráfico que no sea captado por esta regla NO será ajustado. Si
	quiere captar cosas más complicadas (subredes, puertos de origen o
	destino), lea <xref linkend="lartc.filtering.simple">.
      </para>
      <para>
	Si cambia cualquier cosa y quiere reiniciar el script, ejecuta "tc
	qdisc del dev $DEV root" para borrar la configuración existente.
      </para>
      <para>
	Se puede mejorar el script añadiendo la última línea opcional "tc
	qdisc add dev $DEV parent 1:1 sfq perturb 10". Vea
	<xref linkend="lartc.sfq"> si desea detalles sobre la forma de
	hacerlo.
      </para>
    </sect1>

	<sect1 id="lartc.cookbook.fullnat.intro"><title>Ejemplo de una solución de nat completo con QoS</title>
		<para>
			Soy Pedro Larroy <address><email>piotr@member.fsf.org</email></address>. Voy a describir una configuración común donde tenemos muchos usuarios en una red privada conectada a la Internet mediante un router Linux con una dirección IP pública que está haciendo traducción de direcciones de red (NAT). Uso esta configuración de QoS para dar acceso a la Internet a 198 usuarios en una residencia universitaria, en la que vivo y de la que soy administrador de red. Los usuarios hacen uso indiscriminado de programas "peer to peer", de manera que es esencial un control de tráfico adecuado. Espero que esto sirva de ejemplo práctico para todos los lectores de lartc interesados.
		</para>

		<para>
			Primero expondré un acercamiento práctico con configuración paso a paso, y al final explicaré cómo automatizar el proceso durante el arranque. La red a la que se aplica este ejemplo es una LAN privada conectada a la Internet mediante un router Linux que tiene una dirección IP pública. Extenderlo a varias direcciones IP públicas debería ser sencillo, añadiendo un par de reglas de iptables.
			Para obtener las cosas que necesitamos:
			<VariableList>
				<VarListEntry>
					<Term>Núcleo Linux versión 2.4.18 o superior instalado</Term>
					<ListItem>
					<Para>
					Si usa 2.4.18 tendrá que aplicar el parche para HTB.
					</Para></ListItem>
				</VarListEntry>

				<VarListEntry>
					<Term>iproute</Term>
					<ListItem>
					<Para>
					También hay que asegurarse de que el programa "tc" está preparado para HTB; se distribuye uno precompilado con HTB.
					</Para></ListItem>
				</VarListEntry>

				<VarListEntry>
					<Term>iptables</Term>
					<ListItem>
					<Para>
					</Para></ListItem>
				</VarListEntry>
			</VariableList>
		</para>
	<sect2>
	<Title>Empecemos optimizando ese ancho de banda escaso</Title>
		<para>
			Primero necesitamos configurar algunas qdisc en las que clasificaremos el tráfico. Creamos una qdisc htb con 6 clases con prioridad ascendente. Entonces tenemos clases que siempre obtendrán la tasa establecida, pero podemos usar el ancho de banda que no necesitan las otras clases. Recuerde que se asignará primero el exceso de ancho de banda a las clases con mayor prioridad (con número prio mayor). Nuestra conexión es una ADSL con 2Mb de descarga y 300kbit/s de envío. Uso 240kbit/s como tasa superior sólo porque es lo más alto que puedo configurar antes de que la latencia empiece a crecer, debido a llenados de búfer en algún sitio entre nosotros y la máquina remota. Este parámetro deberí medirse de forma experimental, aumentándolo y haciéndolo bajar si se observa latencia entre máquinas cercanas.
		</para>
		<para>
			Ajuste CEIL al 75% de límite del ancho de banda por ahora, y donde uso eth0, debería poner la interfaz que tiene la dirección pública de Internet. Para empezar nuestro ejemplo, ejecute lo siguiente en una sesión de root:
			<Screen>
			CEIL=240
			tc qdisc add dev eth0 root handle 1: htb default 15
			tc class add dev eth0 parent 1: classid 1:1 htb rate ${CEIL}kbit ceil ${CEIL}kbit
			tc class add dev eth0 parent 1:1 classid 1:10 htb rate 80kbit ceil 80kbit prio 0
			tc class add dev eth0 parent 1:1 classid 1:11 htb rate 80kbit ceil ${CEIL}kbit prio 1
			tc class add dev eth0 parent 1:1 classid 1:12 htb rate 20kbit ceil ${CEIL}kbit prio 2
			tc class add dev eth0 parent 1:1 classid 1:13 htb rate 20kbit ceil ${CEIL}kbit prio 2
			tc class add dev eth0 parent 1:1 classid 1:14 htb rate 10kbit ceil ${CEIL}kbit prio 3
			tc class add dev eth0 parent 1:1 classid 1:15 htb rate 30kbit ceil ${CEIL}kbit prio 3
			tc qdisc add dev eth0 parent 1:12 handle 120: sfq perturb 10
			tc qdisc add dev eth0 parent 1:13 handle 130: sfq perturb 10
			tc qdisc add dev eth0 parent 1:14 handle 140: sfq perturb 10
			tc qdisc add dev eth0 parent 1:15 handle 150: sfq perturb 10
			</Screen>
			Ahora hemos creado un árbol htb con un nivel de profundidad. Algo como esto:

			<Screen>
			+---------+
			| root 1: |
			+---------+
			     |
			+---------------------------------------+
			| class 1:1                             |
			+---------------------------------------+
			  |      |      |      |      |      |
			+----+ +----+ +----+ +----+ +----+ +----+
			|1:10| |1:11| |1:12| |1:13| |1:14| |1:15|
			+----+ +----+ +----+ +----+ +----+ +----+
			</Screen>

			<VariableList>
				<VarListEntry>
					<Term>classid 1:10 htb rate 80kbit ceil 80kbit prio 0</Term>
					<ListItem>
					<Para>
					Esta es la clase de mayor prioridad. Los paquetes de esta clase tendrán el menor retraso y será la primera en cargar con exceso de tráfico, de manera que no es buena idea limitar la tasa superior a esta clase. Enviaremos mediante esta clase los siguientes paquetes que se benefician de una latencia baja, como el tráfico interactivo: <emphasis>ssh, telnet, dns, quake3, irc, y paquetes con la etiqueta SYN</emphasis>
					</Para>
					</ListItem>
				</VarListEntry>

				<VarListEntry>
					<Term>classid 1:11 htb rate 80kbit ceil ${CEIL}kbit prio 1</Term>
					<ListItem>
					<Para>
					Aquí tenemos la primera clase en la que podemos empezar a poner tráfico masivo. En mi ejemplo tenemos tráfico de un servidor web local y peticiones de páginas web: puerto de origen 80, y puerto de destino 80, respectivamente.
					</Para></ListItem>
				</VarListEntry>

				<VarListEntry>
					<Term>classid 1:12 htb rate 20kbit ceil ${CEIL}kbit prio 2</Term>
					<ListItem>
					<Para>
+                                       In this class I will put traffic with Maximize-Throughput TOS bit set and the rest of the traffic that goes from <emphasis>local processes</emphasis> on the router to the Internet. So the following classes will only have traffic that is <quote>routed through</quote> the box.
					En esta clase pondré el tráfico con el bit TOS Maximize-Throughput activo, y el resto del tráfico que viene del <emphasis>procesamiento local</emphasis> del router hacia Internet. De manera que las siguientes clases sólo tendrán tráfico que <quote>es encaminado a través de</quote> la máquina.
					</Para></ListItem>
				</VarListEntry>

				<VarListEntry>
					<Term>classid 1:13 htb rate 20kbit ceil ${CEIL}kbit prio 2</Term>
					<ListItem>
					<Para>
					Esta clase es para el tráfico de otras máquinas NAT-eadas que necesitan mayor prioridad en su tráfico masivo.
					</Para></ListItem>
				</VarListEntry>


				<VarListEntry>
					<Term>classid 1:14 htb rate 10kbit ceil ${CEIL}kbit prio 3</Term>
					<ListItem>
					<Para>
					Aquí va el tráfico de correo (SMTP, pop3...) y los paquetes con el bit TOS Minimize-Cost activo.
					</Para></ListItem>
				</VarListEntry>

				<VarListEntry>
					<Term>classid 1:15 htb rate 30kbit ceil ${CEIL}kbit prio 3</Term>
					<ListItem>
					<Para>
					Y finalmente, aquí tenemos el tráfico masivo de las máquinas NAT-eadas tras el router. Kazaa, edonkey y otros irán aquí, de manera que no interfieran con otros servicios.
				</VarListEntry>

			</VariableList>




		</para>
	</sect2>

	<sect2>
	<Title>Clasifición de paquetes</Title>
		<para>
			Hemos creado la configuración de qdisc pero no hemos hecho clasificación de paquetes, de manera que todos los paquetes salientes están pasando por la clase 1:15 (porque hemos usado c qdisc add dev eth0 root handle 1: htb <emphasis>default 15</emphasis>). Ahora necesitamos decir qué paquetes van dónde. Esta es la parte más importante.
		</para>

		<para>
			Ahora establecemos los filtros de manera que clasificamos los paquetes con iptables. Realmente prefiero hacerlo con iptables, porque son muy flexibles y puedes hacer conteo de paquetes por cada regla. Además, con el objetivo RETURN los paquetes no necesitan pasar por todas las reglas. Ejecutamos las siguientes órdenes:
			<Screen>
			tc filter add dev eth0 parent 1:0 protocol ip prio 1 handle 1 fw classid 1:10
			tc filter add dev eth0 parent 1:0 protocol ip prio 2 handle 2 fw classid 1:11
			tc filter add dev eth0 parent 1:0 protocol ip prio 3 handle 3 fw classid 1:12
			tc filter add dev eth0 parent 1:0 protocol ip prio 4 handle 4 fw classid 1:13
			tc filter add dev eth0 parent 1:0 protocol ip prio 5 handle 5 fw classid 1:14
			tc filter add dev eth0 parent 1:0 protocol ip prio 6 handle 6 fw classid 1:15
			</Screen>
+                       We have just told the kernel that packets that has a specific FWMARK value ( hanlde x fw ) go in the specified class ( classid x:x). Next you will see how to mark packets with iptables.
			Acabamos de decirle al núcleo que los paquetes que tienen un valor específico de FWMARK (handle x fw) van en la clase indicada (classid x:x). Lo siguiente que veremos es cómo marcar paquetes con iptables.
		</para>

		<para>
			Antes hay que entender cómo atraviesan los paquetes los filtros con iptables:
			<Screen>
				+------------+                +---------+               +-------------+
			Packet -| PREROUTING |--- routing-----| FORWARD |-------+-------| POSTROUTING |- Packets
			input   +------------+    decision    +---------+       |       +-------------+    out
			                             |                          |
			                        +-------+                    +--------+
			                        | INPUT |---- Local process -| OUTPUT |
			                        +-------+                    +--------+

			</Screen>
			Asumo que tiene todas las tablas vacías y con norma por defecto ACCEPT ( -P ACCEPT ); si no ha jugado aún con iptables, debería estar todo correcto por defecto. Nuestra red privada es una clase B con dirección 172.17.0.0/16 y la IP pública es 212.170.21.172
		</para>

		<para>
			Ahora le decimos al kernel que <emphasis>haga NAT</emphasis>, de manera que los clientes de la red privada puedan empezar a hablar con el exterior.

			<Screen>
			echo 1 > /proc/sys/net/ipv4/ip_forward
			iptables -t nat -A POSTROUTING -s 172.17.0.0/255.255.0.0 -o eth0 -j SNAT --to-source 212.170.21.172
			</Screen>
			Ahora compruebe que hay paquetes pasando por 1:15:
			<Screen>
			tc -s class show dev eth0
			</Screen>
		</para>

		<para>
			Puede empezar a marcar los paquetes añadiendo reglas a la cadena PREROUTING de la tabla mangle:
			<Screen>
			iptables -t mangle -A PREROUTING -p icmp -j MARK --set-mark 0x1
			iptables -t mangle -A PREROUTING -p icmp -j RETURN
			</Screen>
			Ahora debería ver incrementarse la cuenta de paquetes cuando haga ping de máquinas dentro de la red privada a otras en la Internet. Compruebe el incremento en 1:10
			<Screen>
			tc -s class show dev eth0
			</Screen>
			Hemos hecho -j RETURN de manera que los paquetes no atraviesen todas las reglas. No se comprobarán otras reglas por debajo de RETURN para los paquetes Icmp. Téngalo en cuenta.
			Ahora podemos añadir más reglas. Hagamos un control adecuado de TOS:
			<Screen>
			iptables -t mangle -A PREROUTING -m tos --tos Minimize-Delay -j MARK --set-mark 0x1
			iptables -t mangle -A PREROUTING -m tos --tos Minimize-Delay -j RETURN
			iptables -t mangle -A PREROUTING -m tos --tos Minimize-Cost -j MARK --set-mark 0x5
			iptables -t mangle -A PREROUTING -m tos --tos Minimize-Cost -j RETURN
			iptables -t mangle -A PREROUTING -m tos --tos Maximize-Throughput -j MARK --set-mark 0x6
			iptables -t mangle -A PREROUTING -m tos --tos Maximize-Throughput -j RETURN
			</Screen>

			Ahora prioricemos los paquetes ssh:
			<Screen>
			iptables -t mangle -A PREROUTING -p tcp -m tcp --sport 22 -j MARK --set-mark 0x1
			iptables -t mangle -A PREROUTING -p tcp -m tcp --sport 22 -j RETURN
			</Screen>
			Una buena idea es dar prioridad a los paquetes que empiezan conexiones tcp, aquellos con el indicador SYN activo:
			<Screen>
			iptables -t mangle -I PREROUTING -p tcp -m tcp --tcp-flags SYN,RST,ACK SYN -j MARK --set-mark 0x1
			iptables -t mangle -I PREROUTING -p tcp -m tcp --tcp-flags SYN,RST,ACK SYN -j RETURN
			</Screen>
			Y así con todo.

			Cuando acabemos de añadir reglas a PREROUTING en mangle, terminaremos la cadena de PREROUTING con
			<Screen>
			iptables -t mangle -A PREROUTING -j MARK --set-mark 0x6
			</Screen>
			De manera que el tráfico que no hayamos marcado se vaya a 1:15. De hecho, este último paso es innecesario ya que la clase por defecto era 1:15, pero lo marcaré para ser consistente con el resto de la configuración, y además es útil para ver el contador de esa regla.
		</para>

		<para>
			Sería buena idea hacer lo mismo en la cadena OUTPUT, repitiendo aquellas órdenes con -A OUTPUT en lugar de PREROUTING. (s/PREROUTING/OUTPUT/) Entonces también clasificaremos el tráfico generado de forma local (en el router Linux). Termino la cadena OUTPUT con -j MARK --set-mark 0x3 de manera que el tráfico local tenga mayor prioridad.
		</para>

	</sect2>

	<sect2>
	<Title>Mejora de nuestra configuración</Title>
		<para>
			Ahora tenemos todo funcionando. Tómese su tiempo mirando las gráficas, y viendo dónde se emplea el tráfico y cómo lo quiere. Hacerlo durante muchas horas, acabé teniendo la conexión a Internet funcionando realmente bien. De otra manera, observará continuamente timeouts y casi no se le asignará ancho de banda a las conexiones tcp recién creadas.
		</para>
		<para>
			Si encuentra que algunas clases están más llenas la mayor parte del tiempo, puede ser buena idea adjuntarles otras disciplinas de cola de manera que el reparto de ancho de banda sea más justo:
			<Screen>
			tc qdisc add dev eth0 parent 1:13 handle 130: sfq perturb 10
			tc qdisc add dev eth0 parent 1:14 handle 140: sfq perturb 10
			tc qdisc add dev eth0 parent 1:15 handle 150: sfq perturb 10
			</Screen>
		</para>

	</sect2>
	<sect2>
	<Title>Hacer todo lo anterior durante el arranque</Title>
		<para>
			Seguramente se puede hacer de muchas maneras. Yo tengo un script en /etc/init.d/packetfilter que acepta [start | stop | stop-tables | start-tables | reload-tables], que configura las qdisc y carga los módulos del núcleo necesarios, de manera que se comporta bastante como un demonio. El mismo script carga reglas iptables de /etc/network/iptables-rules. Lo arreglaré un poco y lo pondré en mi página web <ULink URL="http://omega.resa.es/piotr/files/packetfilter.tar.bz2">aquí</ULink>
		</para>

	</sect2>
	</sect1>

</chapter>



<chapter id="lartc.bridging">
  <Title>Hacer bridges y pseudo-bridges con Proxy ARP</Title>

<Para>
Los bridges son dispositivos que se pueden instalar en una red sin tener
que reconfigurar. Un switch de red es básicamente un bridge de muchos
puertos. Un bridge a menudo es un switch de 2 puertos. Linux, sin embargo,
soporta varias interfaces en un bridge, lo que le convierte en un
verdadero switch.
</Para>

<Para>
A menudo se usan bridges cuando nos encontramos con una red mal
configurada que debe ser arreglada sin alteraciones. Como un bridge es un
dispositivo de capa 2, una capa por debajo de IP, los router y los
servidores no se percatan de su existencia. Esto significa que puede
bloquear o modificar ciertos paquetes de una manera transparente, o hacer
ajustes.
</Para>

<Para>
Otra cosa buena es que a menudo se puede reemplazar un bridge con un cable
cruzado o un hub, en caso de que se estropee.
</Para>

<Para>
La mala noticia es que un bridge puede causar una gran confusión a
menos que esté muy bien documentado. No aparece en las trazas de ruta,
pero algunos paquetes pueden desaparecer o cambiar entre los puntos A y B
(«¡esta red está EMBRUJADA!»). También debería preguntarse si una
organización que «no quiere cambiar nada» está haciendo lo correcto.
</Para>

<Para>
El bridge de Linux 2.4/2.5 está documentado en
<ULink URL=" http://bridge.sourceforge.net/">esta página</ULink>.
</Para>

<Sect1 id="lartc.bridging.iptables">
  <Title>Estado del bridging e iptables</Title>

<Para>
Hasta Linux 2.4.20, el bridging e iptables no se "ven" uno a otro sin
ayuda. Si se puentean los paquetes de eth0 a eth1, no "pasan" por
iptables. Esto significa que no podrá filtrarlos, hacer NAT, modificarlos,
o lo que sea. En Linux 2.5.45 y superiores, esto está corregido.
</Para>
<para>
Puede que haya visto mencionar "ebtables", que es otro proyecto más (puede
hacer cosas realmente bestiales con MACNAT y "brouting"). Da mucho miedo.
</Sect1>

<Sect1 id="lartc.bridging.shaping">
  <Title>Bridging y ajustes (shaping)</Title>

<Para>
Funciona tal como sugiere. Asegúrese de averiguar en qué lado está cada
interfaz, o puede acabar haciendo ajustes al tráfico saliente en la
interfaz interna, que no es lo que se quiere. Use tcpdump en caso
necesario.
</Para>

</Sect1>

<Sect1 id="lartc.bridging.proxy-arp">
  <Title>Pseudo-bridges con Proxy-ARP</Title>

<Para>
Si simplemente quiere implementar un Pseudo-bridge, sáltese un par de
secciones hasta "Implementándolo", pero es interesante leer un poco sobre
la manera en que funciona en la práctica.
</Para>

<Para>
Un Pseudo-bridge funciona de manera ligeramente diferente. Por defecto, un
bridge pasa los paquetes inalterados de una interfaz a la otra. Sólo
comprueba las direcciones hardware de los paquetes para determinar a dónde
va qué. Esto a su vez significa que se puede hacer bridge sobre tráfico
que Linux no entienda, siempre y cuándo tenga una dirección hardware que
sí comprenda.
</Para>

<Para>
Un "Pseudo-bridge" funciona ligeramente diferente y es más un router
oculto que un bridge, pero al igual que un bridge, tiene poco impacto en
el diseño de la red.
</Para>

<Para>
Una ventaja de que no sea un bridge recae en el hecho de que los paquetes
pasan realmente por el kernel, y se pueden filtrar, cambiar, redirigir y
reencaminar.
</Para>

<Para>
Un bridge real también puede realizar estas tareas, pero necesita código
especial como el Ethernet Frame Diverter, o el parche mencionado
anteriormente.
</Para>

<Para>
Otra ventaja de un pseudo-bridge es que no pasa paquetes que no entienda
(limpiando la red de esta manera de un montón de porquería). En casos en
que necesite esta porquería (como paquetes SAP o Netbeui), use un bridge
de verdad.
</Para>

<Sect2>
<Title>ARP y Proxy-ARP</Title>

<Para>
Cuando una máquina desea hablar con otra en la mismo segmento físico de
red, envía un paquete del Address Resolution Protocol, que, simplificando,
es algo así como «quien tenga 10.0.0.1, que se lo diga a 10.0.0.7». En
respuesta a esto, 10.0.0.1 responde con un breve paquete «aquí».
</Para>

<Para>
10.0.0.7 envía entonces paquetes a la dirección de hardware mencionada en
el paquete «aquí». Hace caché de esta dirección hardware durante un tiempo
relativamente largo, y tras que expire, vuelve a lanzar la pregunta.
</Para>

<Para>
Cuando creamos un Pseudo-bridge, le indicamos que conteste a estos paquetes
ARP, lo que hace que las máquinas de la red envíen sus paquetes al bridge.
Entonces el bridge procesa los paquetes, y los envía a la interfaz
relevante.
</Para>

<Para>
De manera que, en breve, siempre que una máquina a un lado del bridge
pregunta por la dirección de una máquina en el otro lado, el bridge
responde con un paquete que dice «envíamelo a mí».
</Para>

<Para>
De esta manera, todo el tráfico se transmite al sitio correcto, y siempre
pasa por el bridge.
</Para>

</Sect2>

<Sect2>
<Title>Implementándolo</Title>

<Para>
En tiempos más oscuros, se podía instruir al núcleo de Linux para realizar
"proxy-ARP" para cualquier subred. De manera que, para configurar un
pseudo-bridge, tendría tanto que especificar las rutas correctas hacia
ambos lados del bridge COMO crear reglas proxy-ARP correspondientes. Esto
es malo porque precisa escribir mucho, pero también porque le permite
cometer con facilidad errores que harán que el bridge responda a consultas
ARP para redes a las que no sabe cómo llegar.
</Para>

<Para>
Con Linux 2.4/2.5 (y posiblemente 2.2), se ha retirado esta posibilidad y
se sustituye con una marca en el directorio /proc, denominada "proxy_arp".
Por tanto, el procedimiento para construir un pseudo-bridge, es:
</Para>

<Para>

<OrderedList>
<ListItem>

<Para>
Asignar una dirección IP a ambas interfaces, la "izquierda" y la "derecha".
</Para>
</ListItem>
<ListItem>

<Para>
Crear rutas de manera que la máquina sepa qué máquinas residen a la
izquierda y cuales a la derecha.
</Para>
</ListItem>
<ListItem>

<Para>
Ponga en marcha en ambas int
Turn on proxy-ARP on both interfaces, echo 1 &#62;
/proc/sys/net/ipv4/conf/ethI/proxy_arp, echo 1 &#62;
/proc/sys/net/ipv4/conf/ethD/proxy_arp, siendo L y R los números de las
interfaces de la izquierda y derecha respectivamente.
</Para>
</ListItem>

</OrderedList>

</Para>

<Para>
Además, ¡no debe olvidar activar el indicador de ip_forwarding! Al pasar a
ser un bridge verdadero, podría ver que este indicador está inactivo, ya
que no es necesario al hacer un puenteo.
</Para>

<Para>
Otra cosa que podría observar al dar este paso es que necesita borrar la
caché arp de los computadores de la red (la caché arp puede contener
direcciones antiguas pre-bridge que ya no son correctas).
</Para>

<Para>
En un Cisco, esto se hace usando la orden "clear arp-cache", y en Linux,
utilice "arp -d ip.address". También puede esperar a que la caché expire
de forma automática, pero puede tardar un buen rato.
</Para>
<para>
Puede acelerar esto usando la maravillosa herramienta "arping", que en
muchas distribuciones es parte del paquete "iputils". Usando "arping" se
puede enviar muchos mensajes ARP no solicitados para actualizar las caché
arp remotas.
</para>
<para>
¡Esta es una técnica muy poderosa que también usan los "sombreros negros"
(black hats) para subvertir el rutado!
</para>
<note>
<para>
En Linux 2.4, ¡puede ser que necesite ejecutar
"echo 1 &gt; /proc/sys/net/ipv4/ip_nonlocal_bind" antes de poder enviar
paquetes ARP no solicitados!
</para>
</note>
<Para>
También puede descubrir que la red estaba mal configurada si tiene/tenía
el hábito de especificar rutas sin máscaras de red. Me explico, podría ser
que en el pasado, algunas versiones de route hayan acertado con la máscara
de red correcta, o no, sin que usted se haya dado cuenta. Cuando haga
encaminamiento quirúrgico como el descrito anteriormente, ¡es *vital* que
compruebe las máscaras de red!
</Para>

</Sect2>

</Sect1>

</chapter>

<chapter id="lartc.dynamic-routing">
<Title>Encaminamiento dinámico - OSPF y BGP</Title>

<Para>
Una vez que su red empiece a hacerse realmente grande, o empiece a
considerar "la Internet" como su red, necesitará herramientas que
encaminen los datos de forma dinámica. A menudo los sitios están
conectados unos con otros mediante enlaces múltiples, y aparecen otros de
cuando en cuando.
</Para>

<Para>
La Internet prácticamente ha estandarizado OSPF (RFC 2328) y BGP4 (RFC 1771).
Linux soporta ambos, mediante <application>gated</application> y
<application>zebra</application>
</Para>

<Para>
Aunque en estos momentos no se encuentra en el ámbito de este documento,
nos gustaría señalarla las obras definitivas:
</Para>

<Para>
Introducción:
</Para>

<Para>
Cisco Systems
<ULink
URL="http://www.cisco.com/univercd/cc/td/doc/cisintwk/idg4/nd2003.htm"
>Designing large-scale IP Internetworks</ULink
>
</Para>

<Para>
Para OSPF:
</Para>

<Para>
Moy, John T.
"OSPF.  The anatomy of an Internet routing protocol"
Addison Wesley. Reading, MA. 1998.
</Para>

<Para>
Halabi también ha escrito una buena guía al diseño de encaminamiento con
OSPF, pero parece que la han eliminado del sitio web de Cisco.
</Para>

<Para>
Para BGP:
</Para>

<Para>
Halabi, Bassam
"Internet routing architectures"
Cisco Press (New Riders Publishing). Indianapolis, IN. 1997.
</Para>

<Para>
también
</Para>

<Para>
Cisco Systems
</Para>

<Para>
<ULink
URL="http://www.cisco.com/univercd/cc/td/doc/cisintwk/ics/icsbgp4.htm"
>Using the Border Gateway Protocol for interdomain routing</ULink
>
</Para>

<Para>
Aunque los ejemplos son específics de Cisco, son notablemente similares al
lenguaje de configuración de Zebra :-)
</Para>

<Sect1 id="lartc.dynamic-routing.ospf">
	<sect1info>
		<author>
		<FirstName>Pedro</FirstName><Surname>Larroy Tovar</Surname>
		<affiliation>
		<address>
		<email>piotr%member.fsf.org</email>
		</address>
		</affiliation>
		</author>
	</sect1info><Title>Configurar OSPF con Zebra</Title>

	<para>
		Por favor, <ulink url="mailto:piotr%member.fsf.org">hágame</ulink> saber si esta información no es correcta o si tiene alguna sugerencia.
		<ulink url="http://www.zebra.org">Zebra</ulink> es un gran software de encaminamiento dinámico escrito por Kunihiro Ishiguro, Toshiaki Takada y Yashuhiro Ohara. Con Zebra, configurar OSPF es rápido y simple, pero en la práctica hay un montón de parámetros que ajustar si tiene muchas necesidades específicas. OSPF significa Open Shortest Path First, y algunas de sus características principales son:
		<VariableList>
			<VarListEntry>
				<Term>Jerarquía</Term>
				<ListItem>
				<Para>
				Las redes se agrupan por <emphasis>áreas</emphasis>, que están interconectadas por un <emphasis>área backbone</emphasis> que será señalada como <emphasis>área 0</emphasis>. Todo el tráfico pasa por el área 0, y todos los router en el área 0 tienen información de encaminamiento sobre todas las otras áreas.
				</Para>
				</ListItem>
			</VarListEntry>

			<VarListEntry>
				<Term>Convergencia rápida</Term>
				<ListItem>
				<Para>
				Las rutas se propagan muy rápido, comparado con RIP, por ejemplo.
				</Para></ListItem>
			</VarListEntry>
			
			<VarListEntry>
				<Term>Eficiente con el ancho de banda</Term>
				<ListItem>
				<Para>
				Usa multicasting en lugar de broadcastin, de manera que no inunda otras máquinas con información de encaminamiento que pueda no ser de interés para ellas, reduciendo por tanto la carga de la red. Además, los <emphasis>Router Internos</emphasis> (aquellos que sólo tienen interfaces en un área) no tienen información de encaminamiento sobre otras áreas. Los router con interfaces en más de un área se denominan <emphasis>Area Border Routers</emphasis>, y mantienen información topológica sobre las áreas a las que están conectados.
				</Para></ListItem>
			</VarListEntry>

			<VarListEntry>
				<Term>Intensivo en Cpu</Term>
				<ListItem>
				<Para>
				OSPF se basa en el <ulink url="http://www.soi.wide.ad.jp/class/99007/slides/13/07.html">algoritmo Shortest Path First</ulink> (Primero la ruta más corta) de Dijkstra, que es costoso comparado con otros algoritmos de encaminamiento. Pero en realidad esto no es malo, ya que el camino más corto se calcula sólo una vez por cada área, y además, para redes pequeñas y medianas esto no es un problema, y ni siquiera lo notará.
				</Para></ListItem>
			</VarListEntry>
			
			<VarListEntry>
				<Term>Estado del enlace</Term>
				<ListItem>
				<Para>
				OSPF cuenta con las características especiales de las redes e interfaces, tales como ancho de banda, fallo de enlace, y coste monetario.
				</Para></ListItem>
			</VarListEntry>
			
			<VarListEntry>
				<Term>Protocolo abierto y software GPL</Term>
				<ListItem>
				<Para>
				OSPF es un protocolo abierto, y Zebra es software GPL, lo que tiene ventajas obvias sobre software y protocolos en propiedad.
				</Para></ListItem>
			</VarListEntry>

		</VariableList>
  </para>
  
	<Sect2 id="lartc.dynamic-routing.ospf.prereq">
	<Title>Prerequisitos</Title>
		<para>

			<VariableList>
				
				<VarListEntry>
					<Term>Núcleo Linux:</Term>
					<ListItem>
					<Para>
					Compilado con CONFIG_NETLINK_DEV y CONFIG_IP_MULTICAST (no estoy seguro de si se necesita algo más).
					</Para></ListItem>
				</VarListEntry>
				
				<VarListEntry>
					<Term>Iproute</Term>
					<ListItem>
					<Para>
					</Para></ListItem>
				</VarListEntry>
				
				<VarListEntry>
					<Term>Zebra</Term>
					<ListItem>
					<Para>
					Obténgalo con su gestor de paquetes favorito o desde <ulink url="http://www.zebra.org">http://www.zebra.org</ulink>.
					</Para></ListItem>
				</VarListEntry>
			</VariableList>
		</para>
	</sect2>  
	<Sect2 id="lartc.dynamic-routing.ospf.zebracfg">
	<Title>Configuración de Zebra</Title>
		<para>
			Tomemos esta red como ejemplo
			<screen>
			----------------------------------------------------
			| 192.168.0.0/24                                   |
			|                                                  |
			|      Area 0    100BaseTX Switched                |
			|     Backbone     Ethernet                        |
			----------------------------------------------------
			  |           |                |              |
			  |           |                |              |
			  |eth1       |eth1            |eth0          |
			  |100BaseTX  |100BaseTX       |100BaseTX     |100BaseTX
			  |.1         |.2              |.253          |
			 ---------   ------------   -----------      ----------------
			 |R Omega|   |R Atlantis|   |R Legolas|      |R Frodo       |
			 ---------   ------------   -----------      ----------------
			  |eth0         |eth0             |             |          |
			  |             |                 |             |          |
			  |2MbDSL/ATM   |100BaseTX        |10BaseT      |10BaseT   |10BaseT
			------------   ------------------------------------       -------------------------------
			| Internet |   | 172.17.0.0/16        Area 1      |       |  192.168.1.0/24 wlan  Area 2|
			------------   |  Red de estudiantes (residencia) |       |       barcelonawireless     |
			               ------------------------------------       -------------------------------
			</screen>
			No se asuste de este diagrama, ya que zebra hace la mayor parte del trabajo de forma automática, de manera que no le costará nada poner todas las rutas en marcha. Sería doloroso mantener todas estas rutas a mano diariamente. La cosa más importante que debe tener claro, es la topología de la red. Y tenga especial cuidado con el Area 0, ya que es la más importante.
			Primero configure zebra, editando zebra.conf y adaptándolo a sus necesidades:
			<screen>
			hostname omega
			password xxx 
			enable password xxx
			!
			! Interface's description.
			!
			!interface lo
			! description test of desc.
			!
			interface eth1
			multicast
			!
			! Static default route
			!
			ip route 0.0.0.0/0 212.170.21.129
			!
			log file /var/log/zebra/zebra.log
			</screen>
			En Debian, también editaremos /etc/zebra/daemons para que se lancen durante el arranque:
			<screen>
			zebra=yes
			ospfd=yes
			</screen>
			Ahora tenemos que editar ospfd.conf si todavía estamos trabajando con IPv4 u ospf6d.conf si trabajamos con IPv6. Mi ospfd.conf se parece a esto:
			<screen>
			hostname omega
			password xxx
			enable password xxx
			!
			router ospf
			  network 192.168.0.0/24 area 0
			  network 172.17.0.0/16 area 1
			!
			! log stdout
			log file /var/log/zebra/ospfd.log
			</screen>
			Aquí le informamos a ospf sobre la topología de nuestra red.
		</para>
	</sect2>
	
	<Sect2 id="lartc.dynamic-routing.ospf.running">
	<Title>Ejecutar Zebra</Title>
		<para>
			Now, we have to start Zebra; either by hand by typing "zebra -d" or with some script like "/etc/init.d/zebra start". Then carefully watching the ospdfd logs we should see something like:
			Ahora, tenemos que arrancar Zebra; bien a mano, escribiendo "zebra -d" o con algún script como "/etc/init.d/zebra start". Entonces, leyendo cuidadosamente los registros de ospfd, deberíamos ver algo como:
			<screen>
			2002/12/13 22:46:24 OSPF: interface 192.168.0.1 join AllSPFRouters Multicast group.
			2002/12/13 22:46:34 OSPF: SMUX_CLOSE with reason: 5   
			2002/12/13 22:46:44 OSPF: SMUX_CLOSE with reason: 5
			2002/12/13 22:46:54 OSPF: SMUX_CLOSE with reason: 5   
			2002/12/13 22:47:04 OSPF: SMUX_CLOSE with reason: 5   
			2002/12/13 22:47:04 OSPF: DR-Election[1st]: Backup 192.168.0.1
			2002/12/13 22:47:04 OSPF: DR-Election[1st]: DR     192.168.0.1
			2002/12/13 22:47:04 OSPF: DR-Election[2nd]: Backup 0.0.0.0
			2002/12/13 22:47:04 OSPF: DR-Election[2nd]: DR     192.168.0.1
			2002/12/13 22:47:04 OSPF: interface 192.168.0.1 join AllDRouters Multicast group.
			2002/12/13 22:47:06 OSPF: DR-Election[1st]: Backup 192.168.0.2
			2002/12/13 22:47:06 OSPF: DR-Election[1st]: DR     192.168.0.1
			2002/12/13 22:47:06 OSPF: Packet[DD]: Negotiation done (Slave).
			2002/12/13 22:47:06 OSPF: nsm_change_status(): scheduling new router-LSA origination
			2002/12/13 22:47:11 OSPF: ospf_intra_add_router: Start
			</screen>
			Ignore por ahora el mensaje SMUX_CLOSE, ya que es sobre SNMP. Podemos ver que 192.168.0.1 es el <emphasis>Designated Router</emphasis> (enrutador designado) y 192.168.0.2 es el <emphasis>Backup Designated Router</emphasis> (enrutador de reserva designado)
		</para>

		<para>
			También podemos interactuar con zebra o la ospfd ejecutando:
			<screen>
			<prompt>$ </prompt>telnet localhost zebra
			<prompt>$ </prompt>telnet localhost ospfd
			</screen>

			Veamos ahora cómo comprobar si se están propagando las rutas. Abra una sesión en zebra y escriba:
			
			<screen>
			root@atlantis:~# telnet localhost zebra
			Trying 127.0.0.1...
			Connected to atlantis.
			Escape character is '^]'.

			Hello, this is zebra (version 0.92a).
			Copyright 1996-2001 Kunihiro Ishiguro.

			User Access Verification

			Password: 
			atlantis&gt; show ip route
			Codes: K - kernel route, C - connected, S - static, R - RIP, O - OSPF,
			       B - BGP, &gt; - selected route, * - FIB route

			K&gt;* 0.0.0.0/0 via 192.168.0.1, eth1
			C&gt;* 127.0.0.0/8 is directly connected, lo
			O   172.17.0.0/16 [110/10] is directly connected, eth0, 06:21:53
			C&gt;* 172.17.0.0/16 is directly connected, eth0
			O   192.168.0.0/24 [110/10] is directly connected, eth1, 06:21:53
			C&gt;* 192.168.0.0/24 is directly connected, eth1
			atlantis&gt; show ip ospf border-routers
			============ OSPF router routing table =============
			R    192.168.0.253         [10] area: (0.0.0.0), ABR
						   via 192.168.0.253, eth1
							 [10] area: (0.0.0.1), ABR
						   via 172.17.0.2, eth0
			</screen>
			O directamente con iproute:
			<screen>
			root@omega:~# ip route
			212.170.21.128/26 dev eth0  proto kernel  scope link  src 212.170.21.172 
			192.168.0.0/24 dev eth1  proto kernel  scope link  src 192.168.0.1 
			172.17.0.0/16 via 192.168.0.2 dev eth1  proto zebra  metric 20 
			default via 212.170.21.129 dev eth0  proto zebra 
			root@omega:~# 
			</screen>
			Podemos ver las rutas de zebra, que no estaban ahí antes. Es maravilloso ver aparecer rutas sólo unos pocos segundos tras arrancar zebra y ospfd. Puede comprobar la conectividad con otras máquinas y hacer ping. Las rutas de zebra son automáticas; simplemente añada un nuevo router a la red, configure zebra, y ¡voilá!
		</para>
		
		<para>
			Consejo: Puede usar:
			<screen>
			tcpdump -i eth1 ip[9] == 89
			</screen>
			Para capturar paquetes OSPF para su análisis. El número de protocolo IP de OSPF es el 80, y el campo del protocolo es el noveno en la cabecera IP.
		</para>
		
		<para>
			OSPF tiene un montón de parámetros ajustables, especialmente para redes grandes. En posteriores ampliaciones del documento, mostraremos algunas metodologías para afinar OSPF.
		</para>
	</sect2>
</Sect1>  

<Sect1 id="lartc.dynamic-routing.bgp">
<Title>Configurar BGP4 con Zebra</Title>

<para>
El Border Gateway Protocol Version 4 (BGP4) es un protocolo de
encaminamiento dinámico descrito en RFC 1771. Permite la distribución de
información de alcance (reachability), osea, tablas de rutas, a otros
nodos que sepan BGP4. Puede usarse como EGP o IGP, debiando tener cada
nodo su propio número de Sistema Autónomo (AS) en modo EGP. BGP4 soporta
Classless Inter Domain Routing (CIDR) y agregación de rutas (fundir varias
rutas en una).
</para>

<Sect2 id="lartc.dynamic-routing.bgp.netmap">
<Title>Mapa de red (Ejemplo)</Title>

<para>
El siguiente mapa de red se usa en el resto de ejemplos. AS 1 y 50 tienen
más vecinos, pero sólo necesitamos configurar 1 y 50 como nuestros
vecinos. Los nodos se comunican mediante túneles en este ejemplo, pero no
es obligatorio.
</para>

<para>
Nota: Los números AS que usamos en este ejemplo están reservados, por
favor, obtenga su propio AS de RIPE si va a configurar enlaces oficiales.
</para>

<screen>

                  --------------------
                  | 192.168.23.12/24 |
                  |    AS: 23        |
                  --------------------
                    /             \
                   /               \
                  /                 \
        ------------------       ------------------
        | 192.168.1.1/24 |-------| 10.10.1.1/16   |
        |    AS: 1       |       |    AS: 50      |
        ------------------       ------------------
</screen>

</Sect2>

<Sect2 id="lartc.dynamic-routing.bgp.config">
<Title>Configuración (Ejemplo)</Title>

<para>
La siguiente configuración está escrita para el nodo 192.168.23.12/24,
y es fácil de adaptar para los otros nodos.
</para>

<para>
Empieza con cosas generales como el nombre de la máquina, claves y
opciones de depuración:
</para>

<screen>
! nombre de la máquina
hostname anakin

! password de login
password xxx

! activar password (modo super usuario)
enable password xxx

! fichero para registro
log file /var/log/zebra/bgpd.log

! depuración: sé prolijo (se puede eliminar después)
debug bgp events
debug bgp filters
debug bgp fsm
debug bgp keepalives
debug bgp updates
</screen>

<para>
Lista de acceso, usada para limitar la redistribución a redes privadas
(RFC 1918).
</para>

<screen>
! RFC 1918 networks
access-list local_nets permit 192.168.0.0/16
access-list local_nets permit 172.16.0.0/12
access-list local_nets permit 10.0.0.0/8
access-list local_nets deny any
</screen>

<para>
El siguiente paso es hacer la configuración por cada AS:
</para>

<screen>
! Nuestro número de AS
router bgp 23

    ! Dirección IP del router
    bgp router-id 192.168.23.12

    ! anunciar nuestra red a los vecinos
    network 192.168.23.0/24

    ! anunciar todas las rutas conectadas (= interfaces directas)
    redistribute connected

    ! anunciar rutas kernel (= rutas insertadas manualmente)
    redistribute kernel
</screen>

<para>
Cada bloque 'router bgp' contiene una lista de vecinos a los que el router
está conectado:
</para>

<screen>
    neighbor 192.168.1.1 remote-as 1
    neighbor 192.168.1.1 distribute-list local_nets in
    neighbor 10.10.1.1   remote-as 50
    neighbor 10.10.1.1   distribute-list local_nets in
</screen>

</Sect2>

<Sect2>
<Title>Comprobar la configuración</Title>

<para>
Nota: vtysh es un multiplexor y conecta todas las interfaces Zebra juntas.
</para>

<screen>
anakin# sh ip bgp summary 
BGP router identifier 192.168.23.12, local AS number 23
2 BGP AS-PATH entries
0 BGP community entries

Neighbor        V    AS MsgRcvd MsgSent   TblVer  InQ OutQ Up/Down  State/PfxRcd
10.10.0.1       4    50      35      40        0    0    0 00:28:40        1
192.168.1.1     4     1   27574   27644        0    0    0 03:26:04       14

Total number of neighbors 2
anakin#
anakin# sh ip bgp neighbors 10.10.0.1
BGP neighbor is 10.10.0.1, remote AS 50, local AS 23, external link
  BGP version 4, remote router ID 10.10.0.1
  BGP state = Established, up for 00:29:01
  ....
anakin#
</screen>

<para>
Veamos qué rutas obtuvimos de nuestros vecinos:
</para>

<screen>
anakin# sh ip ro bgp 
Codes: K - kernel route, C - connected, S - static, R - RIP, O - OSPF,
       B - BGP, > - selected route, * - FIB route

B>* 172.16.0.0/14 [20/0] via 192.168.1.1, tun0, 2d10h19m
B>* 172.30.0.0/16 [20/0] via 192.168.1.1, tun0, 10:09:24
B>* 192.168.5.10/32 [20/0] via 192.168.1.1, tun0, 2d10h27m
B>* 192.168.5.26/32 [20/0] via 192.168.1.1, tun0, 10:09:24
B>* 192.168.5.36/32 [20/0] via 192.168.1.1, tun0, 2d10h19m
B>* 192.168.17.0/24 [20/0] via 192.168.1.1, tun0, 3d05h07m
B>* 192.168.17.1/32 [20/0] via 192.168.1.1, tun0, 3d05h07m
B>* 192.168.32.0/24 [20/0] via 192.168.1.1, tun0, 2d10h27m
anakin#
</screen>

</Sect2>

</Sect1>

</chapter>

<chapter id="lartc.other"
  xreflabel="Other possibilities">
  <Title>Otras posibilidades</Title>

<Para>
Este capítulo es una lista de proyectos que tienen que ver con el
encaminamiento y el control de tráfico avanzados en Linux. Algunos de
estos enlaces merecerían capítulos completos por sí solos, mientras que
otros están muy bien documentados por sí mismos, y no necesitan más Cómos.
</Para>

<Para>
<VariableList>

<VarListEntry>
<Term>Implementación para Linux de 802.1Q VLAN <ULink
URL="http://scry.wanfear.com/~greear/vlan.html"
>(sitio)</ULink
></Term>
<ListItem>
<Para>
Las VLAN son una manera muy guay de separar sus
redes de una manera más virtual que física. Puede encontrar buena
información sobre las VLAN <ULink
URL="ftp://ftp.netlab.ohio-state.edu/pub/jain/courses/cis788-97/virtual_lans/index.htm"
>aquí</ULink
>. Con esta implementación, puede hacer que su máquina Linux hable
VLAN con máquinas como Cisco Catalyst, 3Com: &lcub;Corebuilder, Netbuilder
II, SuperStack II switch 630&rcub;, Extreme Ntwks Summit 48, Foundry:
&lcub;ServerIronXL, FastIron&rcub;.
</Para>

<Para>
<ULink
URL="http://scry.wanfear.com/~greear/vlan/cisco_howto.html"
>Aquí</ULink
> puede encontrar un gran Cómo sobre VLAN.
</Para>

<Para>
Actualización: incluido en el núcleo desde 2.4.14 (quizá 13).
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>Implementación alternativa para Linux de 802.1Q VLAN <ULink
URL="http://vlan.sourceforge.net "
>(sitio)</ULink
></Term>
<ListItem>
<Para>
Implementación alternativa de VLAN para Linux. Este proyecto empezó por un
desacuerdo con la arquitectura y el estilo de programación del proyecto
"establecido" de VLAN, lo que ha resultado en un diseño general más limpio.
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>Linux Virtual Server <ULink
URL="http://www.LinuxVirtualServer.org/"
>(sitio)</ULink
></Term>
<ListItem>
<Para>
Esta gente es brillante. El Linux Virtual Server es un servidor de alta
escalabilidad y disponibilidad construido sobre un clúster de servidores
reales, con el equilibrador de carga ejecutándose en el sistema operativo
Linux. La arquitectura del clúster es transparente al usuario final. Este
sólo verá un único servidor virtual.
</Para>

<Para>
En breve, siempre que necesite equilibrio de carga, a cualquier nivel de
tráfico, LVS es el camino a seguir. ¡Algunas de sus técnicas son
verdaderamente malvadas! Por ejemplo, permiten que varias máquinas tengan
la misma dirección IP en el mismo segmento, pero desactivándoles ARP. Sólo
la máquina LVS hace ARP, y decide cual de las máquinas posteriores deberá
gestionar un paquete entrante, enviándoselo directamente a la dirección
MAC correcta. El tráfico saliente se envía directamente al router, y no a
través de la máquina LVS, que por tanto no necesita ver sus 5Gbit de
contenido saliendo hacia el mundo, y por tanto no será un cuello de
botella.
</Para>

<Para>
El LVS se implementa como un parche para el núcleo en Linux 2.0 y 2.2,
y como módulo para Netfilter en 2.4/2.5, ¡de manera que no necesitará
parches! El soporte para 2.4 aún se encuentra en principio de desarrollo,
de manera que pruébelo y proporcione realimentación o parches.
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>CBQ.init <ULink
URL="ftp://ftp.equinox.gu.net/pub/linux/cbq/"
>(sitio)</ULink
></Term>
<ListItem>
<Para>
Configurar CBQ puede ser un poco intimidante, especialmente si todo lo que
desea es ajustar el tráfico de algunos computadores hacia un router.
CBQ.init puede ayudarle a configurar Linux con una sintaxis simplificada.
</Para>

<Para>
Por ejemplo, si desea que todos los computadores de su subred
192.168.1.0/24 (en una eth1 10mbit) tengan limitada la velocidad de
descarga a 28kbit/s, ponga esto en el fichero de configuración de
CBQ.init:
</Para>

<Para>

<Screen>
DEVICE=eth1,10Mbit,1Mbit
RATE=28Kbit
WEIGHT=2Kbit
PRIO=5
RULE=192.168.1.0/24
</Screen>

</Para>

<Para>
Use este programa siempre que no le interese el "cómo y por qué". Estamos
usando CBQ.init en producción y funciona muy bien. La documentación está
inscrita en el script, lo cual explica por qué no encontrará un README.
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>Scripts sencillos de regulado de Chronox <ULink
URL="http://www.chronox.de"
>(sitio)</ULink
></Term>
<ListItem>
<Para>
Stephan Mueller (smueller@chronox.de) escribió dos scripts útils,
"limit.conn" y "shaper". El primero permite acelerar fácilmente una única
sesión de descarga, así:
</Para>

<Para>

<Screen>
# limit.conn -s SERVERIP -p SERVERPORT -l LIMIT
</Screen>

</Para>

<Para>
Funciona con Linux 2.2 y 2.4/2.5.
</Para>

<Para>
El segundo script es más complicado, y se puede usar para hacer muchas
colas diferentes basadas en reglas iptables, que se usan para marcar
paquetes que van a ser regulados.
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>Implementación de Virtual Router
Redundancy Protocol <ULink
URL="http://w3.arobas.net/~jetienne/vrrpd/index.html"
>(sitio)</ULink
></Term>
<ListItem>
<Para>
Esto es puramente para redundancia. Dos máquinas con sus propias
direcciones IP y MAC juntas, crean una tercera dirección IP y MAC, que es
virtual. Pensado originalmente sólo para routers, necesitados de una
dirección MAC constante, también funciona para otros servidores.
</Para>

<Para>
La belleza de esta solución es lo increiblemente sencillo de su
configuración. No hay que compilar o parchear el núcleo, todo en espacio
de usuario.
</Para>

<Para>
Simplemente ejecute esto en todas las máquinas que participen en el
servicio:

<Screen>
# vrrpd -i eth0 -v 50 10.0.0.22
</Screen>

</Para>

<Para>
¡Y ya está en marcha! Ahora 10.0.0.22 la lleva uno de los servidores,
probablemente el primero en ejecutar el demonio vrrp. Ahora desconecte ese
computador de la red y rápidamente uno de los otros asumirá la dirección
10.0.0.22, así como la dirección MAC.
</Para>

<Para>
Intenté esto aquí y lo tuve en marcha y funcionando en 1 minuto. Por
alguna razón extraña decidió eliminar mi pasarela por defecto, pero el
indicador -n lo evita.
</Para>

<Para>
Esto es un fallo "en vivo":
</Para>

<Para>

<Screen>
64 bytes from 10.0.0.22: icmp_seq=3 ttl=255 time=0.2 ms
64 bytes from 10.0.0.22: icmp_seq=4 ttl=255 time=0.2 ms
64 bytes from 10.0.0.22: icmp_seq=5 ttl=255 time=16.8 ms
64 bytes from 10.0.0.22: icmp_seq=6 ttl=255 time=1.8 ms
64 bytes from 10.0.0.22: icmp_seq=7 ttl=255 time=1.7 ms
</Screen>

</Para>

<Para>
¡No se perdió ni *un* paquete de ping! Justo tras el cuarto paquete,
desconecté el P200 de mi red, y el 486 tomó su lugar, lo que se puede ver
por la latencia mayor.
</Para></ListItem>
</VarListEntry>
</VariableList>
</Para>

</chapter>

<chapter id="lartc.further">
  <Title>Otras lecturas</Title>

<Para>
<VariableList>

<VarListEntry>
<Term><ULink
URL="http://snafu.freedom.org/linux2.2/iproute-notes.html"
>http://snafu.freedom.org/linux2.2/iproute-notes.html</ULink
></Term>
<ListItem>
<Para>
Contiene mucha información técnica, comentarios del núcleo
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term><ULink
URL="http://www.davin.ottawa.on.ca/ols/"
>http://www.davin.ottawa.on.ca/ols/</ULink
></Term>
<ListItem>
<Para>
Transparencias de Jamal Hadi Salim, uno de los autores del control de
tráfico de Linux
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term><ULink
URL="http://defiant.coinet.com/iproute2/ip-cref/"
>http://defiant.coinet.com/iproute2/ip-cref/</ULink
></Term>
<ListItem>
<Para>
Versión HTML de la documentación en LaTeX de Alexey (explica parte de
iproute2 con gran detalle)
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term><ULink
URL="http://www.aciri.org/floyd/cbq.html"
>http://www.aciri.org/floyd/cbq.html</ULink
></Term>
<ListItem>
<Para>
Very technical stuff, but good reading for those so inclined. 
Sally Floyd tiene una buena página sobre CBQ, incluidos sus documentos
originales. Ninguno es específico a Linux, pero hace un buen trabajo
argumentando la teoría y usos de CBQ.
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>Servicios Diferenciados en Linux</Term>
<ListItem>
<Para>
Este <ULink
URL="ftp://icaftp.epfl.ch/pub/linux/diffserv/misc/dsid-01.txt.gz"
>documento</ULink
> de Werner Almesberger, Jamal Hadi Salim y Alexey
Kuznetsov describe los servicios DiffServ del núcleo de Linux, entre los
que están TBF, GRED, la qdisc DSMARK y el clasificador tcindex.
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term><ULink
URL="http://ceti.pl/~kravietz/cbq/NET4_tc.html"
>http://ceti.pl/~kravietz/cbq/NET4_tc.html</ULink
></Term>
<ListItem>
<Para>
Otro COMO, ¡esta vez en polaco! Puede copiar y pegar líneas de órdenes,
sin embargo, ya que funcionan igual en cualquier idioma. El autor está
cooperando con nosotros y puede que pronto añada secciones a este
documento.
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term><ULink
URL="http://www.cisco.com/univercd/cc/td/doc/product/software/ios111/cc111/car.htm"
>IOS Committed Access Rate</ULink
></Term>
<ListItem>
<Para>
<Anchor id="CAR">
De los buenos chicos de Cisco que tienen la elogiable costumbre de poner
su documentación en línea. La sintaxis de Cisco es diferente pero los
conceptos son los mismos, excepto que nosotros podemos hacer más sin
routers al precio de coches :-)
</Para></ListItem>
</VarListEntry>
<VarListEntry>
<Term>Sitio experimental de Docum <ULink
URL="http://www.docum.org"
>(sitio)</ULink
></Term>
<ListItem>
<Para>
Stef Coene está ocupado convenciendo a su jefe de vender soporte de Linux,
y por tanto experimenta un montón, especialmente con la gestión del ancho
de banda. Su sitio tiene un montón de información práctica, ejemplos,
pruebas y también señala algunos de los fallos de CBQ/tc.
</Para>
</ListItem>
</VarListEntry>
<VarListEntry>
<Term>TCP/IP Illustrated, volume 1, W. Richard Stevens, ISBN 0-201-63346-9</Term>
<ListItem>
<Para>
Lectura necesaria si realmente quiere entender TCP/IP. Entretenido además.
</Para>
</ListItem>
</VarListEntry>
</VariableList> 
</Para>

</chapter>

<chapter id="lartc.ack">
<Title>Reconocimientos </Title>

<Para>
 
Es nuestro objetivo listar a todo el mundo que ha contribuido a este
documento, o ayudado a desmitificar cómo funcionan las cosas. Aunque no
hay planes aún de poner un tablero de puntuaciones como Netfilter, nos
gustaría dar reconocimiento a la gente que nos ayuda.
</Para>

<Para>

<ItemizedList spacing="compact">
<ListItem>

   <Para>
   <author><firstname>Junk</firstname><surname>Alins</surname></author>
   <address><email>juanjo@mat.upc.es</email></address>
   </Para>
  </ListItem>
  <ListItem>
   <Para>
   <author><firstname>Joe</firstname><surname>Van Andel</surname></author>
   </Para>
  </ListItem>

  <ListItem>
   <Para>
   <author><firstname>Michael</firstname><othername>T.</othername>
     <surname>Babcock</surname></author>
   <address><email>mbabcock@fibrespeed.net</email></address>
   </Para>
  </ListItem>


  <ListItem>
   <Para>
   <author><firstname>Christopher</firstname>
     <surname>Barton</surname></author>
   <address><email>cpbarton%uiuc.edu</email></address>
   </Para>
  </ListItem>


  <ListItem>
   <Para>
   <author><firstname>Ard</firstname><surname>van Breemen</surname></author>
   <address><email>ard%kwaak.net</email></address>
  </Para>
  </ListItem>
  <ListItem>
   <Para>
   <author><firstname>Ron</firstname><surname>Brinker</surname></author>
   <address><email>service%emcis.com</email></address>
   </Para>
  </ListItem>
  <ListItem>
   <Para>
   <author><firstname>?ukasz</firstname><surname>Bromirski</surname></author>
   <address><email>l.bromirski@mr0vka.eu.org</email></address>
   </Para>
  </ListItem>
  <ListItem>
   <Para>
   <author><firstname>Lennert</firstname><surname>Buytenhek</surname></author>
   <address><email>buytenh@gnu.org</email></address>
   </Para>
  </ListItem>
  <ListItem>
   <Para>
   <author><firstname>Esteve</firstname><surname>Camps</surname></author>
   <address><email>esteve@hades.udg.es</email></address>
   </Para>
  </ListItem>

  <ListItem>
   <Para>
   <author><firstname>Ricardo Javier</firstname><surname>Cardenes</surname></author>
   <address><email>ricardo%conysis.com</email></address>
   </Para>
  </ListItem>

  <ListItem>
   <Para>
   <author><firstname>Stef</firstname><surname>Coene</surname></author>
   <address><email>stef.coene@docum.org</email></address>
   </Para>
  </ListItem>
  <ListItem>
   <Para>
   <author><firstname>Don</firstname><surname>Cohen</surname></author>
   <address><email>don-lartc%isis.cs3-inc.com</email></address>
   </Para>
  </ListItem>
  <ListItem>
   <Para>
   <author><firstname>Jonathan</firstname><surname>Corbet</surname></author>
   <address><email>lwn%lwn.net</email></address>
   </Para>
  </ListItem>
  <ListItem>
   <Para>
   <author><firstname>Gerry</firstname><surname>Creager</surname>
     <othername>N5JXS</othername></author>
   <address><email>gerry%cs.tamu.edu</email></address>
   </Para>
  </ListItem>
  <ListItem>
   <Para>
   <author><firstname>Marco</firstname><surname>Davids</surname></author>
   <address><email>marco@sara.nl</email></address>
   </Para>
  </ListItem>
  <ListItem>
   <Para>
   <author><firstname>Jonathan</firstname><surname>Day</surname></author>
   <address><email>jd9812@my-deja.com</email></address>
   </Para>
  </ListItem>
  <ListItem>
   <Para>
   <author><firstname>Martin</firstname><surname>Devera</surname>
     <othername>aka devik</othername></author>
   <address><email>devik@cdi.cz</email></address>
  </Para>
  </ListItem>

  <ListItem>
   <Para>
   <author><firstname>Hannes</firstname><surname>Ebner</surname>
     </author>
   <address><email>he%fli4l.de</email></address>
  </Para>
  </ListItem>

  <ListItem>
   <Para>
   <author><firstname>Derek</firstname><surname>Fawcus</surname>
     </author>
   <address><email>dfawcus%cisco.com</email></address>
  </Para>
  </ListItem>

  <ListItem>
   <Para>
   <author><firstname>David</firstname><surname>Fries</surname>
     </author>
   <address><email>dfries%mail.win.org</email></address>
  </Para>
  </ListItem>

  <ListItem>
   <Para>
   <author><firstname>Stephan</firstname><othername>"Kobold"</othername>
     <surname>Gehring</surname></author>
   <address><email>Stephan.Gehring@bechtle.de</email></address>
  </Para>
  </ListItem>
  <ListItem>
   <Para>
   <author><firstname>Jacek</firstname><surname>Glinkowski</surname></author>
   <address><email>jglinkow%hns.com</email></address>
  </Para>
  </ListItem>

  <ListItem>
   <Para>
   <author><firstname>Andrea</firstname><surname>Glorioso</surname></author>
   <address><email>sama%perchetopi.org</email></address>
  </Para>
  </ListItem>

  <ListItem>
   <Para>
   <author><firstname>Thomas</firstname><surname>Graaf</surname></author>
   <address><email>tgraf%suug.ch</email></address>
  </Para>
  </ListItem>


  <ListItem>
   <Para>
   <author><firstname>Sandy</firstname><surname>Harris</surname></author>
   <address><email>sandy%storm.ca</email></address>
  </Para>
  </ListItem>
  <ListItem>
   <Para>
   <author><firstname>Nadeem</firstname><surname>Hasan</surname></author>
   <address><email>nhasan@usa.net</email></address>
   </Para>
  </ListItem>
  <ListItem>
   <Para>
   <author><firstname>Erik</firstname><surname>Hensema</surname></author>
   <address><email>erik%hensema.xs4all.nl</email></address>
   </Para>
  </ListItem>
  <ListItem>
   <Para>
   <author><firstname>Vik</firstname><surname>Heyndrickx</surname></author>
   <address><email>vik.heyndrickx@edchq.com</email></address>
   </Para>
  </ListItem>
  <ListItem>
   <Para>
   <author><firstname>Spauldo</firstname><surname>Da Hippie</surname></author>
   <address><email>spauldo%usa.net</email></address>
   </Para>
  </ListItem>
  <ListItem>
   <Para>
   <author><firstname>Koos</firstname><surname>van den Hout</surname></author>
   <address><email>koos@kzdoos.xs4all.nl</email></address>
   </Para>
  </ListItem>
  <ListItem>

<Para>
Stefan Huelbrock &lt;shuelbrock%datasystems.de&gt;
</Para>
</ListItem>
<ListItem>

<Para>
Alexander W. Janssen &lt;yalla%ynfonatic.de&gt;
</Para>
</ListItem>
<ListItem>

<para>
Andreas Jellinghaus &lt;aj%dungeon.inka.de&gt;
</para>
</listitem>

<listitem>
<Para>
Gareth John &lt;gdjohn%zepler.org&gt;
</Para>
</ListItem>

  <ListItem>
   <Para>
   <author><firstname>Dave</firstname><surname>Johnson</surname></author>
   <address><email>dj@www.uk.linux.org</email></address>
   </Para>
  </ListItem>


<ListItem>

<Para>
Martin Josefsson &lt;gandalf%wlug.westbo.se&gt;
</Para>
</ListItem>
<ListItem>

<Para>
Andi Kleen &lt;ak%suse.de&gt;
</Para>
</ListItem>
<ListItem>

<Para>
Andreas J. Koenig &lt;andreas.koenig%anima.de&gt;
</Para>
</ListItem>
<ListItem>

<Para>
Pawel Krawczyk &lt;kravietz%alfa.ceti.pl&gt;
</Para>
</ListItem>
<ListItem>

<Para>
Amit Kucheria &lt;amitk@ittc.ku.edu&gt;
</Para>
</ListItem>
<ListItem>

<Para>
Edmund Lau &lt;edlau%ucf.ics.uci.edu&gt;
</Para>
</ListItem>
<ListItem>

<Para>
Philippe Latu &lt;philippe.latu%linux-france.org&gt;
</Para>
</ListItem>
<ListItem>

<Para>
Arthur van Leeuwen &lt;arthurvl%sci.kun.nl&gt;
</Para>
</ListItem>
  <ListItem>
   <Para>
   <author><firstname>Jose Luis Domingo</firstname><surname>Lopez</surname>
     </author>
   <address><email>jdomingo@24x7linux.com</email></address>
  </Para>
  </ListItem>


  <ListItem>
   <Para>
   <author><firstname>Robert</firstname><surname>Lowe</surname>
     </author>
   <address><email>robert.h.lowe@lawrence.edu</email></address>
  </Para>
  </ListItem>


<ListItem>

<Para>
Jason Lunz &lt;j@cc.gatech.edu&gt;
</Para>
</ListItem>
<ListItem>

<Para>
Stuart Lynne &lt;sl@fireplug.net&gt;
</Para>
</ListItem>
<ListItem>

<Para>
Alexey Mahotkin &lt;alexm@formulabez.ru&gt;
</Para>
</ListItem>
<ListItem>

<Para>
Predrag Malicevic &lt;pmalic@ieee.org&gt;
</Para>
</ListItem>
<listitem>
<para>
Patrick McHardy &lt;kaber@trash.net&gt;
</para>
</ListItem>

<ListItem>


<Para>
Andreas Mohr &lt;andi%lisas.de&gt;
</Para>
</ListItem>

<listitem>
<para>James Morris &lt;jmorris@intercode.com.au&gt;
</para></listitem>


<ListItem>
<Para>
Andrew Morton &lt;akpm%zip.com.au&gt;
</Para>
</ListItem>

<ListItem>
<Para>
Wim van der Most 
</Para>
</ListItem>
<ListItem>

<Para>
Stephan Mueller &lt;smueller@chronox.de&gt;
</Para>
</ListItem>
<ListItem>

<Para>
Togan Muftuoglu &lt;toganm%yahoo.com&gt;
</Para>
</ListItem>
<ListItem>


<Para>
Chris Murray &lt;cmurray@stargate.ca&gt;
</Para>
</ListItem>
<ListItem>

<Para>
Patrick Nagelschmidt &lt;dto%gmx.net&gt;
</Para>
</ListItem>
<ListItem>

<Para>
Ram Narula &lt;ram@princess1.net&gt;
</Para>
</ListItem>
<ListItem>

<Para>
Jorge Novo &lt;jnovo@educanet.net&gt;
</Para>
</ListItem>
<ListItem>

<Para>
Patrik &lt;ph@kurd.nu&gt;
</Para>
</ListItem>

<listitem><para>P?l Osgy?ny &lt;oplab%westel900.net&gt;</para></listitem>

<ListItem>

<Para>
Lutz Pre&szlig;ler &lt;Lutz.Pressler%SerNet.DE&gt;
</Para>
</ListItem>
<ListItem>

<Para>
Jason Pyeron &lt;jason%pyeron.com&gt;
</Para>
</ListItem>

<ListItem>
<Para>
Rod Roark &lt;rod%sunsetsystems.com&gt;
</Para>
</ListItem>

<ListItem>
<Para>
Pavel Roskin &lt;proski@gnu.org&gt;
</Para>
</ListItem>


<ListItem>
<Para>
Rusty Russell &lt;rusty%rustcorp.com.au&gt;
</Para>
</ListItem>

<ListItem>
<Para>
Mihai RUSU &lt;dizzy%roedu.net&gt;
</Para>
</ListItem>

<ListItem>
<Para>
Rob Pitman &lt;rob%pitman.co.za&gt;
</Para>
</ListItem>


<ListItem>
<Para>
Jamal Hadi Salim &lt;hadi%cyberus.ca&gt;
</Para>
</ListItem>

<ListItem>
<Para>
Ren? Serral &lt;rserral%ac.upc.es&gt; 
</Para>
</ListItem>


<ListItem>
<Para>
David Sauer &lt;davids%penguin.cz&gt;
</Para>
</ListItem>
<ListItem>

<Para>
Sheharyar Suleman Shaikh &lt;sss23@drexel.edu&gt;
</Para>
</ListItem>
<ListItem>

<Para>
Stewart Shields &lt;MourningBlade%bigfoot.com&gt;
</Para>
</ListItem>
<ListItem>

<Para>
Nick Silberstein &lt;nhsilber%yahoo.com&gt;
</Para>
</ListItem>
<ListItem>

<Para>
Konrads Smelkov &lt;konrads@interbaltika.com&gt;
</Para>
</ListItem>
<ListItem>

<Para>
<author><firstname>William</firstname><surname>Stearns</surname></author>
<address><email>wstearns@pobox.com</email></address>
</Para>
</ListItem>

<ListItem>
<Para>
Andreas Steinmetz &lt;ast%domdv.de&gt;
</Para>
</ListItem>

<ListItem>
<Para>
Matthew Strait &lt;straitm%mathcs.carleton.edu&gt;
</Para>
</ListItem>

<ListItem>
<Para>
Jason Tackaberry &lt;tack@linux.com&gt;
</Para>
</ListItem>
<ListItem>

<Para>
Charles Tassell &lt;ctassell%isn.net&gt;
</Para>
</ListItem>
<ListItem>

<Para>
Glen Turner &lt;glen.turner%aarnet.edu.au&gt;
</Para>
</ListItem>

<ListItem>
<Para>
Tea Sponsor: Eric Veldhuyzen &lt;eric%terra.nu&gt; 
</Para>
</ListItem>

<listitem>
<para>
Thomas Walpuski &lt;thomas%bender.thinknerd.de&gt;
</para>
</listitem>


<ListItem>
<Para>
Song Wang &lt;wsong@ece.uci.edu&gt;
</Para>
</ListItem>

  <ListItem>
   <Para>
   <author><firstname>Chris</firstname><surname>Wilson</surname></author>
   <address><email>chris@netservers.co.uk</email></address>
   </Para>
  </ListItem>

  <ListItem>
   <Para>
   <author><firstname>Lazar</firstname><surname>Yanackiev</surname></author>
   <address><email>Lyanackiev%gmx.net</email></address>
   </Para>
  </ListItem>

  <ListItem>
   <Para>
   <author><firstname>Pedro</firstname><surname>Larroy</surname></author>
   <address><email>piotr%member.fsf.org</email></address>
   <ItemizedList>
       <ListItem>
       <para>
       Chapter 15, section 10: Example of a full nat solution with QoS
       </para>
       </ListItem>

       <ListItem>
       <para>
       Chapter 17, section 1: Setting up OSPF with Zebra
       </para>
       </ListItem>
   </ItemizedList>
   </Para>
  </ListItem>


</ItemizedList>

</Para>

</chapter>

</Book>





<!--
     FILE ARCHIVED ON 2:04:01 Apr 8, 2004 AND RETRIEVED FROM THE
     INTERNET ARCHIVE ON 11:43:07 Jan 16, 2014.
     JAVASCRIPT APPENDED BY WAYBACK MACHINE, COPYRIGHT INTERNET ARCHIVE.

     ALL OTHER CONTENT MAY ALSO BE PROTECTED BY COPYRIGHT (17 U.S.C.
     SECTION 108(a)(3)).
-->
